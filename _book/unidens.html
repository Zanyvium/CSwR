<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Computational Statistics with R</title>
  <meta name="description" content="Lecture notes providing an introduction to computational statistics using the R programming language.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Computational Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Computational Statistics with R" />
  
  <meta name="twitter:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

<meta name="author" content="Niels Richard Hansen">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="density.html">
<link rel="next" href="kernel-density.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro-smooth.html"><a href="intro-smooth.html"><i class="fa fa-check"></i><b>1.1</b> Smoothing</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro-smooth.html"><a href="intro-smooth.html#intro-angles"><i class="fa fa-check"></i><b>1.1.1</b> Angle distributions in proteins</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro-smooth.html"><a href="intro-smooth.html#using-ggplot2"><i class="fa fa-check"></i><b>1.1.2</b> Using ggplot2</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro-smooth.html"><a href="intro-smooth.html#changing-the-defaults"><i class="fa fa-check"></i><b>1.1.3</b> Changing the defaults</a></li>
<li class="chapter" data-level="1.1.4" data-path="intro-smooth.html"><a href="intro-smooth.html#large-scale-smoothing"><i class="fa fa-check"></i><b>1.1.4</b> Large scale smoothing</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html"><i class="fa fa-check"></i><b>1.2</b> Monte Carlo Methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#univariate-von-mises-distributions"><i class="fa fa-check"></i><b>1.2.1</b> Univariate von Mises distributions</a></li>
<li class="chapter" data-level="1.2.2" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#mixtures-of-von-mises-distributions"><i class="fa fa-check"></i><b>1.2.2</b> Mixtures of von Mises distributions</a></li>
<li class="chapter" data-level="1.2.3" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#large-scale-simulation"><i class="fa fa-check"></i><b>1.2.3</b> Large scale simulation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>1.3</b> Optimization</a><ul>
<li class="chapter" data-level="1.3.1" data-path="optimization.html"><a href="optimization.html#the-em-algorithm"><i class="fa fa-check"></i><b>1.3.1</b> The EM-algorithm</a></li>
<li class="chapter" data-level="1.3.2" data-path="optimization.html"><a href="optimization.html#large-scale-optimization"><i class="fa fa-check"></i><b>1.3.2</b> Large scale optimization</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.4</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#r-training-exercises"><i class="fa fa-check"></i>R training exercises</a></li>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#histograms-with-non-equidistant-breaks"><i class="fa fa-check"></i>Histograms with non-equidistant breaks</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Smoothing</b></span></li>
<li class="chapter" data-level="2" data-path="density.html"><a href="density.html"><i class="fa fa-check"></i><b>2</b> Density estimation</a><ul>
<li class="chapter" data-level="2.1" data-path="unidens.html"><a href="unidens.html"><i class="fa fa-check"></i><b>2.1</b> Univariate density estimation</a><ul>
<li class="chapter" data-level="2.1.1" data-path="unidens.html"><a href="unidens.html#likelihood"><i class="fa fa-check"></i><b>2.1.1</b> Likelihood considerations</a></li>
<li class="chapter" data-level="2.1.2" data-path="unidens.html"><a href="unidens.html#r-digression"><i class="fa fa-check"></i><b>2.1.2</b> R digression</a></li>
<li class="chapter" data-level="2.1.3" data-path="unidens.html"><a href="unidens.html#sieves"><i class="fa fa-check"></i><b>2.1.3</b> Method of sieves</a></li>
<li class="chapter" data-level="2.1.4" data-path="unidens.html"><a href="unidens.html#basis-density"><i class="fa fa-check"></i><b>2.1.4</b> Basis expansions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="kernel-density.html"><a href="kernel-density.html"><i class="fa fa-check"></i><b>2.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="kernel-density.html"><a href="kernel-density.html#benchmarking"><i class="fa fa-check"></i><b>2.2.1</b> Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bandwidth.html"><a href="bandwidth.html"><i class="fa fa-check"></i><b>2.3</b> Bandwidth selection</a><ul>
<li class="chapter" data-level="2.3.1" data-path="bandwidth.html"><a href="bandwidth.html#revisiting-the-rectangular-kernel"><i class="fa fa-check"></i><b>2.3.1</b> Revisiting the rectangular kernel</a></li>
<li class="chapter" data-level="2.3.2" data-path="bandwidth.html"><a href="bandwidth.html#ise-mise-and-mse-for-kernel-estimators"><i class="fa fa-check"></i><b>2.3.2</b> ISE, MISE and MSE for kernel estimators</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="multivariate-smoothing.html"><a href="multivariate-smoothing.html"><i class="fa fa-check"></i><b>2.4</b> Multivariate methods</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bivariate.html"><a href="bivariate.html"><i class="fa fa-check"></i><b>3</b> Bivariate smoothing</a><ul>
<li class="chapter" data-level="3.1" data-path="running-means.html"><a href="running-means.html"><i class="fa fa-check"></i><b>3.1</b> Running means</a><ul>
<li class="chapter" data-level="3.1.1" data-path="running-means.html"><a href="running-means.html#dense-linear-algebra"><i class="fa fa-check"></i><b>3.1.1</b> Dense linear algebra</a></li>
<li class="chapter" data-level="3.1.2" data-path="running-means.html"><a href="running-means.html#direct-implementation"><i class="fa fa-check"></i><b>3.1.2</b> Direct implementation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="kernel-methods.html"><a href="kernel-methods.html"><i class="fa fa-check"></i><b>3.2</b> Kernel methods</a></li>
<li class="chapter" data-level="3.3" data-path="sparse-linear-algebra.html"><a href="sparse-linear-algebra.html"><i class="fa fa-check"></i><b>3.3</b> Sparse linear algebra</a></li>
<li class="chapter" data-level="3.4" data-path="orthogonal-basis-expansions.html"><a href="orthogonal-basis-expansions.html"><i class="fa fa-check"></i><b>3.4</b> Orthogonal basis expansions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="orthogonal-basis-expansions.html"><a href="orthogonal-basis-expansions.html#polynomial-expansions"><i class="fa fa-check"></i><b>3.4.1</b> Polynomial expansions</a></li>
<li class="chapter" data-level="3.4.2" data-path="orthogonal-basis-expansions.html"><a href="orthogonal-basis-expansions.html#fourier-expansions"><i class="fa fa-check"></i><b>3.4.2</b> Fourier expansions</a></li>
<li class="chapter" data-level="3.4.3" data-path="orthogonal-basis-expansions.html"><a href="orthogonal-basis-expansions.html#wavelets"><i class="fa fa-check"></i><b>3.4.3</b> Wavelets</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>3.5</b> Splines</a></li>
<li class="chapter" data-level="3.6" data-path="gaussian-processes.html"><a href="gaussian-processes.html"><i class="fa fa-check"></i><b>3.6</b> Gaussian processes</a></li>
<li class="chapter" data-level="3.7" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html"><i class="fa fa-check"></i><b>3.7</b> The Kalman filter</a><ul>
<li class="chapter" data-level="3.7.1" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#ar1-example"><i class="fa fa-check"></i><b>3.7.1</b> AR(1)-example</a></li>
<li class="chapter" data-level="3.7.2" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#the-kalman-smoother"><i class="fa fa-check"></i><b>3.7.2</b> The Kalman smoother</a></li>
<li class="chapter" data-level="3.7.3" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#implementation"><i class="fa fa-check"></i><b>3.7.3</b> Implementation</a></li>
<li class="chapter" data-level="3.7.4" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#the-kalman-filter-1"><i class="fa fa-check"></i><b>3.7.4</b> The Kalman filter</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Monte Carlo Methods</b></span></li>
<li class="chapter" data-level="4" data-path="univariate-random-variables.html"><a href="univariate-random-variables.html"><i class="fa fa-check"></i><b>4</b> Univariate random variables</a><ul>
<li class="chapter" data-level="4.1" data-path="pseudo-random-numbers.html"><a href="pseudo-random-numbers.html"><i class="fa fa-check"></i><b>4.1</b> Pseudo random numbers</a></li>
<li class="chapter" data-level="4.2" data-path="transformation-techniques.html"><a href="transformation-techniques.html"><i class="fa fa-check"></i><b>4.2</b> Transformation techniques</a><ul>
<li class="chapter" data-level="4.2.1" data-path="transformation-techniques.html"><a href="transformation-techniques.html#sampling-from-a-t-distribution"><i class="fa fa-check"></i><b>4.2.1</b> Sampling from a <span class="math inline">\(t\)</span>-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="reject-samp.html"><a href="reject-samp.html"><i class="fa fa-check"></i><b>4.3</b> Rejection sampling</a><ul>
<li class="chapter" data-level="4.3.1" data-path="reject-samp.html"><a href="reject-samp.html#gamma-distribution"><i class="fa fa-check"></i><b>4.3.1</b> Gamma distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="MCI.html"><a href="MCI.html"><i class="fa fa-check"></i><b>5</b> Monte Carlo integration</a><ul>
<li class="chapter" data-level="5.1" data-path="assessment.html"><a href="assessment.html"><i class="fa fa-check"></i><b>5.1</b> Assessment</a><ul>
<li class="chapter" data-level="5.1.1" data-path="assessment.html"><a href="assessment.html#using-the-central-limit-theorem"><i class="fa fa-check"></i><b>5.1.1</b> Using the central limit theorem</a></li>
<li class="chapter" data-level="5.1.2" data-path="assessment.html"><a href="assessment.html#concentration-inequalities"><i class="fa fa-check"></i><b>5.1.2</b> Concentration inequalities</a></li>
<li class="chapter" data-level="5.1.3" data-path="assessment.html"><a href="assessment.html#exponential-tail-bound-for-gamma-distributed-variables"><i class="fa fa-check"></i><b>5.1.3</b> Exponential tail bound for Gamma distributed variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>5.2</b> Importance sampling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="importance-sampling.html"><a href="importance-sampling.html#unknown-normalization-constants"><i class="fa fa-check"></i><b>5.2.1</b> Unknown normalization constants</a></li>
<li class="chapter" data-level="5.2.2" data-path="importance-sampling.html"><a href="importance-sampling.html#computing-a-high-dimensional-integral"><i class="fa fa-check"></i><b>5.2.2</b> Computing a high-dimensional integral</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="network-failure.html"><a href="network-failure.html"><i class="fa fa-check"></i><b>5.3</b> Network failure</a><ul>
<li class="chapter" data-level="5.3.1" data-path="network-failure.html"><a href="network-failure.html#object-oriented-implementation"><i class="fa fa-check"></i><b>5.3.1</b> Object oriented implementation</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="design-of-experiments.html"><a href="design-of-experiments.html"><i class="fa fa-check"></i><b>5.4</b> Design of experiments</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-random-variables.html"><a href="multivariate-random-variables.html"><i class="fa fa-check"></i><b>6</b> Multivariate random variables</a><ul>
<li class="chapter" data-level="6.1" data-path="sequential-simulation.html"><a href="sequential-simulation.html"><i class="fa fa-check"></i><b>6.1</b> Sequential simulation</a><ul>
<li class="chapter" data-level="6.1.1" data-path="sequential-simulation.html"><a href="sequential-simulation.html#sequential-mc-for-the-ar1-process"><i class="fa fa-check"></i><b>6.1.1</b> Sequential MC for the AR(1)-process</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="gaussian-random-variables.html"><a href="gaussian-random-variables.html"><i class="fa fa-check"></i><b>6.2</b> Gaussian random variables</a></li>
</ul></li>
<li class="part"><span><b>Part III: Optimization</b></span></li>
<li class="chapter" data-level="7" data-path="four-examples.html"><a href="four-examples.html"><i class="fa fa-check"></i><b>7</b> Four Examples</a><ul>
<li class="chapter" data-level="7.1" data-path="multinomial-models.html"><a href="multinomial-models.html"><i class="fa fa-check"></i><b>7.1</b> Multinomial models</a><ul>
<li class="chapter" data-level="7.1.1" data-path="multinomial-models.html"><a href="multinomial-models.html#peppered-moths"><i class="fa fa-check"></i><b>7.1.1</b> Peppered Moths</a></li>
<li class="chapter" data-level="7.1.2" data-path="multinomial-models.html"><a href="multinomial-models.html#multinomial-cell-collapsing"><i class="fa fa-check"></i><b>7.1.2</b> Multinomial cell collapsing</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="mixtures.html"><a href="mixtures.html"><i class="fa fa-check"></i><b>7.2</b> Mixtures</a><ul>
<li class="chapter" data-level="7.2.1" data-path="mixtures.html"><a href="mixtures.html#gaussian-mixtures"><i class="fa fa-check"></i><b>7.2.1</b> Gaussian mixtures</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html"><i class="fa fa-check"></i><b>7.3</b> Mixed effects models</a></li>
<li class="chapter" data-level="7.4" data-path="gaussian-state-space-models.html"><a href="gaussian-state-space-models.html"><i class="fa fa-check"></i><b>7.4</b> Gaussian state space models</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="numerical-optimization.html"><a href="numerical-optimization.html"><i class="fa fa-check"></i><b>8</b> Numerical optimization</a><ul>
<li class="chapter" data-level="8.1" data-path="gradient-based-algorithms.html"><a href="gradient-based-algorithms.html"><i class="fa fa-check"></i><b>8.1</b> Gradient based algorithms</a><ul>
<li class="chapter" data-level="8.1.1" data-path="gradient-based-algorithms.html"><a href="gradient-based-algorithms.html#gradient-descent-and-conjugate-gradient"><i class="fa fa-check"></i><b>8.1.1</b> Gradient descent and conjugate gradient</a></li>
<li class="chapter" data-level="8.1.2" data-path="gradient-based-algorithms.html"><a href="gradient-based-algorithms.html#peppered-moths-1"><i class="fa fa-check"></i><b>8.1.2</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="newton-type-algorithms.html"><a href="newton-type-algorithms.html"><i class="fa fa-check"></i><b>8.2</b> Newton-type algorithms</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="EM.html"><a href="EM.html"><i class="fa fa-check"></i><b>9</b> Expectation Maximization algorithms</a><ul>
<li class="chapter" data-level="9.1" data-path="basic-properties.html"><a href="basic-properties.html"><i class="fa fa-check"></i><b>9.1</b> Basic properties</a><ul>
<li class="chapter" data-level="9.1.1" data-path="basic-properties.html"><a href="basic-properties.html#incomplete-data-likelihood"><i class="fa fa-check"></i><b>9.1.1</b> Incomplete data likelihood</a></li>
<li class="chapter" data-level="9.1.2" data-path="basic-properties.html"><a href="basic-properties.html#the-em-algorithm-is-ascending"><i class="fa fa-check"></i><b>9.1.2</b> The EM-algorithm is ascending</a></li>
<li class="chapter" data-level="9.1.3" data-path="basic-properties.html"><a href="basic-properties.html#multinomial-cell-collapsing-1"><i class="fa fa-check"></i><b>9.1.3</b> Multinomial cell collapsing</a></li>
<li class="chapter" data-level="9.1.4" data-path="basic-properties.html"><a href="basic-properties.html#peppered-moths-e--and-m-steps"><i class="fa fa-check"></i><b>9.1.4</b> Peppered Moths E- and M-steps</a></li>
<li class="chapter" data-level="9.1.5" data-path="basic-properties.html"><a href="basic-properties.html#inside-the-em"><i class="fa fa-check"></i><b>9.1.5</b> Inside the EM</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="EM-exp.html"><a href="EM-exp.html"><i class="fa fa-check"></i><b>9.2</b> Exponential families</a></li>
<li class="chapter" data-level="9.3" data-path="fisher-information.html"><a href="fisher-information.html"><i class="fa fa-check"></i><b>9.3</b> Fisher information</a></li>
<li class="chapter" data-level="9.4" data-path="two-examples-revisited.html"><a href="two-examples-revisited.html"><i class="fa fa-check"></i><b>9.4</b> Two examples revisited</a><ul>
<li class="chapter" data-level="9.4.1" data-path="two-examples-revisited.html"><a href="two-examples-revisited.html#gaussian-mixtures-1"><i class="fa fa-check"></i><b>9.4.1</b> Gaussian mixtures</a></li>
<li class="chapter" data-level="9.4.2" data-path="two-examples-revisited.html"><a href="two-examples-revisited.html#gaussian-state-space"><i class="fa fa-check"></i><b>9.4.2</b> Gaussian state space</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="stochastic-optimization.html"><a href="stochastic-optimization.html"><i class="fa fa-check"></i><b>10</b> Stochastic Optimization</a><ul>
<li class="chapter" data-level="10.1" data-path="stochastic-gradient.html"><a href="stochastic-gradient.html"><i class="fa fa-check"></i><b>10.1</b> Stochastic gradient</a></li>
<li class="chapter" data-level="10.2" data-path="stochastic-em.html"><a href="stochastic-em.html"><i class="fa fa-check"></i><b>10.2</b> Stochastic EM</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="unidens" class="section level2">
<h2><span class="header-section-number">2.1</span> Univariate density estimation</h2>
<p>Recall the data on <a href="intro-smooth.html#intro-angles"><span class="math inline">\(\phi\)</span>- and <span class="math inline">\(\psi\)</span>-angles</a> in polypeptide backbone structures, as considered in Section <a href="intro-smooth.html#intro-angles">1.1.1</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:phipsiDens2"></span>
<img src="CSwR_files/figure-html/phipsiDens2-1.png" alt="Histograms equipped with a rug plot of the distribution of \(\phi\)-angles (left) and \(\psi\)-angles (right) of the peptide planes in the protein human protein 1HMP." width="49%" /><img src="CSwR_files/figure-html/phipsiDens2-2.png" alt="Histograms equipped with a rug plot of the distribution of \(\phi\)-angles (left) and \(\psi\)-angles (right) of the peptide planes in the protein human protein 1HMP." width="49%" />
<p class="caption">
Figure 2.1: Histograms equipped with a rug plot of the distribution of <span class="math inline">\(\phi\)</span>-angles (left) and <span class="math inline">\(\psi\)</span>-angles (right) of the peptide planes in the protein human protein <a href="https://www.rcsb.org/structure/1HMP">1HMP</a>.
</p>
</div>
<p>We will in this section start the treatment of methods for smooth density estimation for univariate data such as data on either the <span class="math inline">\(\phi\)</span>- or the <span class="math inline">\(\psi\)</span>-angle. <a href="multivariate-smoothing.html#multivariate-smoothing">Multivariate methods</a> for estimation of e.g. the bivariate joint density of the angles is postponed to Section <a href="multivariate-smoothing.html#multivariate-smoothing">2.4</a>.</p>
<div id="likelihood" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Likelihood considerations</h3>
<p>Let <span class="math inline">\(f_0\)</span> denote the unknown density we want to estimate.</p>
<ul>
<li><p>If we fit a parametrized statistical model <span class="math inline">\((f_{\theta})_{\theta}\)</span> to data using the estimator <span class="math inline">\(\hat{\theta}\)</span>, then <span class="math inline">\(f_{\hat{\theta}}\)</span> is an estimate of <span class="math inline">\(f_0\)</span>.</p></li>
<li><p>The histogram is a nonparametric density estimator, <span class="math inline">\(\hat{f}\)</span>, of <span class="math inline">\(f_0\)</span>.</p></li>
<li>We are interested in nonparametric estimators because
<ul>
<li>we want to compare data with the parametric estimate <span class="math inline">\(f_{\hat{\theta}}\)</span></li>
<li>we don’t known a suitable parametric model</li>
<li>visualization</li>
</ul></li>
</ul>
<blockquote>
<p>“With four parameters I can fit an elephant, and with five I can make him wiggle his trunk.”</p>
<p>— John von Neumann</p>
</blockquote>
<p>The Normal-inverse Gaussian distribution has four parameters, the generalised hyperbolic distribution is an extension with five, but Neumann was probably thinking more in terms of the spline based expansion in Section <a href="unidens.html#basis-density">2.1.4</a> with four or five suitable basis functions.</p>
<p>For a parametric family we can use the MLE <span class="math display">\[\hat{\theta} = \text{arg max}_{\theta} \sum_{i=1}^n \log f_{\theta}(x_i).\]</span></p>
<p>For nonparametric estimation we can still introduce the log-likelihood: <span class="math display">\[\ell(f) = \sum_{i=1}^n \log f(x_i)\]</span></p>
<p>Let’s see what happens if <span class="math display">\[f(x) = f_h(x) = \frac{1}{nh \sqrt{2 \pi}} \sum_{j=1}^n e^{- \frac{(x - x_j)^2}{2 h^2} }.\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:gausKern"></span>
<img src="CSwR_files/figure-html/gausKern-1.png" alt="(ref:gausKern)" width="49%" /><img src="CSwR_files/figure-html/gausKern-2.png" alt="(ref:gausKern)" width="49%" /><img src="CSwR_files/figure-html/gausKern-3.png" alt="(ref:gausKern)" width="49%" /><img src="CSwR_files/figure-html/gausKern-4.png" alt="(ref:gausKern)" width="49%" /><img src="CSwR_files/figure-html/gausKern-5.png" alt="(ref:gausKern)" width="49%" /><img src="CSwR_files/figure-html/gausKern-6.png" alt="(ref:gausKern)" width="49%" />
<p class="caption">
Figure 2.2: (ref:gausKern)
</p>
</div>
<p>Log-likelihood</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hseq &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="fl">0.001</span>, <span class="op">-</span><span class="fl">0.001</span>)
ll &lt;-<span class="st"> </span><span class="kw">sapply</span>(hseq, <span class="cf">function</span>(h) 
         <span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">ffun</span>(phipsi<span class="op">$</span>psi, h))))</code></pre></div>
<p><img src="CSwR_files/figure-html/pside-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Log-likelihood</p>
<p>If <span class="math inline">\(x_i \neq x_j\)</span> when <span class="math inline">\(i \neq j\)</span></p>
<span class="math display">\[\begin{align*}
\ell(f_h) &amp; = \sum_{i} \log\left(1 + \sum_{j \neq i} e^{-(x_i - x_j)^2 / (2 h^2)} \right) - 
n \log(nh\sqrt{2 \pi}) \\
&amp; \sim - n \log(nh\sqrt{2 \pi})
\end{align*}\]</span>
<p>for <span class="math inline">\(h \to 0\)</span>.</p>
<p>Hence, <span class="math inline">\(\ell(f_h) \to \infty\)</span> for <span class="math inline">\(h \to 0\)</span> and there is no MLE in the set of distributions with densities.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(phipsi)
asympll &lt;-<span class="st"> </span><span class="op">-</span><span class="st"> </span>n <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(n <span class="op">*</span><span class="st"> </span>hseq <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-<span class="st"> </span>p1 <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(hseq, asympll))
p2 &lt;-<span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(hseq, asympll))</code></pre></div>
<p><img src="CSwR_files/figure-html/pside2-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>In the sense of <a href="https://en.wikipedia.org/wiki/Convergence_of_measures#Weak_convergence_of_measures">weak convergence</a> it actually holds that <span class="math display">\[f_h \cdot m \overset{\mathrm{wk}}{\longrightarrow} 
\varepsilon_n = \frac{1}{n} \sum_{i=1}^n \delta_{x_i}\]</span> for <span class="math inline">\(h \to 0\)</span>.</p>
<p>The <em>empirical measure</em> <span class="math inline">\(\varepsilon_n\)</span> can sensibly be regarded as the nonparametric MLE of the distribution. But the empirical measure does not have a density,</p>
</div>
<div id="r-digression" class="section level3">
<h3><span class="header-section-number">2.1.2</span> R digression</h3>
<p>Alternative, which is faster but more special purpose:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">diffsq &lt;-<span class="st"> </span><span class="kw">outer</span>(phipsi<span class="op">$</span>psi, phipsi<span class="op">$</span>psi, 
                <span class="cf">function</span>(x, y) (x <span class="op">-</span><span class="st"> </span>y)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(phipsi)
ll2 &lt;-<span class="st"> </span><span class="kw">sapply</span>(hseq, <span class="cf">function</span>(h) 
                <span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">colSums</span>(<span class="kw">exp</span>(<span class="op">-</span>diffsq <span class="op">/</span><span class="st"> </span>h<span class="op">^</span><span class="dv">2</span>)))) <span class="op">-</span><span class="st"> </span>
<span class="st">                </span>n <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(n <span class="op">*</span><span class="st"> </span>h <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi)))</code></pre></div>
<p>The second implementation reveals the <span class="math inline">\(n^2\)</span>-complexity of the computations by the call to <code>outer</code>.</p>
</div>
<div id="sieves" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Method of sieves</h3>
<p><a href="https://projecteuclid.org/euclid.aos/1176345782">Nonparametric Maximum Likelihood Estimation by the Method of Sieves</a></p>
<p>Penalized and constraint MLE.</p>
</div>
<div id="basis-density" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Basis expansions</h3>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="density.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="kernel-density.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

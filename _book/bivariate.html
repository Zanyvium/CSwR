<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Bivariate smoothing | Computational Statistics with R</title>
<meta name="author" content="Niels Richard Hansen">
<meta name="description" content="The focus of this chapter is on estimating how one variable, \(Y\), is smoothly related to another, \(X\). Thus we are directly aiming for an estimate of (aspects of) the conditional distribution...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 3 Bivariate smoothing | Computational Statistics with R">
<meta property="og:type" content="book">
<meta property="og:description" content="The focus of this chapter is on estimating how one variable, \(Y\), is smoothly related to another, \(X\). Thus we are directly aiming for an estimate of (aspects of) the conditional distribution...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Bivariate smoothing | Computational Statistics with R">
<meta name="twitter:description" content="The focus of this chapter is on estimating how one variable, \(Y\), is smoothly related to another, \(X\). Thus we are directly aiming for an estimate of (aspects of) the conditional distribution...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.10/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/_Roboto%20Slab-0.4.0/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.3.0/transition.js"></script><script src="libs/bs3compat-0.3.0/tabs.js"></script><script src="libs/bs3compat-0.3.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Computational Statistics with R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Introduction</a></li>
<li class="book-part">Part I: Smoothing</li>
<li><a class="" href="density.html"><span class="header-section-number">2</span> Density estimation</a></li>
<li><a class="active" href="bivariate.html"><span class="header-section-number">3</span> Bivariate smoothing</a></li>
<li class="book-part">Part II: Monte Carlo Methods</li>
<li><a class="" href="univariate-random-variables.html"><span class="header-section-number">4</span> Univariate random variables</a></li>
<li><a class="" href="mci.html"><span class="header-section-number">5</span> Monte Carlo integration</a></li>
<li class="book-part">Part III: Optimization</li>
<li><a class="" href="four-examples.html"><span class="header-section-number">6</span> Four Examples</a></li>
<li><a class="" href="numopt.html"><span class="header-section-number">7</span> Numerical optimization</a></li>
<li><a class="" href="em.html"><span class="header-section-number">8</span> Expectation maximization algorithms</a></li>
<li><a class="" href="StochOpt.html"><span class="header-section-number">9</span> Stochastic Optimization</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="app-R.html"><span class="header-section-number">A</span> R programming</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/nielsrhansen/CSwR">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="bivariate" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Bivariate smoothing<a class="anchor" aria-label="anchor" href="#bivariate"><i class="fas fa-link"></i></a>
</h1>
<p>The focus of this chapter is on estimating how one variable, <span class="math inline">\(Y\)</span>, is smoothly
related to another, <span class="math inline">\(X\)</span>. Thus we are directly aiming for an estimate of
(aspects of) the conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>. If both variables
are real valued, we can get a pretty good idea of their relation by simply
looking at a scatter plot, and what we are aiming for is also often referred to
as <em>scatter plot smoothing</em>. In some cases <span class="math inline">\(X\)</span> represents a random variable,
while in other cases, as the temperature example below, <span class="math inline">\(X\)</span> represents a
deterministic variable. In the example below <span class="math inline">\(X\)</span> is time, and in other applications
<span class="math inline">\(X\)</span> could be fixed by an experimental design.</p>
<p>One of the examples that will be used throughout is the monthly and yearly
temperatures in Nuuk, Greenland, see <span class="citation"><a href="references.html#ref-Vinther:2006" role="doc-biblioref">Vinther et al.</a> (<a href="references.html#ref-Vinther:2006" role="doc-biblioref">2006</a>)</span>. The updated data is available
from the site
<a href="https://crudata.uea.ac.uk/cru/data/greenland/">SW Greenland temperature data</a>.</p>
<pre><code>## Warning: `read_table2()` was deprecated in readr 2.0.0.
## Please use `read_table()` instead.</code></pre>

<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_Nuuk</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Nuuk_year</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Year</span>, y <span class="op">=</span> <span class="va">Temperature</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">p_Nuuk</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>
    method <span class="op">=</span> <span class="st">"lm"</span>, 
    formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">10</span><span class="op">)</span>,      <span class="co"># A degree-10 polynomial expansion</span>
    color <span class="op">=</span> <span class="st">"red"</span>, 
    se <span class="op">=</span> <span class="cn">FALSE</span>
  <span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>
    method <span class="op">=</span> <span class="st">"gam"</span>, 
    formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">x</span>, bs <span class="op">=</span> <span class="st">"cr"</span><span class="op">)</span>,   <span class="co"># A spline smoother via 'mgcv::gam()'</span>
    color <span class="op">=</span> <span class="st">"purple"</span>, 
    se <span class="op">=</span> <span class="cn">FALSE</span>
  <span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Nuuk</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Month</span>, y <span class="op">=</span> <span class="va">Temperature</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>group <span class="op">=</span> <span class="va">Year</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"red"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>  <span class="co"># A spline smoother</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:NuukSmooth"></span>
<img src="CSwR_files/figure-html/NuukSmooth-1.png" alt="Nuuk average yearly temperature in degrees Celsius (left) smoothed using loess (black), a degree 10 polynomial (red) and a smooth spline (purple). Nuuk annual temperature cycles (right) smoothed using a spline." width="49%"><img src="CSwR_files/figure-html/NuukSmooth-2.png" alt="Nuuk average yearly temperature in degrees Celsius (left) smoothed using loess (black), a degree 10 polynomial (red) and a smooth spline (purple). Nuuk annual temperature cycles (right) smoothed using a spline." width="49%"><p class="caption">
Figure 3.1: Nuuk average yearly temperature in degrees Celsius (left) smoothed using loess (black), a degree 10 polynomial (red) and a smooth spline (purple). Nuuk annual temperature cycles (right) smoothed using a spline.
</p>
</div>
<div id="nearest-neighbor-smoothers" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Nearest neighbor smoothers<a class="anchor" aria-label="anchor" href="#nearest-neighbor-smoothers"><i class="fas fa-link"></i></a>
</h2>
<p>One of the most basic ideas on smoothing bivariate data is to use a
running mean or moving average. This is particularly sensible when the
<span class="math inline">\(x\)</span>-values are equidistant, e.g. when the observations constitute
a time series such as the Nuuk temperature data. The running mean is
an example of the more general nearest neighbor smoothers.</p>
<p>Mathematically, the <span class="math inline">\(k\)</span> nearest neighbor smoother in <span class="math inline">\(x_i\)</span> is defined as
<span class="math display">\[\hat{f}_i = \frac{1}{k} \sum_{j \in N_i} y_j\]</span>
where <span class="math inline">\(N_i\)</span> is the set of indices for the <span class="math inline">\(k\)</span> nearest neighbors of <span class="math inline">\(x_i\)</span>.
This simple idea is actually very general and powerful. It works as long
as the <span class="math inline">\(x\)</span>-values lie in a metric space, and by letting <span class="math inline">\(k\)</span> grow with
<span class="math inline">\(n\)</span> it is possible to construct consistent nonparametric estimators of
regression functions, <span class="math inline">\(f(x) = E(Y \mid X = x)\)</span>, under minimal assumptions.
The practical problem is that <span class="math inline">\(k\)</span> must grow slowly in high dimensions,
and the estimator is not a panacea.</p>
<p>In this chapter we focus exclusively on <span class="math inline">\(x\)</span> being real valued with the
ordinary metric used to define the nearest neighbors. The total ordering of the
real line adds a couple of extra possibilities to the definition of <span class="math inline">\(N_i\)</span>.
When <span class="math inline">\(k\)</span> is odd, the <em>symmetric</em> nearest neighbor smoother takes <span class="math inline">\(N_i\)</span> to consist
of <span class="math inline">\(x_i\)</span> together with the <span class="math inline">\((k-1)/2\)</span> smaller <span class="math inline">\(x_j\)</span>-s closest to
<span class="math inline">\(x_i\)</span> and the <span class="math inline">\((k-1)/2\)</span> larger <span class="math inline">\(x_j\)</span>-s closest to <span class="math inline">\(x_i\)</span>. It is
also possible to choose a one-sided smoother with <span class="math inline">\(N_i\)</span> corresponding
to the <span class="math inline">\(k\)</span> smaller <span class="math inline">\(x_j\)</span>-s closest to <span class="math inline">\(x_i\)</span>, in which case the smoother would
be known as a causal filter.</p>
<p>The symmetric definition of neighbors makes it very easy
to handle the neighbors computationally; we don’t need to compute and keep
track of the <span class="math inline">\(n^2\)</span> pairwise distances between the <span class="math inline">\(x_i\)</span>-s, we only need
to sort data according to the <span class="math inline">\(x\)</span>-values. Once data is sorted,
<span class="math display">\[N_i = \{i - (k - 1) / 2, i - (k - 1) / 2 + 1, \ldots, i - 1 , i, i + 1, \ldots,   i + (k - 1) / 2\}\]</span>
for <span class="math inline">\((k - 1) / 2 \leq i \leq n - (k - 1) / 2\)</span>. The symmetric <span class="math inline">\(k\)</span> nearest neighbor
smoother is thus a running mean of the <span class="math inline">\(y\)</span>-values when sorted according to
the <span class="math inline">\(x\)</span>-values. There are a couple of possibilities for handling the boundaries,
one being simply to not define a value of <span class="math inline">\(\hat{f}_i\)</span> outside of the interval
above.</p>
<p>With <span class="math inline">\(\hat{\mathbf{f}}\)</span> denoting the vector of smoothed values by a nearest
neighbor smoother we can observe that it is always possible to write
<span class="math inline">\(\hat{\mathbf{f}} = \mathbf{S}\mathbf{y}\)</span> for a matrix <span class="math inline">\(\mathbf{S}\)</span>. For the symmetric
nearest neighbor smoother and with data sorted according to the <span class="math inline">\(x\)</span>-values,
the matrix has the following band diagonal form</p>
<p><span class="math display">\[
\mathbf{S} = \left( \begin{array}{cccccccccc} 
\frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; 0 &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
0 &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; 0 &amp; \ldots &amp; 0 &amp; 0\\
0 &amp; 0 &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \frac{1}{5} &amp; \ldots &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \ldots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \ldots &amp; \frac{1}{5} &amp; \frac{1}{5} \\
\end{array} \right) 
\]</span></p>
<p>here given for <span class="math inline">\(k = 5\)</span> and with dimensions <span class="math inline">\((n - 4) \times n\)</span> due to the
undefined boundary values.</p>
<div id="linear-smoothers" class="section level3" number="3.1.1">
<h3>
<span class="header-section-number">3.1.1</span> Linear smoothers<a class="anchor" aria-label="anchor" href="#linear-smoothers"><i class="fas fa-link"></i></a>
</h3>
<p>A smoother of the form <span class="math inline">\(\hat{\mathbf{f}} = \mathbf{S}\mathbf{y}\)</span> for a <em>smoother matrix</em> <span class="math inline">\(\mathbf{S}\)</span>,
such as the nearest neighbor smoother, is known as a <em>linear smoother</em>.
The linear form is often beneficial for theoretical arguments, and many smoothers
considered in this chapter will be linear smoothers. For computing <span class="math inline">\(\mathbf{f}\)</span>
there may, however, be many alternatives to forming the matrix <span class="math inline">\(\mathbf{S}\)</span>
and computing the matrix-vector product. Indeed, this is often not the best
way to compute the smoothed values.</p>
<p>It is, on the other hand, useful to see how <span class="math inline">\(\mathbf{S}\)</span> can be constructed
for the symmetric nearest neighbor smoother.</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">11</span>, <span class="fl">11</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">147</span> <span class="op">-</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span>
<span class="va">S</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">w</span>, <span class="fl">147</span> <span class="op">-</span> <span class="fl">10</span>, <span class="fl">147</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code>## Warning in matrix(w, 147 - 10, 147, byrow = TRUE): data length [148] is not a sub-multiple or
## multiple of the number of rows [137]</code></pre>
<p>The construction above relies on vector recycling of <code>w</code> in the construction of <code>S</code>
and the fact that <code>w</code> has length <span class="math inline">\(147 + 1\)</span>, which will effectively cause <code>w</code> to be
translated by one to the right every time it is recycled for a new row. As seen,
the code triggers a warning by R, but in this case we get what we want.</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">S</span></code></pre></div>
<div class="inline-figure"><img src="CSwR_files/figure-html/S-NN-top-actual-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>We can use the matrix to smooth the annual average temperature in Nuuk using a
running mean with a window of <span class="math inline">\(k = 11\)</span> years. That is, the smoothed temperature
at a given year is the average of the temperatures in the period
from five years before to five years after. Note that to add the smoothed
values to the previous plot we need to pad the values at the boundaries
with <code>NA</code>s to get a vector of length 147.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Check first if data is sorted correctly.</span>
<span class="co"># The test is backwards, but confirms that data isn't unsorted :-)</span>
<span class="fu"><a href="https://rdrr.io/r/base/is.unsorted.html">is.unsorted</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">f_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="fl">5</span><span class="op">)</span>, <span class="va">S</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span>
<span class="va">p_Nuuk</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">f_hat</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-NN-plot"></span>
<img src="CSwR_files/figure-html/Nuuk-NN-plot-1.png" alt="Annual average temperature in Nuuk smoothed using the running mean with $k = 11$ neighbors." width="70%"><p class="caption">
Figure 3.2: Annual average temperature in Nuuk smoothed using the running mean with <span class="math inline">\(k = 11\)</span> neighbors.
</p>
</div>
</div>
<div id="implementing-the-running-mean" class="section level3" number="3.1.2">
<h3>
<span class="header-section-number">3.1.2</span> Implementing the running mean<a class="anchor" aria-label="anchor" href="#implementing-the-running-mean"><i class="fas fa-link"></i></a>
</h3>
<p>The running mean smoother fulfills the following identity
<span class="math display">\[\hat{f}_{i+1} = \hat{f}_{i} - y_{i - (k-1)/2} / k + y_{i + (k + 1)/2} / k,\]</span>
which can be used for a much more efficient implementation
than the matrix-vector multiplication. It should be emphasized
again that the identity above and the implementation below
assume that data is sorted according to <span class="math inline">\(x\)</span>-values.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># The vector 'y' must be sorted according to the x-values</span>
<span class="va">run_mean</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">k</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
  <span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">floor</a></span><span class="op">(</span><span class="op">(</span><span class="va">k</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span>
  <span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">m</span> <span class="op">+</span> <span class="fl">1</span>           <span class="co"># Ensures k to be odd and m = (k - 1) / 2</span>
  <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">y</span> <span class="op">/</span> <span class="va">k</span>
  <span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">n</span><span class="op">)</span>
  <span class="va">s</span><span class="op">[</span><span class="va">m</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">]</span><span class="op">)</span>
  <span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="op">(</span><span class="va">m</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">m</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> 
    <span class="va">s</span><span class="op">[</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">s</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">-</span> <span class="va">y</span><span class="op">[</span><span class="va">i</span> <span class="op">-</span> <span class="va">m</span><span class="op">]</span> <span class="op">+</span> <span class="va">y</span><span class="op">[</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">m</span><span class="op">]</span>
  <span class="va">s</span>
<span class="op">}</span></code></pre></div>

<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_Nuuk</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">run_mean</span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fl">11</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-NN-plot2"></span>
<img src="CSwR_files/figure-html/Nuuk-NN-plot2-1.png" alt="Annual average temperature in Nuuk smoothed using the running mean with \(k = 11\) neighbors. This time using a different implementation than in Figure 3.2." width="70%"><p class="caption">
Figure 3.3: Annual average temperature in Nuuk smoothed using the running mean with <span class="math inline">\(k = 11\)</span> neighbors. This time using a different implementation than in Figure <a href="bivariate.html#fig:Nuuk-NN-plot">3.2</a>.
</p>
</div>
<p>The R function <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> (from the stats package) can be used to compute running
means and general moving averages using any weight vector. We compare our two
implementations to <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code>.</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">f_hat_filter</span> <span class="op">&lt;-</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">11</span>, <span class="fl">11</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">f_hat_filter</span> <span class="op">-</span> <span class="va">f_hat</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -4.440892e-16  4.440892e-16</code></pre>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">f_hat_filter</span> <span class="op">-</span> <span class="fu">run_mean</span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fl">11</span><span class="op">)</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -1.332268e-15  4.440892e-16</code></pre>
<p>Note that <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> uses the same boundary convention as used in <code>run_mean()</code>.</p>
<p>A benchmark comparison between matrix-vector multiplication, <code>run_mean()</code> and <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code>
gives the following table with median run time in microseconds.</p>
<pre><code>##                                       expr     median
## 1                          S1 %*% y[1:512]   484.8890
## 2                         S2 %*% y[1:1024]  1950.6210
## 3                         S3 %*% y[1:2048]  8258.3855
## 4                         S4 %*% y[1:4096] 33075.7655
## 5               run_mean(y[1:512], k = 11)   112.4760
## 6              run_mean(y[1:1024], k = 11)   197.7215
## 7              run_mean(y[1:2048], k = 11)   376.1560
## 8              run_mean(y[1:4096], k = 11)   734.0545
## 9   stats::filter(y[1:512], rep(1/11, 11))   135.1490
## 10 stats::filter(y[1:1024], rep(1/11, 11))   180.7525
## 11 stats::filter(y[1:2048], rep(1/11, 11))   229.8480
## 12 stats::filter(y[1:4096], rep(1/11, 11))   389.4675</code></pre>
<p>The matrix-vector computation is clearly much slower than the two alternatives,
and the time to construct the <span class="math inline">\(\mathbf{S}\)</span>-matrix has not even been included
in the benchmark above. There is also a difference in how the matrix-vector
multiplication scales with the size of data compared to the alternatives.
Whenever the data size doubles the run time approximately doubles for
both <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> and <code>run_mean()</code>, while it quadruples for the matrix-vector
multiplication. This shows the difference between an algorithm
that scales like <span class="math inline">\(O(n)\)</span> and an algorithm that scales like <span class="math inline">\(O(n^2)\)</span>
as the matrix-vector product does.</p>
<p>Despite that <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> is implementing a more general
algorithm than <code>run_mean()</code>, it is still faster, which reflects that
it is implemented in C and compiled.</p>
</div>
<div id="choose-k-by-cross-validation" class="section level3" number="3.1.3">
<h3>
<span class="header-section-number">3.1.3</span> Choose <span class="math inline">\(k\)</span> by cross-validation<a class="anchor" aria-label="anchor" href="#choose-k-by-cross-validation"><i class="fas fa-link"></i></a>
</h3>
<p>Cross-validation relies predictions of <span class="math inline">\(y_i\)</span> from <span class="math inline">\(x_i\)</span>
for data points <span class="math inline">\((x_i, y_i)\)</span> left out of the data set when the predictor
is fitted to data. Many (linear) smoothers have a natural definition of an “out-of-sample”
prediction, that is, how <span class="math inline">\(\hat{f}(x)\)</span> is computed for <span class="math inline">\(x\)</span> not
in the data. If so, it becomes possible to define
<span class="math display">\[\hat{f}^{-i}_i = \hat{f}^{-i}(x_i)\]</span>
as the prediction at <span class="math inline">\(x_i\)</span> using the smoother computed from data
with <span class="math inline">\((x_i, y_i)\)</span> excluded. However, here we derectly <em>define</em>
<span class="math display">\[\hat{f}^{-i}_i = \sum_{j \neq i} \frac{S_{ij}y_j}{1 - S_{ii}}\]</span>
for any linear smoother. This definition concurs with the
“out-of-sample” predictor in <span class="math inline">\(x_i\)</span> for most smoothers,
but this has to be verified case-by-case.</p>
<p>The running mean is a little special in this respect. In the
previous section, the
running mean was only considered for odd <span class="math inline">\(k\)</span> and using
a symmetric neighbor definition. This is convenient
when considering the running mean <em>in the observations</em> <span class="math inline">\(x_i\)</span>.
When considering the running mean in any other point, a symmetric
neighbor definition works better with an even <span class="math inline">\(k\)</span>. This
is exactly what the definition of <span class="math inline">\(\hat{f}^{-i}_i\)</span> above amounts to.
If <span class="math inline">\(\mathbf{S}\)</span> is the running mean smoother matrix for an odd <span class="math inline">\(k\)</span>,
then <span class="math inline">\(\hat{f}^{-i}_i\)</span> corresponds to symmetric <span class="math inline">\((k-1)\)</span>-nearest
neighbor smoothing excluding <span class="math inline">\((x_i, y_i)\)</span> from the data.</p>
<p>Using the definition above, we get that the <em>leave-one-out cross-validation</em>
squared error criterion becomes
<span class="math display">\[\mathrm{LOOCV} = \sum_{i=1}^n (y_i - \hat{f}^{-i}_i)^2 = 
\sum_{i=1}^n \left(\frac{y_i - \hat{f}_i}{1 - S_{ii}}\right)^2.\]</span>
The important observation from the identity above is that LOOCV
can be computed without actually computing all the <span class="math inline">\(\hat{f}^{-i}_i\)</span>.</p>
<p>For the running mean, all diagonal elements of the smoother matrix are identical.
We disregard boundary values (with the <code>NA</code> value), so to get
a comparable quantity across different choices of <span class="math inline">\(k\)</span> we use <code><a href="https://rdrr.io/r/base/mean.html">mean()</a></code> instead of
<code><a href="https://rdrr.io/r/base/sum.html">sum()</a></code> in the implementation.</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">loocv</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">k</span>, <span class="va">y</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">f_hat</span> <span class="op">&lt;-</span> <span class="fu">run_mean</span><span class="op">(</span><span class="va">y</span>, <span class="va">k</span><span class="op">)</span>
  <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">f_hat</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span><span class="op">/</span><span class="va">k</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> 
<span class="op">}</span></code></pre></div>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">k</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">40</span>, <span class="fl">2</span><span class="op">)</span>
<span class="va">CV</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">k</span>, <span class="va">loocv</span>, y <span class="op">=</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span>
<span class="va">k_opt</span> <span class="op">&lt;-</span> <span class="va">k</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">CV</span><span class="op">)</span><span class="op">]</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/qplot.html">qplot</a></span><span class="op">(</span><span class="va">k</span>, <span class="va">CV</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">k_opt</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-running-loocv"></span>
<img src="CSwR_files/figure-html/Nuuk-running-loocv-1.png" alt="The leave-one-out cross-validation criterion for the running mean as a function of the number of neighbors $k$." width="70%"><p class="caption">
Figure 3.4: The leave-one-out cross-validation criterion for the running mean as a function of the number of neighbors <span class="math inline">\(k\)</span>.
</p>
</div>
<p>The optimal choice of <span class="math inline">\(k\)</span> is 15, but the LOOCV criterion jumps quite a
lot up and down with changing neighbor size, and <span class="math inline">\(k = 9\)</span> as well as <span class="math inline">\(k = 25\)</span>
give rather low values as well.</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_Nuuk</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">run_mean</span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">run_mean</span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="va">k_opt</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">run_mean</span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fl">25</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"purple"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-NN-plot3"></span>
<img src="CSwR_files/figure-html/Nuuk-NN-plot3-1.png" alt="The $k$-nearest neighbor smoother with the optimal choice of $k$ based on LOOCV (blue) and with $k = 9$ (red) and $k = 25$ (purple)." width="70%"><p class="caption">
Figure 3.5: The <span class="math inline">\(k\)</span>-nearest neighbor smoother with the optimal choice of <span class="math inline">\(k\)</span> based on LOOCV (blue) and with <span class="math inline">\(k = 9\)</span> (red) and <span class="math inline">\(k = 25\)</span> (purple).
</p>
</div>
</div>
</div>
<div id="kernel-methods" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Kernel methods<a class="anchor" aria-label="anchor" href="#kernel-methods"><i class="fas fa-link"></i></a>
</h2>
<div id="nadarayawatson-kernel-smoothing" class="section level3" number="3.2.1">
<h3>
<span class="header-section-number">3.2.1</span> Nadaraya–Watson kernel smoothing<a class="anchor" aria-label="anchor" href="#nadarayawatson-kernel-smoothing"><i class="fas fa-link"></i></a>
</h3>
<p>The section before introduced the basic idea of nearest neighbor smoothing
using a fixed number of neighbors. A very similar idea is to use a fixed
neighborhood, <span class="math inline">\(B_i\)</span>, say, around <span class="math inline">\(x_i\)</span>. This leads to the estimator
<span class="math display">\[\hat{f}_i = \frac{\sum_{j=1}^n y_j 1_{B_i}(x_j)}{\sum_{j=1}^n 1_{B_i}(x_j)},\]</span>
which is simply the average of the <span class="math inline">\(y\)</span>-s for which the corresponding <span class="math inline">\(x\)</span>-s
fall in the neighborhood <span class="math inline">\(B_i\)</span> of <span class="math inline">\(x_i\)</span>. Note that contrary to the nearest
neighbor estimator, the denominator now also depends on the <span class="math inline">\(x\)</span>-s.</p>
<p>In a metric space the natural
choice of <span class="math inline">\(B_i\)</span> is the ball, <span class="math inline">\(B(x_i, h)\)</span>, around <span class="math inline">\(x_i\)</span> with some radius <span class="math inline">\(h\)</span>.
In <span class="math inline">\(\mathbb{R}\)</span> with the usual metric (or even <span class="math inline">\(\mathbb{R}^p\)</span> equipped with any
norm-induced metric) we have that<br><span class="math display">\[1_{B(x_i, h)}(x) = 1_{B(0, 1)}\left(\frac{x - x_i}{h}\right),\]</span>
thus since <span class="math inline">\(B(0, 1) = [-1, 1]\)</span> in <span class="math inline">\(\mathbb{R}\)</span>
<span class="math display">\[\hat{f}_i = \frac{\sum_{j=1}^n y_j 1_{[-1, 1]}\left(\frac{x_j - x_i}{h}\right)}{\sum_{l=1}^n 1_{[-1, 1]}\left(\frac{x_l - x_i}{h}\right)}.\]</span>
This nonparametric estimator of the conditional expectation <span class="math inline">\(E(Y \mid X = x_i)\)</span>
is closely related to the kernel density estimator with the
rectangular kernel, see Section <a href="density.html#kernel-density">2.2</a>, and just as for this
estimator there is a natural generalization allowing for arbitrary kernels
instead of the indicator function <span class="math inline">\(1_{[-1, 1]}\)</span>.</p>
<p>With <span class="math inline">\(K : \mathbb{R} \mapsto \mathbb{R}\)</span> a fixed kernel the corresponding
kernel smoother with bandwidth <span class="math inline">\(h\)</span> becomes
<span class="math display">\[\hat{f}_i = \frac{\sum_{j=1}^n y_j K\left(\frac{x_j - x_i}{h}\right)}{\sum_{l=1}^n K\left(\frac{x_l - x_i}{h}\right)}.\]</span>
This smoother is known as the Nadaraya–Watson kernel smoother or Nadaraya–Watson
estimator. See Exercise <a href="bivariate.html#exr:NW">3.1</a> for an additional
perspective based on bivariate kernel density estimation.</p>
<p>The Nadaraya–Watson kernel smoother can be implemented in much the same way
as the kernel density estimator, and the run time will inevitably scale
like <span class="math inline">\(O(n^2)\)</span> unless we exploit special properties of the kernel or use
approximation techniques such as binning. In this section we will focus on
implementing bandwidth selection rather than the kernel smoother itself.
The basic kernel smoothing computation is also implemented in the
<code>ksmooth</code> function from the stats package.</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">f_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ksmooth.html">ksmooth</a></span><span class="op">(</span>
  <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, 
  <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, 
  kernel <span class="op">=</span> <span class="st">"normal"</span>,
  bandwidth <span class="op">=</span> <span class="fl">10</span>, 
  x.points <span class="op">=</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>
<span class="op">)</span>
<span class="va">p_Nuuk</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">f_hat</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ksmooth-Nuuk"></span>
<img src="CSwR_files/figure-html/ksmooth-Nuuk-1.png" alt="Nadaraya–Watson kernel smoother of the annual average temperature in Nuuk computed using `ksmooth` with the Gaussian kernel and bandwidth 10." width="70%"><p class="caption">
Figure 3.6: Nadaraya–Watson kernel smoother of the annual average temperature in Nuuk computed using <code>ksmooth</code> with the Gaussian kernel and bandwidth 10.
</p>
</div>
<p>The kernel smoother is clearly a linear smoother, and we will implement its
computation and the bandwidth selection using LOOCV by direct computation
of the the smoother matrix <span class="math inline">\(\mathbf{S}\)</span>, which is given by
<span class="math display">\[S_{ij} = \frac{K\left(\frac{x_j - x_i}{h}\right)}{\sum_{l=1}^n K\left(\frac{x_l - x_i}{h}\right)}.\]</span>
The rows sum to 1 by construction, and the diagonal elements are
<span class="math display">\[S_{ii} = \frac{K(0)}{\sum_{l=1}^n K\left(\frac{x_l - x_i}{h}\right)}.\]</span>
The computation of <span class="math inline">\(\mathbf{S}\)</span> for the Gaussian kernel is implemented
using <code>outer</code> and <code>rowSums</code>.</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">kern</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span> <span class="va">x</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span>  <span class="co"># The Gaussian kernel</span>
<span class="va">Kij</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/outer.html">outer</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="fu">kern</span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span>
<span class="va">S</span> <span class="op">&lt;-</span> <span class="va">Kij</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">Kij</span><span class="op">)</span>
<span class="va">f_hat</span> <span class="op">&lt;-</span> <span class="va">S</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>
<span class="va">p_Nuuk</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">f_hat</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:smooth-Nuuk"></span>
<img src="CSwR_files/figure-html/smooth-Nuuk-1.png" alt="Nadaraya–Watson kernel smoother of the annual average temperature in Nuuk computed using the smoother matrix and the Gaussian kernel with bandwidth 10." width="70%"><p class="caption">
Figure 3.7: Nadaraya–Watson kernel smoother of the annual average temperature in Nuuk computed using the smoother matrix and the Gaussian kernel with bandwidth 10.
</p>
</div>
<p>The implementation above will work with any kernel and any sequence of <span class="math inline">\(x\)</span>-s.
In this example, the kernel is symmetric and the <span class="math inline">\(x\)</span>-s are equidistant. Exercise
<a href="bivariate.html#exr:Sdiag">3.2</a> explores how to exploit this in the computation of the
smoother matrix as well as the diagonal elements of the smoother matrix.</p>
<p>The smoother computed using <code>ksmooth</code> with bandwidth 10,
as shown in Figure <a href="bivariate.html#fig:ksmooth-Nuuk">3.6</a>, is different from the smoother
computed directly from the smoother matrix, see Figure <a href="bivariate.html#fig:smooth-Nuuk">3.7</a>.
Though both computations use the Gaussian kernel and allegedly a bandwidth of 10,
the resulting smoothers differ because <code>ksmooth</code> internally rescales the
bandwidth. The rescaling amounts to multiplying <span class="math inline">\(h\)</span> by the factor 0.3706506,
which will make the kernel have quartiles in <span class="math inline">\(\pm 0.25 h\)</span> (see also <code><a href="https://rdrr.io/r/stats/ksmooth.html">?ksmooth</a></code>).</p>
<p>The LOOCV computation is implemented as a function that computes the smoother
matrix and the corresponding LOOCV value as a function of the bandwidth.
For comparison with previous implementations the mean is computed instead of the
sum.</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">loocv</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">h</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">Kij</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/outer.html">outer</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="fu">kern</span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="va">h</span><span class="op">)</span><span class="op">)</span>
  <span class="va">S</span> <span class="op">&lt;-</span> <span class="va">Kij</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">Kij</span><span class="op">)</span>
  <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span> <span class="op">-</span> <span class="va">S</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">S</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> 
<span class="op">}</span></code></pre></div>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">h</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">0.05</span><span class="op">)</span>
<span class="va">CV</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">h</span>, <span class="va">loocv</span><span class="op">)</span>
<span class="va">h_opt</span> <span class="op">&lt;-</span> <span class="va">h</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">CV</span><span class="op">)</span><span class="op">]</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/qplot.html">qplot</a></span><span class="op">(</span><span class="va">h</span>, <span class="va">CV</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">h_opt</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-kernel-loocv"></span>
<img src="CSwR_files/figure-html/Nuuk-kernel-loocv-1.png" alt="The leave-one-out cross-validation criterion for the kernel smoother using the Gaussian kernel as a function of the bandwidth $h$." width="70%"><p class="caption">
Figure 3.8: The leave-one-out cross-validation criterion for the kernel smoother using the Gaussian kernel as a function of the bandwidth <span class="math inline">\(h\)</span>.
</p>
</div>
<p>The optimal bandwith is 1.55. We compute the resulting optimal smoother
and compare it to the smoother computed using <code>ksmooth</code>.</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Kij</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/outer.html">outer</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="fu">kern</span><span class="op">(</span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="va">h_opt</span><span class="op">)</span><span class="op">)</span>
<span class="va">S</span> <span class="op">&lt;-</span> <span class="va">Kij</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">Kij</span><span class="op">)</span>
<span class="va">f_hat</span> <span class="op">&lt;-</span> <span class="va">S</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>
<span class="va">f_hat_ksmooth</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ksmooth.html">ksmooth</a></span><span class="op">(</span>
  <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, 
  kernel <span class="op">=</span> <span class="st">"normal"</span>,
  bandwidth <span class="op">=</span> <span class="va">h_opt</span> <span class="op">/</span>  <span class="fl">0.3706506</span>,  <span class="co"># Rescaling!</span>
  x.points <span class="op">=</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">f_hat</span> <span class="op">-</span> <span class="va">f_hat_ksmooth</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -4.535467e-05  4.598776e-05</code></pre>
<p>The differences are of the order <span class="math inline">\(10^{-5}\)</span>, which is small but larger than
can be explained by rounding errors alone. In fact, <code>ksmooth</code> truncates the
tails of the Gaussian kernel to 0 beyond <span class="math inline">\(4h\)</span>. This is where the kernel becomes
less than <span class="math inline">\(0.000335 \times K(0) = 0.000134\)</span>, which for practical purposes
effectively equals zero. The truncation explains the relatively
large differences between the two results that should otherwise be equivalent. It is an
example where the approximate solution computed by <code>ksmooth</code> is acceptable because
it substantially reduces the run time.</p>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_Nuuk</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">run_mean</span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">f_hat</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-NN-plot4"></span>
<img src="CSwR_files/figure-html/Nuuk-NN-plot4-1.png" alt="Nadaraya–Watson kernel smoother of the annual average temperature in Nuuk for the optimal bandwidth using LOOCV (blue) compared to the $k$-nearest neighbor smoother with $k = 9$ (red)." width="70%"><p class="caption">
Figure 3.9: Nadaraya–Watson kernel smoother of the annual average temperature in Nuuk for the optimal bandwidth using LOOCV (blue) compared to the <span class="math inline">\(k\)</span>-nearest neighbor smoother with <span class="math inline">\(k = 9\)</span> (red).
</p>
</div>
<p>Figure <a href="bivariate.html#fig:Nuuk-NN-plot4">3.9</a> shows the optimal kernel smoother, which is actually
somewhat wiggly. It is locally more smooth than the <span class="math inline">\(k\)</span>-nearest neighbor smoother
but overall comparable to this smoother with <span class="math inline">\(k = 9\)</span>.</p>
</div>
<div id="local-regression-smoothers" class="section level3" number="3.2.2">
<h3>
<span class="header-section-number">3.2.2</span> Local regression smoothers<a class="anchor" aria-label="anchor" href="#local-regression-smoothers"><i class="fas fa-link"></i></a>
</h3>
</div>
</div>
<div id="sparse-linear-algebra" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Sparse linear algebra<a class="anchor" aria-label="anchor" href="#sparse-linear-algebra"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://Matrix.R-forge.R-project.org/">Matrix</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/bandSparse.html">bandSparse</a></span><span class="op">(</span><span class="fl">15</span>, <span class="fl">15</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## 15 x 15 sparse Matrix of class "ngCMatrix"
##                                    
##  [1,] | | | . . . . . . . . . . . .
##  [2,] | | | | . . . . . . . . . . .
##  [3,] | | | | | . . . . . . . . . .
##  [4,] . | | | | | . . . . . . . . .
##  [5,] . . | | | | | . . . . . . . .
##  [6,] . . . | | | | | . . . . . . .
##  [7,] . . . . | | | | | . . . . . .
##  [8,] . . . . . | | | | | . . . . .
##  [9,] . . . . . . | | | | | . . . .
## [10,] . . . . . . . | | | | | . . .
## [11,] . . . . . . . . | | | | | . .
## [12,] . . . . . . . . . | | | | | .
## [13,] . . . . . . . . . . | | | | |
## [14,] . . . . . . . . . . . | | | |
## [15,] . . . . . . . . . . . . | | |</code></pre>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">K</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/bandSparse.html">bandSparse</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">n</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">weights</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">3</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">5</span>, <span class="va">n</span> <span class="op">-</span> <span class="fl">4</span><span class="op">)</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span>
<span class="va">weights</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="cn">NA</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">5</span>, <span class="va">n</span> <span class="op">-</span> <span class="fl">4</span><span class="op">)</span>, <span class="cn">NA</span>, <span class="cn">NA</span><span class="op">)</span>
<span class="va">p_Nuuk</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Nuuk_year</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Year</span>, <span class="va">Temperature</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">p_Nuuk</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">K</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span> <span class="op">*</span> <span class="va">weights</span><span class="op">)</span>, 
            color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_runmeans-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>When the smoother matrix is <em>sparse</em>, matrix multiplication can be much faster.</p>
<p>We will present some benchmark comparisons below. First we compare the run time
for the matrix multiplication <code>as.numeric(K %*% Nuuk_year$Temperature) * weights</code>
using a sparse matrix (as above) with the run time
using a dense matrix. The dense matrix is given as <code>Kdense = as.matrix(K)</code>. These
run times are compared to using <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code>. In all computations, <span class="math inline">\(k = 5\)</span>.</p>
<div class="inline-figure"><img src="CSwR_files/figure-html/runmean_bench_fit-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>The difference in slopes between dense and sparse matrix multiplication should be
noted. This is the difference between <span class="math inline">\(O(n^2)\)</span> and <span class="math inline">\(O(n)\)</span> run time. The run time for
the dense matrix multiplication will not change with <span class="math inline">\(k\)</span>. For the
other two it will increase (linearly) with increasing <span class="math inline">\(k\)</span>.</p>
<p>For smoothing only once with a given smoother matrix the time to construct the matrix
should also be taken into account for fair comparison with <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code>. It turns out
that the function <code>bandSparse</code> is not optimized for the specific running mean
banded matrix, and a faster C++ function for this job is given below.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb81-1"><a href="bivariate.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span></span>
<span id="cb81-2"><a href="bivariate.html#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="kw">using</span> <span class="kw">namespace</span> Rcpp;</span>
<span id="cb81-3"><a href="bivariate.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co">// [[Rcpp::export]]</span></span>
<span id="cb81-4"><a href="bivariate.html#cb81-4" aria-hidden="true" tabindex="-1"></a>List fastBand(<span class="dt">int</span> n, <span class="dt">int</span> k) {</span>
<span id="cb81-5"><a href="bivariate.html#cb81-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> N = (<span class="dv">2</span> * k + <span class="dv">1</span>) * (n - <span class="dv">2</span> * k) + <span class="dv">3</span> * k * k + k;</span>
<span id="cb81-6"><a href="bivariate.html#cb81-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> iter = <span class="dv">0</span>;</span>
<span id="cb81-7"><a href="bivariate.html#cb81-7" aria-hidden="true" tabindex="-1"></a>  IntegerVector i(N), p(n + <span class="dv">1</span>);</span>
<span id="cb81-8"><a href="bivariate.html#cb81-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(<span class="dt">int</span> col = <span class="dv">0</span>; col &lt; n; ++col) {</span>
<span id="cb81-9"><a href="bivariate.html#cb81-9" aria-hidden="true" tabindex="-1"></a>    p[col] = iter;</span>
<span id="cb81-10"><a href="bivariate.html#cb81-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(<span class="dt">int</span> r = <span class="bu">std::</span>max(col - k, <span class="dv">0</span>); r &lt; <span class="bu">std::</span>min(col + k + <span class="dv">1</span>, n); ++r) {</span>
<span id="cb81-11"><a href="bivariate.html#cb81-11" aria-hidden="true" tabindex="-1"></a>      i[iter] = r;</span>
<span id="cb81-12"><a href="bivariate.html#cb81-12" aria-hidden="true" tabindex="-1"></a>      ++iter;</span>
<span id="cb81-13"><a href="bivariate.html#cb81-13" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb81-14"><a href="bivariate.html#cb81-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb81-15"><a href="bivariate.html#cb81-15" aria-hidden="true" tabindex="-1"></a>  p[n] = N;</span>
<span id="cb81-16"><a href="bivariate.html#cb81-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> List::create(_[<span class="st">"i"</span>] = i, _[<span class="st">"p"</span>] = p);</span>
<span id="cb81-17"><a href="bivariate.html#cb81-17" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>And then R function.</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">bandSparseFast</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>
  <span class="va">k</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span>
  <span class="va">tmp</span> <span class="op">&lt;-</span> <span class="fu">fastBand</span><span class="op">(</span><span class="va">n</span>, <span class="va">k</span><span class="op">)</span>
  <span class="fu">new</span><span class="op">(</span><span class="st">"ngCMatrix"</span>, 
      i <span class="op">=</span> <span class="va">tmp</span><span class="op">$</span><span class="va">i</span>, 
      p <span class="op">=</span> <span class="va">tmp</span><span class="op">$</span><span class="va">p</span>, 
      Dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<div class="inline-figure"><img src="CSwR_files/figure-html/fast_runmean_bench_fig-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>The construction of the sparse matrix turns out to take up much more time than the
matrix-vector multiplication. The run time is still <span class="math inline">\(O(n)\)</span>, but the constant is of
the order of a factor 16 larger than for <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code>. With the faster construction of
the sparse matrix, the constant is reduced to being
of the order 5 larger than for <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code>. For small <span class="math inline">\(n\)</span> there is some overhead
from the constructor of the sparse matrix object even for the faster algorithm.</p>
<p>If you implement an algorithm (like a smoother) using linear algebra (e.g. a
matrix-vector product) then sparse matrix numerical methods can be useful
compared to dense matrix numerical methods. The Matrix package for R implements
sparse matrices, and you should always attempt to use methods for constructing
the sparse matrix that avoid dense intermediates. But even with a special
purpose constructor of a sparse band matrix, sparse linear algebra cannot
compete with optimized special purpose algorithms like <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> or a
C++ implementation of <code>run_mean()</code>. The <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> function even works more
generally for kernels (weights) with <em>equidistant</em> data.</p>
<p>We conclude this section by verifying that <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> actually computes
the running mean up to numerical errors.</p>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/qplot.html">qplot</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span>, 
      <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">K</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span> <span class="op">*</span> <span class="va">weights</span> <span class="op">-</span> 
        <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span><span class="st">"Difference"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="CSwR_files/figure-html/runmean_accuracy_fig-1.png" width="70%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/all.html">all</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">K</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span> <span class="op">*</span> <span class="va">weights</span> <span class="op">==</span> 
      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html">all.equal</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">K</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span> <span class="op">*</span> <span class="va">weights</span>, 
          <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/identical.html">identical</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">K</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span> <span class="op">*</span> <span class="va">weights</span>, 
          <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
</div>
<div id="onb" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Orthogonal basis expansions<a class="anchor" aria-label="anchor" href="#onb"><i class="fas fa-link"></i></a>
</h2>
<div id="polynomial-expansions" class="section level3" number="3.4.1">
<h3>
<span class="header-section-number">3.4.1</span> Polynomial expansions<a class="anchor" aria-label="anchor" href="#polynomial-expansions"><i class="fas fa-link"></i></a>
</h3>
<p>Degree 19 polynomial fitted to the temperature data.</p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_poly_fig-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>We can extract the model matrix from the lm-object.</p>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">intercept</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>, <span class="va">n</span><span class="op">)</span>  <span class="co"># To make intercept column have norm one</span>
<span class="va">polylm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Temperature</span> <span class="op">~</span> <span class="va">intercept</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">Year</span>, <span class="fl">19</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span>, data <span class="op">=</span> <span class="va">Nuuk_year</span><span class="op">)</span>
<span class="va">Phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">polylm</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:model-matrix-fig"></span>
<img src="CSwR_files/figure-html/model-matrix-fig-1.png" alt="The model matrix columns as functions" width="100%"><p class="caption">
Figure 3.10: The model matrix columns as functions
</p>
</div>
<p>The model matrix is (almost) orthogonal, and estimation becomes quite simple.
With an orthogonal model matrix the normal equation reduces to the estimate
<span class="math display">\[\hat{\beta} = \Phi^T Y\]</span>
since <span class="math inline">\(\Phi^T \Phi = I\)</span>. The predicted (or fitted) values are <span class="math inline">\(\Phi \Phi^T Y\)</span>
with smoother matrix <span class="math inline">\(\mathbf{S} = \Phi \Phi^T\)</span> being a projection.</p>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fl">1</span><span class="op">]</span></code></pre></div>
<pre><code>##       intercept poly(Year, 19)1 poly(Year, 19)2 poly(Year, 19)3 poly(Year, 19)4 poly(Year, 19)5 
##     -17.2469646       4.9002430      -1.7968913       0.8175400       5.9668689       1.4265091 
## poly(Year, 19)6 poly(Year, 19)7 poly(Year, 19)8 poly(Year, 19)9 
##      -1.9258864      -0.2523581      -2.1355117      -0.8046267</code></pre>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">polylm</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></code></pre></div>
<pre><code>##       intercept poly(Year, 19)1 poly(Year, 19)2 poly(Year, 19)3 poly(Year, 19)4 poly(Year, 19)5 
##     -17.2469646       4.9002430      -1.7968913       0.8175400       5.9668689       1.4265091 
## poly(Year, 19)6 poly(Year, 19)7 poly(Year, 19)8 poly(Year, 19)9 
##      -1.9258864      -0.2523581      -2.1355117      -0.8046267</code></pre>
<p>With homogeneous variance
<span class="math display">\[\hat{\beta}_i \overset{\text{approx}}{\sim} \mathcal{N}(\beta_i, \sigma^2),\]</span>
and for <span class="math inline">\(\beta_i = 0\)</span> we have <span class="math inline">\(P(|\hat{\beta}_i| \geq 1.96\sigma) \simeq 0.05.\)</span></p>
<p>Thresholding:</p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_poly_threshold-1.png" width="70%" style="display: block; margin: auto;"></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-poly-fig2"></span>
<img src="CSwR_files/figure-html/Nuuk-poly-fig2-1.png" alt="Polynomial fit using all 19 basis functions (blue) and using a degree 5 polynomial (red)." width="70%"><p class="caption">
Figure 3.11: Polynomial fit using all 19 basis functions (blue) and using a degree 5 polynomial (red).
</p>
</div>
</div>
<div id="fourier-expansions" class="section level3" number="3.4.2">
<h3>
<span class="header-section-number">3.4.2</span> Fourier expansions<a class="anchor" aria-label="anchor" href="#fourier-expansions"><i class="fas fa-link"></i></a>
</h3>
<p>Introducing
<span class="math display">\[x_{k,m} = \frac{1}{\sqrt{n}} e^{2 \pi i k m / n},\]</span>
then</p>
<p><span class="math display">\[\sum_{k=0}^{n-1} |x_{k,m}|^2 = 1\]</span></p>
<p>and for <span class="math inline">\(m_1 \neq m_2\)</span>
<span class="math display">\[\sum_{k=0}^{n-1} x_{k,m_1}\overline{x_{k,m_2}} = 0\]</span></p>
<p>Thus <span class="math inline">\(\Phi = (x_{k,m})_{k,m}\)</span> is an <span class="math inline">\(n \times n\)</span> unitary matrix;
<span class="math display">\[\Phi^*\Phi = I\]</span>
where <span class="math inline">\(\Phi^*\)</span> is the conjugate transposed of <span class="math inline">\(\Phi\)</span>.</p>
<p><span class="math inline">\(\hat{\beta} = \Phi^* y\)</span> is the <em>discrete Fourier transform</em> of <span class="math inline">\(y\)</span>.
It is the basis coefficients in the orthonormal basis given by <span class="math inline">\(\Phi\)</span>;
<span class="math display">\[y_k = \frac{1}{\sqrt{n}} \sum_{m=0}^{n-1} \hat{\beta}_m  e^{2 \pi i k m / n}\]</span></p>
<p>or <span class="math inline">\(y = \Phi \hat{\beta}.\)</span></p>
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/outer.html">outer</a></span><span class="op">(</span>
  <span class="fl">0</span><span class="op">:</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>, 
  <span class="fl">0</span><span class="op">:</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>, 
  <span class="kw">function</span><span class="op">(</span><span class="va">k</span>, <span class="va">m</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fl">2</span> <span class="op">*</span> <span class="va">pi</span> <span class="op">*</span> <span class="fl">1i</span> <span class="op">*</span> <span class="op">(</span><span class="va">k</span> <span class="op">*</span> <span class="va">m</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<p>The matrix <span class="math inline">\(\Phi\)</span> generates an interesting pattern.</p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Fourier_fig-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Columns in the matrix <span class="math inline">\(\Phi\)</span>:</p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Fourier_basis_fig-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>We can estimate by matrix multiplication</p>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">betahat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/complex.html">Conj</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span> <span class="co"># t(Phi) = Phi for Fourier bases</span>
<span class="va">betahat</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">4</span>, <span class="fl">73</span>, <span class="va">n</span><span class="op">:</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></code></pre></div>
<pre><code>## [1] -17.2469646+0.0000000i  -2.4642887+2.3871189i   3.5481329+0.9099226i   1.6721444+0.7413580i
## [5]   0.0321232+0.7089991i  -2.4642887-2.3871189i   3.5481329-0.9099226i   1.6721444-0.7413580i</code></pre>
<p>For real <span class="math inline">\(y\)</span> it holds that <span class="math inline">\(\hat{\beta}_0\)</span> is real, and the symmetry
<span class="math display">\[\hat{\beta}_{n-m} = \hat{\beta}_m^*\]</span>
holds for <span class="math inline">\(m = 1, \ldots, n - 1\)</span>. (For <span class="math inline">\(n\)</span> even, <span class="math inline">\(\hat{\beta}_{n/2}\)</span> is real too).</p>
<p>Modulus distribution:</p>
<p>Note that for <span class="math inline">\(m \neq 0, n/2\)</span>, <span class="math inline">\(\beta_m = 0\)</span> and <span class="math inline">\(y \sim \mathcal{N}(\Phi\beta, \sigma^2 I_n)\)</span> then<br><span class="math display">\[(\mathrm{Re}(\hat{\beta}_m), \mathrm{Im}(\hat{\beta}_m))^T \sim \mathcal{N}\left(0, \frac{\sigma^2}{2} I_2\right),\]</span></p>
<p>hence
<span class="math display">\[|\hat{\beta}_m|^2 = \mathrm{Re}(\hat{\beta}_m)^2 + \mathrm{Im}(\hat{\beta}_m)^2 \sim \frac{\sigma^2}{2} \chi^2_2,\]</span>
that is, <span class="math inline">\(P(|\hat{\beta}_m| \geq 1.73 \sigma) = 0.05.\)</span> There is a clear case
of multiple testing if we use this threshold at face value, and we would expect
around <span class="math inline">\(0.05 \times n/2\)</span> false positive if there is no signal at all. Lowering
the probability using the Bonferroni correction yields a threshold of around <span class="math inline">\(2.7 \sigma\)</span>
instead.</p>
<p>Thresholding Fourier:</p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_Fourier_threshold-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>The coefficients are not independent (remember the symmetry), and one can alternatively
consider
<span class="math display">\[\hat{\gamma}_m = \sqrt{2} \mathrm{Re}(\hat{\beta}_m) \quad \text{and} \quad 
\hat{\gamma}_{n' + m} = - \sqrt{2} \mathrm{Im}(\hat{\beta}_m)\]</span>
for <span class="math inline">\(1 \leq m &lt; n / 2\)</span>. Here <span class="math inline">\(n' = \lfloor n / 2 \rfloor\)</span>. Here, <span class="math inline">\(\hat{\gamma}_0 = \hat{\beta}_0\)</span>, and <span class="math inline">\(\hat{\gamma}_{n/2} = \hat{\beta}_{n/2}\)</span> for <span class="math inline">\(n\)</span> even.</p>
<p>These coefficients are the coefficients in a real cosine,
<span class="math inline">\(\sqrt{2} \cos(2\pi k m / n)\)</span>, and sine, <span class="math inline">\(\sqrt{2} \sin(2\pi k m / n)\)</span>, basis
expansion, and they are i.i.d.
<span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span> distributed.</p>
<p>Thresholding Fourier:</p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_Fourier_threshold2-1.png" width="70%" style="display: block; margin: auto;"></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:NuukFourierthresholdfig"></span>
<img src="CSwR_files/figure-html/NuukFourierthresholdfig-1.png" alt="Fourier based smoother by thresholding (blue) and polynomial fit of degree 5 (red)." width="70%"><p class="caption">
Figure 3.12: Fourier based smoother by thresholding (blue) and polynomial fit of degree 5 (red).
</p>
</div>
<p>What is the point using the discrete Fourier transform?
The point is that the discrete Fourier transform can be computed via the
<em>fast Fourier transform</em> (FFT), which has an <span class="math inline">\(O(n\log(n))\)</span> time complexity.
The FFT works optimally for <span class="math inline">\(n = 2^p\)</span>.</p>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/fft.html">fft</a></span><span class="op">(</span><span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -17.246965+0.000000i  -2.464289+2.387119i   3.548133+0.909923i   1.672144+0.741358i</code></pre>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">betahat</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span></code></pre></div>
<pre><code>## [1] -17.246965+0.000000i  -2.464289+2.387119i   3.548133+0.909923i   1.672144+0.741358i</code></pre>
</div>
</div>
<div id="splines" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Splines<a class="anchor" aria-label="anchor" href="#splines"><i class="fas fa-link"></i></a>
</h2>
<p>In <a href="bivariate.html#onb">the previous section</a> orthogonality of basis functions played an
important role for computing basis function expansions efficiently as well
as for the statistical assessment of estimated coefficients. This section
will deal with bivariate smoothing via basis functions that are not
necessarily orthogonal.</p>
<p>Though some of the material of this section will apply to any choice of
basis, we restrict attention to splines and consider almost
exclusively the widely used B-splines (the “B” is for basis).</p>
<div id="smoothing-splines" class="section level3" number="3.5.1">
<h3>
<span class="header-section-number">3.5.1</span> Smoothing splines<a class="anchor" aria-label="anchor" href="#smoothing-splines"><i class="fas fa-link"></i></a>
</h3>
<p>To motivate splines we briefly consider the following penalized least squares
criterion for finding a smooth approximation to bivariate data: minimize
<span class="math display" id="eq:spline-criterion">\[\begin{equation}
L(f) = \sum_{i=1}^n (y_i - f(x_i))^2 + \lambda \|f''\|_2^2
\tag{3.1}
\end{equation}\]</span>
over all twice differentiable functions <span class="math inline">\(f\)</span>. The first term is the standard
squared error, and we can easily find a smooth function interpolating the
<span class="math inline">\(y\)</span>-values (if all the <span class="math inline">\(x\)</span>-values are different), which will thus drive
the squared error to 0. The squared 2-norm regularizes the minimization
problem so that the minimizer finds a balance between interpolation and
having a small second derivative (note that <span class="math inline">\(\|f''\|_2 = 0\)</span> if and only if <span class="math inline">\(f\)</span> is an
affine function). The tuning parameter <span class="math inline">\(\lambda\)</span> controls this balance.</p>
<p>It is possible to show that the minimizer of <a href="bivariate.html#eq:spline-criterion">(3.1)</a> is a
<a href="https://en.wikipedia.org/wiki/Spline_(mathematics)">natural cubic spline</a> with
<em>knots</em> in the data points <span class="math inline">\(x_i\)</span>. That is, the spline is a <span class="math inline">\(C^2\)</span>-function
that equals a third degree polynomial in between the knots. At the knots,
the two polynomials that meet fit together up to the second derivative, but they
may differ on the third derivative. That the solution is <em>natural</em> means
that it has zero second and third derivative at and beyond the two boundary knots.</p>
<p>It is not particularly difficult to show that the space of natural cubic
splines is a vector space of dimension <span class="math inline">\(n\)</span> if all the <span class="math inline">\(x\)</span>-values are different.
It is therefore possible to find a basis of splines, <span class="math inline">\(\varphi_1, \ldots, \varphi_n\)</span>,
such that the <span class="math inline">\(f\)</span> that minimizes <a href="bivariate.html#eq:spline-criterion">(3.1)</a> is of the form
<span class="math display">\[f = \sum_{i=1}^n \beta_i \varphi_i.\]</span>
What is remarkable about this is that the basis (and the finite dimensional
vector space it spans) doesn’t depend upon the <span class="math inline">\(y\)</span>-values. Though the
optimization is over an infinite dimensional space, the penalization ensures
that the minimizer is always in the same finite dimensional space nomatter
what <span class="math inline">\(y_1, \ldots, y_n\)</span> are. Moreover, since <a href="bivariate.html#eq:spline-criterion">(3.1)</a> is
a quite natural criterion to minimize to find a smooth function fitting
the bivariate data, splines appear as good candidates
for producing such smooth fits. On top of that, splines have several
computational advantages and are widely used.</p>
<p>If we let <span class="math inline">\(\hat{f}_i = \hat{f}(x_i)\)</span> with <span class="math inline">\(\hat{f}\)</span> the minimizer of
<a href="bivariate.html#eq:spline-criterion">(3.1)</a>, we have in vector notation that
<span class="math display">\[\hat{\mathbf{f}} = \boldsymbol{\Phi}\hat{\beta}\]</span>
with <span class="math inline">\(\boldsymbol{\Phi}_{ij} = \varphi_j(x_i)\)</span>. The minimizer
can be found by observing that</p>
<p><span class="math display">\[\begin{align}
 L(\mathbf{f}) &amp; = (\mathbf{y} - \mathbf{f})^T (\mathbf{y} - \mathbf{f}) + \lambda \| f'' \|_2^2 \\
&amp; = ( \mathbf{y} -  \boldsymbol{\Phi}\beta)^T (\mathbf{y} -  \boldsymbol{\Phi}\beta) + \lambda \beta^T \mathbf{\Omega} \beta
\end{align}\]</span></p>
<p>where
<span class="math display">\[\mathbf{\Omega}_{ij} = \langle \varphi_i'', \varphi_j'' \rangle = 
\int  \varphi_i''(z) \varphi_j''(z) \mathrm{d}z.\]</span>
The matrix <span class="math inline">\(\mathbf{\Omega}\)</span> is positive semidefinite by construction, and
we refer to it as the <em>penalty matrix</em>. It induces a seminorm on <span class="math inline">\(\mathbb{R}^n\)</span>
so that we can express the seminorm, <span class="math inline">\(\|f''\|_2\)</span>, of <span class="math inline">\(f\)</span> in terms of the
parameters in the basis expansion using <span class="math inline">\(\varphi_i\)</span>.</p>
<p>This is a standard penalized least squares problem, whose solution is
<span class="math display">\[\hat{\beta} = (\boldsymbol{\Phi}^T \boldsymbol{\Phi} + \lambda \mathbf{\Omega})^{-1}\boldsymbol{\Phi}^T  \mathbf{y}\]</span>
and with resulting smoother
<span class="math display">\[\hat{\mathbf{f}} = \underbrace{\boldsymbol{\Phi} ((\boldsymbol{\Phi}^T \boldsymbol{\Phi} + \lambda \mathbf{\Omega})^{-1}\boldsymbol{\Phi}^T}_{\mathbf{S}_{\lambda}} \mathbf{y}.\]</span>
This linear smoother with smoothing matrix <span class="math inline">\(\mathbf{S}_{\lambda}\)</span> based
on natural cubic splines gives what is known as a
<a href="https://en.wikipedia.org/wiki/Smoothing_spline">smoothing spline</a> that
minimizes <a href="bivariate.html#eq:spline-criterion">(3.1)</a>. We will pursue
spline based smoothing by minimizing <a href="bivariate.html#eq:spline-criterion">(3.1)</a> but
using various B-spline bases that may have more or less than <span class="math inline">\(n\)</span> elements.
For the linear algebra, it actually doesn’t matter if we use a spline
basis or any other basis – as long as
<span class="math inline">\(\boldsymbol{\Phi}_{ij} = \varphi_j(x_i)\)</span> and <span class="math inline">\(\mathbf{\Omega}\)</span> is
given in terms of <span class="math inline">\(\varphi''_i\)</span> as above.</p>
</div>
<div id="splines-in-r" class="section level3" number="3.5.2">
<h3>
<span class="header-section-number">3.5.2</span> Splines in R<a class="anchor" aria-label="anchor" href="#splines-in-r"><i class="fas fa-link"></i></a>
</h3>
<p>The splines package in R implements some of the basic functions needed to work
with splines. In particular, the <code><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign()</a></code> function that computes evaluations
of B-splines and their derivatives.</p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">splines</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Note the specification of repeated boundary knots</span>
<span class="va">knots</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0.2</span><span class="op">)</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>
<span class="va">xx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0.005</span><span class="op">)</span>
<span class="va">B_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign</a></span><span class="op">(</span><span class="va">knots</span>, <span class="va">xx</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/matplot.html">matplot</a></span><span class="op">(</span><span class="va">xx</span>, <span class="va">B_splines</span>, type <span class="op">=</span> <span class="st">"l"</span>, lty <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:splines"></span>
<img src="CSwR_files/figure-html/splines-1.png" alt="B-spline basis as computed by `splineDesign()`." width="70%"><p class="caption">
Figure 3.13: B-spline basis as computed by <code><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign()</a></code>.
</p>
</div>
<p>The basis shown in Figure <a href="bivariate.html#fig:splines">3.13</a> is an example of a cubic B-spline
basis with the 11 inner knots <span class="math inline">\(0, 0.1, \ldots, 0.9, 1\)</span>. The repeated
boundary knots control how the spline basis behaves close to the boundaries
of the interval. This basis has 13 basis functions, not 11, and spans a
larger space than the space of <em>natural</em> cubic splines. It is
possible to compute a basis based on B-splines for the natural cubic splines
using the function <code>ns</code>, but for all practical purposes this is not
important, and we will work exclusively with the B-spline basis itself.</p>
<p>The computation of the penalty matrix <span class="math inline">\(\mathbf{\Omega}\)</span> constitutes a
practical problem, but observing that <span class="math inline">\(\varphi''_i\)</span> is an affine
function in between knots leads to a simple way of
computing <span class="math inline">\(\mathbf{\Omega}_{ij}\)</span>. Letting <span class="math inline">\(g_{ij} = \varphi''_i \varphi''_j\)</span>
it holds that <span class="math inline">\(g_{ij}\)</span> is quadratic between two consecutive knots <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>,
in which case
<span class="math display">\[\int_a^b g_{ij}(z) \mathrm{d}z = \frac{b - a}{6}\left(g_{ij}(a) + 4 g_{ij}\left(\frac{a + b}{2}\right) + g_{ij}(b)\right).\]</span>
This identity is behind <a href="https://en.wikipedia.org/wiki/Simpson%27s_rule">Simpson’s rule</a>
for numerical integration, and the fact that this is an identity for quadratic
polynomials, and not an approximation, means that Simpson’s rule
applied appropriately leads to exact computation of
<span class="math inline">\(\mathbf{\Omega}_{ij}\)</span>. All we need is the ability to evaluate
<span class="math inline">\(\varphi''_i\)</span> at certain points, and <code><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign()</a></code> can be used for that.</p>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pen_mat</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">knots</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>, <span class="va">inner_knots</span><span class="op">)</span><span class="op">)</span>
  <span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/diff.html">diff</a></span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span>  <span class="co"># The vector of knot differences; b - a </span>
  <span class="va">g_ab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign</a></span><span class="op">(</span><span class="va">knots</span>, <span class="va">inner_knots</span>, derivs <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> 
  <span class="va">knots_mid</span> <span class="op">&lt;-</span> <span class="va">inner_knots</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span><span class="op">]</span> <span class="op">+</span> <span class="va">d</span> <span class="op">/</span> <span class="fl">2</span>
  <span class="va">g_ab_mid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign</a></span><span class="op">(</span><span class="va">knots</span>, <span class="va">knots_mid</span>, derivs <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
  <span class="va">g_a</span> <span class="op">&lt;-</span> <span class="va">g_ab</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">g_ab</span><span class="op">)</span>, <span class="op">]</span>
  <span class="va">g_b</span> <span class="op">&lt;-</span> <span class="va">g_ab</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span>
  <span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">d</span> <span class="op">*</span> <span class="va">g_a</span>,  <span class="va">g_a</span><span class="op">)</span> <span class="op">+</span> 
      <span class="fl">4</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">d</span> <span class="op">*</span> <span class="va">g_ab_mid</span>, <span class="va">g_ab_mid</span><span class="op">)</span> <span class="op">+</span> 
      <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">d</span> <span class="op">*</span> <span class="va">g_b</span>, <span class="va">g_b</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="fl">6</span> 
<span class="op">}</span></code></pre></div>
<p>It is laborious to write good tests of <code>pen_mat()</code>. We would have to work out a
set of example matrices by other means, e.g. by hand. Alternatively, we can
compare to a simpler numerical integration technique using Riemann sums.</p>
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">spline_deriv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0.5</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, 
  <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1e-5</span><span class="op">)</span>, 
  derivs <span class="op">=</span> <span class="fl">2</span>
<span class="op">)</span>
<span class="va">Omega_numeric</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">spline_deriv</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="fl">1e-5</span>  <span class="co"># Right Riemann sums</span>
<span class="va">Omega</span> <span class="op">&lt;-</span> <span class="fu">pen_mat</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">Omega_numeric</span> <span class="op">/</span> <span class="va">Omega</span></code></pre></div>
<pre><code>##           [,1]      [,2]     [,3]     [,4]     [,5]
## [1,] 0.9999700 0.9999673 0.999940 1.000000      NaN
## [2,] 0.9999673 0.9999663 0.999955 1.000000 1.000000
## [3,] 0.9999400 0.9999550 1.000000 1.000045 1.000060
## [4,] 1.0000000 1.0000000 1.000045 1.000034 1.000033
## [5,]       NaN 1.0000000 1.000060 1.000033 1.000030</code></pre>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="op">(</span><span class="va">Omega_numeric</span> <span class="op">-</span> <span class="va">Omega</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">Omega</span> <span class="op">+</span> <span class="fl">0.001</span><span class="op">)</span><span class="op">)</span>  <span class="co">#  Relative error</span></code></pre></div>
<pre><code>## [1] -5.99967e-05  5.99983e-05</code></pre>
<p>And we should also test an example with non-equidistant knots.</p>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">spline_deriv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.65</span>, <span class="fl">0.7</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, 
  <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1e-5</span><span class="op">)</span>, 
  derivs <span class="op">=</span> <span class="fl">2</span>
<span class="op">)</span>
<span class="va">Omega_numeric</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">spline_deriv</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="fl">1e-5</span>  <span class="co"># Right Riemann sums</span>
<span class="va">Omega</span> <span class="op">&lt;-</span> <span class="fu">pen_mat</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.65</span>, <span class="fl">0.7</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="op">(</span><span class="va">Omega_numeric</span> <span class="op">-</span> <span class="va">Omega</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">Omega</span> <span class="op">+</span> <span class="fl">0.001</span><span class="op">)</span><span class="op">)</span> <span class="co"># Relative error</span></code></pre></div>
<pre><code>## [1] -0.0001607084  0.0002545494</code></pre>
<p>These examples indicate that <code>pen_mat()</code> computes <span class="math inline">\(\mathbf{\Omega}\)</span> correctly,
in particular as increasing the Riemann sum precision by
lowering the number <span class="math inline">\(10^{-5}\)</span> will decrease the relative error (not shown).
Of course, correctness ultimately depends on <code><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign()</a></code> computing
the correct second derivatives, which hasn’t been tested here.</p>
<p>We can also test how our implementation of smoothing splines works
on data. We do this here by implementing the matrix-algebra directly
for computing <span class="math inline">\(\mathbf{S}_{\lambda} \mathbf{y}\)</span>.</p>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">inner_knots</span> <span class="op">&lt;-</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>
<span class="va">Phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>, <span class="va">inner_knots</span><span class="op">)</span>, <span class="va">inner_knots</span><span class="op">)</span>
<span class="va">Omega</span> <span class="op">&lt;-</span> <span class="fu">pen_mat</span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span>
<span class="va">smoother</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span> 
  <span class="va">Phi</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span>
    <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span> <span class="op">+</span> <span class="va">lambda</span> <span class="op">*</span> <span class="va">Omega</span>, 
    <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>
  <span class="op">)</span>
<span class="va">p_Nuuk</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">smoother</span><span class="op">(</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span>      <span class="co"># Undersmooth</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">smoother</span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>     <span class="co"># Smooth</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu">smoother</span><span class="op">(</span><span class="fl">100000</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"purple"</span><span class="op">)</span>  <span class="co"># Oversmooth</span></code></pre></div>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk-smooth-spline-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>Smoothing splines can be computed using the R function <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code>
from the stats package. It is possible to manually specify the amount of
smoothing using one of the arguments <code>lambda</code>, <code>spar</code> or <code>df</code>
(the latter being the trace of the smoother matrix). However,
due to internal differences from the <code><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign()</a></code> basis
above, the <code>lambda</code> argument to <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code> does not match the
<span class="math inline">\(\lambda\)</span> parameter above.</p>
<p>If the amount of smoothing is not manually set, <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code> chooses
<span class="math inline">\(\lambda\)</span> by <em>generalized cross validation</em> (GCV), which minimizes
<span class="math display">\[\mathrm{GCV} = \sum_{i=1}^n \left(\frac{y_i - \hat{f}_i}{1 - \mathrm{df} / n}\right)^2,\]</span>
where
<span class="math display">\[\mathrm{df} = \mathrm{trace}(\mathbf{S}) = \sum_{i=1}^n S_{ii}.\]</span>
GCV corresponds to LOOCV with the diagonal entries, <span class="math inline">\(S_{ii}\)</span>,
replaced by their average <span class="math inline">\(\mathrm{df} / n\)</span>. The main reason for
using GCV over LOOCV is that for some smoothers, such as the
spline smoother, it is possible to compute the trace <span class="math inline">\(\mathrm{df}\)</span> easily
without computing <span class="math inline">\(\mathbf{S}\)</span> or even its diagonal elements.</p>
<p>To compare our results to <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code> we optimize the GCV criterion.
First we implement a function that computes GCV for a fixed value of <span class="math inline">\(\lambda\)</span>.
Here the implementation is relying on computing the smoother matrix, but
this is not the most efficient implementation. Section <a href="bivariate.html#efficient-splines">3.5.3</a>
provides a diagonalization of the smoother matrix jointly in the tuning
parameters. This representation allows for efficient computation
with splines, and it will become clear why it is not necessary to compute
<span class="math inline">\(\mathbf{S}\)</span> or even its diagonal elements. The trace is nevertheless
easily computable <span class="math inline">\(\mathbf{S}\)</span>.</p>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">gcv</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span>, <span class="va">y</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">S</span> <span class="op">&lt;-</span> <span class="va">Phi</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span> <span class="op">+</span> <span class="va">lambda</span> <span class="op">*</span> <span class="va">Omega</span>, <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span><span class="op">)</span>
  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">S</span><span class="op">)</span><span class="op">)</span>  <span class="co"># The trace of the smoother matrix</span>
  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">S</span> <span class="op">%*%</span> <span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">df</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> 
<span class="op">}</span></code></pre></div>
<p>Then we apply this function to a grid of <span class="math inline">\(\lambda\)</span>-values and
choose the value of <span class="math inline">\(\lambda\)</span> that minimizes GCV.</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">250</span>, <span class="fl">2</span><span class="op">)</span>
<span class="va">GCV</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">lambda</span>, <span class="va">gcv</span>, y <span class="op">=</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span><span class="op">)</span>
<span class="va">lambda_opt</span> <span class="op">&lt;-</span> <span class="va">lambda</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">GCV</span><span class="op">)</span><span class="op">]</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/qplot.html">qplot</a></span><span class="op">(</span><span class="va">lambda</span>, <span class="va">GCV</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">lambda_opt</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-spline-gcv"></span>
<img src="CSwR_files/figure-html/Nuuk-spline-gcv-1.png" alt="The generalized cross-validation criterion for smoothing splines as a function of the tuning parameter $\lambda$." width="70%"><p class="caption">
Figure 3.14: The generalized cross-validation criterion for smoothing splines as a function of the tuning parameter <span class="math inline">\(\lambda\)</span>.
</p>
</div>
<p>Finally, we can visualize the resulting smoothing spline.</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">smooth_opt</span> <span class="op">&lt;-</span> <span class="va">Phi</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span> <span class="op">+</span> <span class="va">lambda_opt</span> <span class="op">*</span> <span class="va">Omega</span>, 
  <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>
<span class="op">)</span>
<span class="va">p_Nuuk</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">smooth_opt</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-spline-opt"></span>
<img src="CSwR_files/figure-html/Nuuk-spline-opt-1.png" alt="The smoothing spline that minimizes GCV over the tuning parameter $\lambda$" width="70%"><p class="caption">
Figure 3.15: The smoothing spline that minimizes GCV over the tuning parameter <span class="math inline">\(\lambda\)</span>
</p>
</div>
<p>The smoothing spline that we found by minimizing GCV can be compared to
the smoothing spline that <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code> computes by minimizing GCV
as well.</p>

<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">smooth_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline</a></span><span class="op">(</span>
  <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span>, 
  <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span>, 
  all.knots <span class="op">=</span> <span class="cn">TRUE</span>        <span class="co"># Don't use heuristic</span>
<span class="op">)</span>  
<span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">smooth_splines</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="va">smooth_opt</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -0.000775662  0.001072587</code></pre>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_Nuuk</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">smooth_splines</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Nuuk-spline-opt2"></span>
<img src="CSwR_files/figure-html/Nuuk-spline-opt2-1.png" alt="The smoothing spline that minimizes GCV as computed by smooth.spline()." width="70%"><p class="caption">
Figure 3.16: The smoothing spline that minimizes GCV as computed by <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code>.
</p>
</div>
<p>The differences between the smoothing spline computed by our implementation
and by <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code> is hardly detectable visually, and they are at most
of the order <span class="math inline">\(10^{-3}\)</span> as computed above. It is possible to further
decrease the differences by finding the optimal value of <span class="math inline">\(\lambda\)</span> with a
higher precision, but we will not pursue this here.</p>
</div>
<div id="efficient-splines" class="section level3" number="3.5.3">
<h3>
<span class="header-section-number">3.5.3</span> Efficient computation with splines<a class="anchor" aria-label="anchor" href="#efficient-splines"><i class="fas fa-link"></i></a>
</h3>
<p>Using the full B-spline basis with knots in every observation is computationally
heavy and from a practical viewpoint unnecessary. Smoothing using B-splines
is therefore often done using a knot-selection heuristic that selects much fewer
knots than <span class="math inline">\(n\)</span>, in particular if <span class="math inline">\(n\)</span> is large. This is also what <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code>
does unless <code>all.knots = TRUE</code>. The heuristic for selecting
the number of knots is a bit complicated, but it is implemented in the function <code><a href="https://rdrr.io/r/stats/smooth.spline.html">.nknots.smspl()</a></code>,
which can be inspected for details. Once the number of knots gets above 200 it
grows extremely slowly with <span class="math inline">\(n\)</span>. With the number of knots selected,
a common heuristic for selecting their position is to use the quantiles of
the distribution of the <span class="math inline">\(x\)</span>-values. That is, with 9 knots, say, the knots
are positioned in the deciles (0.1-quantile, 0.2-quantile etc.). This is
effectively also what <code><a href="https://rdrr.io/r/stats/smooth.spline.html">smooth.spline()</a></code> does, and this heuristic places most of
the knots where we have most of the data points.</p>
<p>Having implemented a knot-selection heuristic that results in <span class="math inline">\(p\)</span> B-spline
basis functions, the matrix <span class="math inline">\(\Phi\)</span> will be <span class="math inline">\(n \times p\)</span>, typically with <span class="math inline">\(p &lt; n\)</span>
and with <span class="math inline">\(\Phi\)</span> of full rank <span class="math inline">\(p\)</span>. In this case we derive a way of computing the
smoothing spline that is computationally more efficient and numerically more
stable than relying on the matrix-algebraic solution above. This is particularly
so when we need to compute the smoother for many different <span class="math inline">\(\lambda\)</span>-s to optimize
the smoother. As we will show, we are
effectively computing a simultaneous diagonalization of the (symmetric) smoother
matrix <span class="math inline">\(\mathbf{S}_{\lambda}\)</span> for all values of <span class="math inline">\(\lambda\)</span>.</p>
<p>The matrix <span class="math inline">\(\Phi\)</span> has a singular value decomposition
<span class="math display">\[\Phi = \mathbf{U} D \mathbf{V}^T\]</span>
where <span class="math inline">\(D\)</span> is diagonal with entries <span class="math inline">\(d_1 \geq d_2 \geq \ldots \geq d_p &gt; 0\)</span>,
<span class="math inline">\(\mathbf{U}\)</span> is <span class="math inline">\(n \times p\)</span>, <span class="math inline">\(\mathbf{V}\)</span> is <span class="math inline">\(p \times p\)</span> and both are orthogonal matrices.
This means that
<span class="math display">\[\mathbf{U}^T \mathbf{U} = \mathbf{V}^T \mathbf{V} = \mathbf{V} \mathbf{V}^T =  I\]</span>
is the <span class="math inline">\(p \times p\)</span> dimensional identity matrix. We find that</p>
<p><span class="math display">\[\begin{align}
\mathbf{S}_{\lambda} &amp; =  \mathbf{U}D\mathbf{V}^T(\mathbf{V}D^2\mathbf{V}^T + \lambda \mathbf{\Omega})^{-1}
\mathbf{V}D\mathbf{U}^T \\
&amp; = \mathbf{U}D (D^2 + \lambda  \mathbf{V}^T \mathbf{\Omega} \mathbf{V})^{-1} D \mathbf{U}^T \\
&amp; = \mathbf{U} (I + \lambda D^{-1} \mathbf{V}^T \mathbf{\Omega} \mathbf{V} D^{-1})^{-1} \mathbf{U}^T \\
&amp; = \mathbf{U}(I + \lambda  \widetilde{\mathbf{\Omega}})^{-1} \mathbf{U}^T,
\end{align}\]</span></p>
<p>where
<span class="math inline">\(\widetilde{\mathbf{\Omega}} = D^{-1} \mathbf{V}^T \mathbf{\Omega} \mathbf{V} D^{-1}\)</span> is
a positive semidefinite <span class="math inline">\(p \times p\)</span> matrix. By diagonalization,
<span class="math display">\[\widetilde{\mathbf{\Omega}} = \mathbf{W} \Gamma \mathbf{W}^T,\]</span>
where <span class="math inline">\(\mathbf{W}\)</span> is orthogonal and <span class="math inline">\(\Gamma\)</span> is a diagonal matrix with nonnegative
values in the diagonal, and we find that</p>
<p><span class="math display">\[\begin{align}
\mathbf{S}_{\lambda} &amp; = \mathbf{U} \mathbf{W} (I + \lambda  \Gamma)^{-1}  \mathbf{W}^T  \mathbf{U}^T \\
&amp; = \widetilde{\mathbf{U}}  (I + \lambda  \Gamma)^{-1} \widetilde{\mathbf{U}}^T
\end{align}\]</span></p>
<p>where <span class="math inline">\(\widetilde{\mathbf{U}} = \mathbf{U} \mathbf{W}\)</span> is an orthogonal
<span class="math inline">\(n \times p\)</span> matrix.</p>
<p>The interpretation of this representation is as follows.</p>
<ul>
<li>First, the coefficients, <span class="math inline">\(\hat{\beta} = \widetilde{\mathbf{U}}^Ty\)</span>, are computed for
expanding <span class="math inline">\(y\)</span> in the basis given by the columns of <span class="math inline">\(\widetilde{\mathbf{U}}\)</span>.</li>
<li>Second, the <span class="math inline">\(i\)</span>-th coefficient is shrunk towards 0,
<span class="math display">\[\hat{\beta}_i(\lambda) = \frac{\hat{\beta}_i}{1 + \lambda \gamma_i}.\]</span>
</li>
<li>Third, the smoothed values, <span class="math inline">\(\widetilde{\mathbf{U}} \hat{\beta}(\lambda)\)</span>,
are computed as an expansion using the shrunken coefficients.</li>
</ul>
<p>Thus the smoother works by shrinking the coefficients toward zero in the orthonormal basis
given by the columns of <span class="math inline">\(\widetilde{\mathbf{U}}\)</span>. The coefficients corresponding to the
largest eigenvalues <span class="math inline">\(\gamma_i\)</span> are shrunk relatively more toward zero
than those corresponding to the small eigenvalues. The basis formed by the
columns of <span class="math inline">\(\widetilde{\mathbf{U}}\)</span> is known as the Demmler-Reinch basis
with reference to <span class="citation"><a href="references.html#ref-Demmler:1975" role="doc-biblioref">Demmler and Reinsch</a> (<a href="references.html#ref-Demmler:1975" role="doc-biblioref">1975</a>)</span>.</p>
<p>We implement the computation of the diagonalization for the Nuuk temperature
data using <span class="math inline">\(p = 20\)</span> basis functions (18 inner knots) equidistantly distributed
over the range of the years for which we have data.</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">inner_knots</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1867</span>, <span class="fl">2013</span>, length.out <span class="op">=</span> <span class="fl">18</span><span class="op">)</span>
<span class="va">Phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/splines/splineDesign.html">splineDesign</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>, <span class="va">inner_knots</span><span class="op">)</span>, <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Year</span><span class="op">)</span>
<span class="va">Omega</span> <span class="op">&lt;-</span> <span class="fu">pen_mat</span><span class="op">(</span><span class="va">inner_knots</span><span class="op">)</span>
<span class="va">Phi_svd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/svd.html">svd</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span>
<span class="va">Omega_tilde</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/matrix-products.html">crossprod</a></span><span class="op">(</span><span class="va">Phi_svd</span><span class="op">$</span><span class="va">v</span>, <span class="va">Omega</span> <span class="op">%*%</span> <span class="va">Phi_svd</span><span class="op">$</span><span class="va">v</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="va">Phi_svd</span><span class="op">$</span><span class="va">d</span>
<span class="va">Omega_tilde</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">Omega_tilde</span><span class="op">)</span> <span class="op">/</span> <span class="va">Phi_svd</span><span class="op">$</span><span class="va">d</span>
<span class="co"># It is safer to use the numerical singular value decomposition ('svd()')</span>
<span class="co"># for diagonalizing a positive semidefinite matrix than to use a </span>
<span class="co"># more general numerical diagonalization implementation such as 'eigen()'. </span>
<span class="va">Omega_tilde_svd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/svd.html">svd</a></span><span class="op">(</span><span class="va">Omega_tilde</span><span class="op">)</span>  
<span class="va">U_tilde</span> <span class="op">&lt;-</span> <span class="va">Phi_svd</span><span class="op">$</span><span class="va">u</span> <span class="op">%*%</span> <span class="va">Omega_tilde_svd</span><span class="op">$</span><span class="va">u</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:spline-gamma"></span>
<img src="CSwR_files/figure-html/spline-gamma-1.png" alt="The eigenvalues $\gamma_i$ that determine how much the different basis coefficients in the orthonormal spline expansion are shrunk toward zero. Left plot shows the eigenvalues, ane the right plot shows the eigenvalues on a log-scale." width="49%"><img src="CSwR_files/figure-html/spline-gamma-2.png" alt="The eigenvalues $\gamma_i$ that determine how much the different basis coefficients in the orthonormal spline expansion are shrunk toward zero. Left plot shows the eigenvalues, ane the right plot shows the eigenvalues on a log-scale." width="49%"><p class="caption">
Figure 3.17: The eigenvalues <span class="math inline">\(\gamma_i\)</span> that determine how much the different basis coefficients in the orthonormal spline expansion are shrunk toward zero. Left plot shows the eigenvalues, ane the right plot shows the eigenvalues on a log-scale.
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:spline-basis"></span>
<img src="CSwR_files/figure-html/spline-basis-1.png" alt="The columns of $\widetilde{\mathbf{U}}$  that consitute an orthonormal basis known as the Demmler-Reinch basis for computing the spline based smoother." width="100%"><p class="caption">
Figure 3.18: The columns of <span class="math inline">\(\widetilde{\mathbf{U}}\)</span> that consitute an orthonormal basis known as the Demmler-Reinch basis for computing the spline based smoother.
</p>
</div>
<p>We observe from Figures <a href="bivariate.html#fig:spline-gamma">3.17</a> and <a href="bivariate.html#fig:spline-basis">3.18</a>
that there are two relatively large eigenvalues corresponding to the
two basis functions with erratic behavior close to the boundaries, and there are
two eigenvalues that are effectively zero corresponding to the two affine
basis functions. In addition, the more oscillating the basis function is,
the larger is the corresponding eigenvalue, and the more is the corresponding
coefficient shrunk toward zero by the spline smoother.</p>
<p>Observe also that
<span class="math display">\[\mathrm{df}(\lambda) = \mathrm{trace}(\mathbf{S}_\lambda) 
= \sum_{i=1}^p \frac{1}{1 + \lambda \gamma_i},\]</span>
which makes it possible to implement GCV without even computing the diagonal entries
of <span class="math inline">\(\mathbf{S}_{\lambda}.\)</span></p>
</div>
</div>
<div id="gaussian-processes" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> Gaussian processes<a class="anchor" aria-label="anchor" href="#gaussian-processes"><i class="fas fa-link"></i></a>
</h2>
<p>Suppose that <span class="math inline">\(X = X_{1:n} \sim \mathcal{N}(\xi_x, \Sigma_{x})\)</span> with
<span class="math display">\[\mathrm{cov}(X_i, X_j) = K(t_i - t_j)\]</span>
for a kernel function <span class="math inline">\(K\)</span>.</p>
<p>With the <em>observation equation</em> <span class="math inline">\(Y_i = X_i + \delta_i\)</span>
for <span class="math inline">\(\delta = \delta_{1:n} \sim \mathcal{N}(0, \Omega)\)</span> and <span class="math inline">\(\delta \perp \! \! \perp X\)</span> we get</p>
<p><span class="math display">\[(X, Y) \sim \mathcal{N}\left(\left(\begin{array}{c} \xi_x \\ \xi_x \end{array}\right),
\left(\begin{array}{cc} \Sigma_x &amp; \Sigma_x \\ \Sigma_x &amp; \Sigma_x + \Omega \end{array} \right) \right).\]</span></p>
<p>Hence
<span class="math display">\[E(X \mid Y) = \xi_x + \Sigma_x (\Sigma_x + \Omega)^{-1} (Y - \xi_x).\]</span></p>
<p>Assuming that <span class="math inline">\(\xi_x = 0\)</span> the conditional expectation is a linear smoother with
smoother matrix
<span class="math display">\[S = \Sigma_x (\Sigma_x + \Omega)^{-1}.\]</span></p>
<p>This is also true if <span class="math inline">\(\Sigma_x (\Sigma_x + \Omega)^{-1} \xi_x = \xi_x\)</span>. If this
identity holds approximately, we can argue that for computing <span class="math inline">\(E(X \mid Y)\)</span> we
don’t need to know <span class="math inline">\(\xi_x\)</span>.</p>
<p>If the observation variance is <span class="math inline">\(\Omega = \sigma^2 I\)</span> then the smoother matrix is
<span class="math display">\[\Sigma_x (\Sigma_x + \sigma^2 I)^{-1} = (I + \sigma^2 \Sigma_x^{-1})^{-1}.\]</span></p>
</div>
<div id="the-kalman-filter" class="section level2" number="3.7">
<h2>
<span class="header-section-number">3.7</span> The Kalman filter<a class="anchor" aria-label="anchor" href="#the-kalman-filter"><i class="fas fa-link"></i></a>
</h2>
<div id="ar1-example" class="section level3" number="3.7.1">
<h3>
<span class="header-section-number">3.7.1</span> AR(1)-example<a class="anchor" aria-label="anchor" href="#ar1-example"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose that <span class="math inline">\(|\alpha| &lt; 1\)</span>, <span class="math inline">\(X_1 = \epsilon_1 / \sqrt{1 - \alpha^2}\)</span> and
<span class="math display">\[X_i = \alpha X_{i-1} + \epsilon_i\]</span>
for <span class="math inline">\(i = 2, \ldots, n\)</span> with <span class="math inline">\(\epsilon = \epsilon_{1:n} \sim \mathcal{N}(0, \sigma^2 I)\)</span>.</p>
<p>We have <span class="math inline">\(\mathrm{cov}(X_i, X_j) = \alpha^{|i-j|} / (1 - \alpha^2)\)</span>, thus we can find <span class="math inline">\(\Sigma_x\)</span> and compute
<span class="math display">\[E(X_n \mid Y) = ((I + \sigma^2 \Sigma_x^{-1})^{-1} Y)_n\]</span></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:SmoothMat-fig"></span>
<img src="CSwR_files/figure-html/SmoothMat-fig-1.png" alt="Smoothers" width="70%"><p class="caption">
Figure 3.19: Smoothers
</p>
</div>
</div>
<div id="the-kalman-smoother" class="section level3" number="3.7.2">
<h3>
<span class="header-section-number">3.7.2</span> The Kalman smoother<a class="anchor" aria-label="anchor" href="#the-kalman-smoother"><i class="fas fa-link"></i></a>
</h3>
<p>From the identity <span class="math inline">\(\epsilon_i = X_i - \alpha X_{i-1}\)</span> it follows that
<span class="math inline">\(\epsilon = A X\)</span> where</p>
<p><span class="math display">\[A = \left( \begin{array}{cccccc}
\sqrt{1 - \alpha^2} &amp; 0 &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
-\alpha &amp; 1 &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
0 &amp; -\alpha &amp; 1 &amp; \ldots &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; -\alpha &amp; 1 \\
\end{array}\right),\]</span></p>
<p>This gives
<span class="math inline">\(I = V(\epsilon) = A \Sigma_x A^T\)</span>, hence
<span class="math display">\[\Sigma_x^{-1} = (A^{-1}(A^T)^{-1})^{-1} = A^T A.\]</span></p>
<p>We have shown that
<span class="math display">\[\Sigma_x^{-1} = \left( \begin{array}{cccccc}
1 &amp; -\alpha &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
-\alpha &amp; 1 + \alpha^2 &amp; -\alpha &amp; \ldots &amp; 0 &amp; 0 \\
0 &amp; -\alpha &amp; 1 + \alpha^2 &amp; \ldots &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; 1 + \alpha^2 &amp; -\alpha \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; -\alpha &amp; 1 \\
\end{array}\right).\]</span></p>
<p>Hence
<span class="math display">\[I + \sigma^2 \Sigma_x^{-1} = \left( \begin{array}{cccccc}
\gamma_0 &amp; \rho &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
\rho &amp; \gamma &amp; \rho &amp; \ldots &amp; 0 &amp; 0 \\
0 &amp; \rho &amp; \gamma &amp; \ldots &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; \gamma &amp; \rho \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; \rho &amp; \gamma_0 \\
\end{array}\right)\]</span></p>
<p>with <span class="math inline">\(\gamma_0 = 1 + \sigma^2\)</span>, <span class="math inline">\(\gamma = 1 + \sigma^2 (1 + \alpha^2)\)</span> and <span class="math inline">\(\rho = -\sigma^2 \alpha\)</span> is a <em>tridiagonal matrix.</em></p>
<p>The equation</p>
<p><span class="math display">\[\left( \begin{array}{cccccc}
\gamma_0 &amp; \rho &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
\rho &amp; \gamma &amp; \rho &amp; \ldots &amp; 0 &amp; 0 \\
0 &amp; \rho &amp; \gamma &amp; \ldots &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; \gamma &amp; \rho \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; \rho &amp; \gamma_0 \\
\end{array}\right) 
\left( \begin{array}{c} 
x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_{n-1} \\ x_n 
\end{array}\right) = \left(\begin{array}{c}
y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_{n-1} \\ y_n 
\end{array}\right)\]</span></p>
<p>can be solved by a forward and backward sweep.</p>
<p><strong>Forward sweep:</strong></p>
<ul>
<li>Set <span class="math inline">\(\rho_1' = \rho / \gamma_0\)</span> and <span class="math inline">\(y_1' = y_1 / \gamma_0\)</span>,</li>
<li>then recursively
<span class="math display">\[\rho_i' = \frac{\rho}{\gamma - \rho \rho_{i-1}'} \quad \text{and} \quad y_i' = \frac{y_i - \rho y_{i-1}'}{\gamma - \rho \rho_{i-1}'}\]</span>
for <span class="math inline">\(i = 2, \ldots, n-1\)</span>
</li>
<li>and finally
<span class="math display">\[y_n' = \frac{y_n - \rho y_{n-1}'}{\gamma_0 - \rho \rho_{n-1}'}.\]</span>
</li>
</ul>
<p>By the forward sweep the equation is transformed to</p>
<p><span class="math display">\[\left( \begin{array}{cccccc}
1 &amp; \rho_1' &amp; 0 &amp; \ldots &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; \rho_2' &amp; \ldots &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; \ldots &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; 1 &amp; \rho_{n-1}' \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; 0 &amp; 1 \\
\end{array}\right) 
\left( \begin{array}{c}
x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_{n-1} \\ x_n 
\end{array}\right) = \left(\begin{array}{c} 
y_1' \\ y_2' \\ y_3' \\ \vdots \\ y_{n-1}' \\ y_n' 
\end{array}\right),\]</span></p>
<p>which is then solved by backsubstitution from below; <span class="math inline">\(x_n = y_n'\)</span> and
<span class="math display">\[x_{i} = y_i' - \rho_{i}' x_{i+1}, \quad i = n-1, \ldots, 1.\]</span></p>
</div>
<div id="implementation" class="section level3" number="3.7.3">
<h3>
<span class="header-section-number">3.7.3</span> Implementation<a class="anchor" aria-label="anchor" href="#implementation"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb119"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb119-1"><a href="bivariate.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span></span>
<span id="cb119-2"><a href="bivariate.html#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="kw">using</span> <span class="kw">namespace</span> Rcpp;</span>
<span id="cb119-3"><a href="bivariate.html#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="co">// [[Rcpp::export]]</span></span>
<span id="cb119-4"><a href="bivariate.html#cb119-4" aria-hidden="true" tabindex="-1"></a>NumericVector KalmanSmooth(NumericVector y, <span class="dt">double</span> alpha, <span class="dt">double</span> sigmasq) {</span>
<span id="cb119-5"><a href="bivariate.html#cb119-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">double</span> tmp, gamma0 = <span class="dv">1</span> + sigmasq, rho = - sigmasq * alpha;</span>
<span id="cb119-6"><a href="bivariate.html#cb119-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">double</span> gamma = <span class="dv">1</span> + sigmasq * (<span class="dv">1</span> + alpha * alpha);</span>
<span id="cb119-7"><a href="bivariate.html#cb119-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> n = y.size();</span>
<span id="cb119-8"><a href="bivariate.html#cb119-8" aria-hidden="true" tabindex="-1"></a>  NumericVector x(n), rhop(n - <span class="dv">1</span>);</span>
<span id="cb119-9"><a href="bivariate.html#cb119-9" aria-hidden="true" tabindex="-1"></a>  rhop[<span class="dv">0</span>] = rho / gamma0;</span>
<span id="cb119-10"><a href="bivariate.html#cb119-10" aria-hidden="true" tabindex="-1"></a>  x[<span class="dv">0</span>] = y[<span class="dv">0</span>] / gamma0;</span>
<span id="cb119-11"><a href="bivariate.html#cb119-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(<span class="dt">int</span> i = <span class="dv">1</span>; i &lt; n - <span class="dv">1</span>; ++i) { <span class="co">/* Forward sweep */</span></span>
<span id="cb119-12"><a href="bivariate.html#cb119-12" aria-hidden="true" tabindex="-1"></a>    tmp = (gamma - rho * rhop[i - <span class="dv">1</span>]);</span>
<span id="cb119-13"><a href="bivariate.html#cb119-13" aria-hidden="true" tabindex="-1"></a>    rhop[i] = rho / tmp;</span>
<span id="cb119-14"><a href="bivariate.html#cb119-14" aria-hidden="true" tabindex="-1"></a>    x[i] = (y[i] - rho * x[i - <span class="dv">1</span>]) / tmp;</span>
<span id="cb119-15"><a href="bivariate.html#cb119-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb119-16"><a href="bivariate.html#cb119-16" aria-hidden="true" tabindex="-1"></a>  x[n - <span class="dv">1</span>] = (y[n - <span class="dv">1</span>] - rho * x[n - <span class="dv">2</span>]) / (gamma0 - rho * rhop[n - <span class="dv">2</span>]);</span>
<span id="cb119-17"><a href="bivariate.html#cb119-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(<span class="dt">int</span> i = n - <span class="dv">2</span>; i &gt;= <span class="dv">0</span>; --i) { <span class="co">/* Backsubstitution */</span></span>
<span id="cb119-18"><a href="bivariate.html#cb119-18" aria-hidden="true" tabindex="-1"></a>    x[i] = x[i] - rhop[i] * x[i + <span class="dv">1</span>];</span>
<span id="cb119-19"><a href="bivariate.html#cb119-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb119-20"><a href="bivariate.html#cb119-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> x;</span>
<span id="cb119-21"><a href="bivariate.html#cb119-21" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Result, <span class="math inline">\(\alpha = 0.95\)</span>, <span class="math inline">\(\sigma^2 = 10\)</span></p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_smooth-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>Comparing results</p>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/outer.html">outer</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span>, <span class="fl">1</span><span class="op">:</span><span class="va">n</span>, 
               <span class="kw">function</span><span class="op">(</span><span class="va">i</span>, <span class="va">j</span><span class="op">)</span> <span class="va">alpha</span><span class="op">^</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">i</span> <span class="op">-</span> <span class="va">j</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>  
<span class="va">Smooth</span> <span class="op">&lt;-</span> <span class="va">Sigma</span> <span class="op">%*%</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/solve-methods.html">solve</a></span><span class="op">(</span><span class="va">Sigma</span> <span class="op">+</span> <span class="va">sigmasq</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/qplot.html">qplot</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n</span>, <span class="va">Smooth</span> <span class="op">%*%</span> <span class="va">Nuuk_year</span><span class="op">$</span><span class="va">Temperature</span> <span class="op">-</span> <span class="va">ySmooth</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Difference"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_smooth_accuracy-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>Note that the forward sweep computes <span class="math inline">\(x_n = E(X_n \mid Y)\)</span>, and from this, the backsubstitution solves the smoothing problem of computing <span class="math inline">\(E(X \mid Y)\)</span>.</p>
<p>The Gaussian process used here (the AR(1)-process) is not very smooth and nor is
the smoothing of the data. This is related to the kernel function
<span class="math inline">\(K(s) = \alpha^{|s|}\)</span> being non-differentiable in 0.</p>
<p>Many smoothers are equivalent to a Gaussian process smoother with an appropriate
choice of kernel. Not all have a simple inverse covariance matrix and a Kalman
filter algorithm.</p>
</div>
<div id="the-kalman-filter-1" class="section level3" number="3.7.4">
<h3>
<span class="header-section-number">3.7.4</span> The Kalman filter<a class="anchor" aria-label="anchor" href="#the-kalman-filter-1"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb121"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb121-1"><a href="bivariate.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span></span>
<span id="cb121-2"><a href="bivariate.html#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="kw">using</span> <span class="kw">namespace</span> Rcpp;</span>
<span id="cb121-3"><a href="bivariate.html#cb121-3" aria-hidden="true" tabindex="-1"></a><span class="co">// [[Rcpp::export]]</span></span>
<span id="cb121-4"><a href="bivariate.html#cb121-4" aria-hidden="true" tabindex="-1"></a>NumericVector KalmanFilt(NumericVector y, <span class="dt">double</span> alpha, <span class="dt">double</span> sigmasq) {</span>
<span id="cb121-5"><a href="bivariate.html#cb121-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">double</span> tmp, gamma0 = <span class="dv">1</span> + sigmasq, rho = - sigmasq * alpha, yp;</span>
<span id="cb121-6"><a href="bivariate.html#cb121-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">double</span> gamma = <span class="dv">1</span> + sigmasq * (<span class="dv">1</span> + alpha * alpha);</span>
<span id="cb121-7"><a href="bivariate.html#cb121-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> n = y.size();</span>
<span id="cb121-8"><a href="bivariate.html#cb121-8" aria-hidden="true" tabindex="-1"></a>  NumericVector x(n), rhop(n);</span>
<span id="cb121-9"><a href="bivariate.html#cb121-9" aria-hidden="true" tabindex="-1"></a>  rhop[<span class="dv">0</span>] = rho / gamma0;</span>
<span id="cb121-10"><a href="bivariate.html#cb121-10" aria-hidden="true" tabindex="-1"></a>  yp = y[<span class="dv">0</span>] / gamma0;</span>
<span id="cb121-11"><a href="bivariate.html#cb121-11" aria-hidden="true" tabindex="-1"></a>  x[<span class="dv">0</span>] = y[<span class="dv">0</span>] / (<span class="dv">1</span> + sigmasq * (<span class="dv">1</span> - alpha * alpha));</span>
<span id="cb121-12"><a href="bivariate.html#cb121-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(<span class="dt">int</span> i = <span class="dv">1</span>; i &lt; n; ++i) { </span>
<span id="cb121-13"><a href="bivariate.html#cb121-13" aria-hidden="true" tabindex="-1"></a>    tmp = (gamma - rho * rhop[i - <span class="dv">1</span>]);</span>
<span id="cb121-14"><a href="bivariate.html#cb121-14" aria-hidden="true" tabindex="-1"></a>    rhop[i] = rho / tmp;</span>
<span id="cb121-15"><a href="bivariate.html#cb121-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">/* Note differences when compared to smoother */</span></span>
<span id="cb121-16"><a href="bivariate.html#cb121-16" aria-hidden="true" tabindex="-1"></a>    x[i] = (y[i] - rho * yp) / (gamma0 - rho * rhop[i - <span class="dv">1</span>]); </span>
<span id="cb121-17"><a href="bivariate.html#cb121-17" aria-hidden="true" tabindex="-1"></a>    yp = (y[i] - rho * yp) / tmp;         </span>
<span id="cb121-18"><a href="bivariate.html#cb121-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb121-19"><a href="bivariate.html#cb121-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> x;</span>
<span id="cb121-20"><a href="bivariate.html#cb121-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Result, <span class="math inline">\(\alpha = 0.95\)</span>, <span class="math inline">\(\sigma^2 = 10\)</span></p>
<div class="inline-figure"><img src="CSwR_files/figure-html/Nuuk_filter-1.png" width="70%" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="bivariate:ex" class="section level2" number="3.8">
<h2>
<span class="header-section-number">3.8</span> Exercises<a class="anchor" aria-label="anchor" href="#bivariate:ex"><i class="fas fa-link"></i></a>
</h2>
<div id="nearest-neighbors" class="section level3 unnumbered">
<h3>Nearest neighbors<a class="anchor" aria-label="anchor" href="#nearest-neighbors"><i class="fas fa-link"></i></a>
</h3>
</div>
<div id="kernel-estimators" class="section level3 unnumbered">
<h3>Kernel estimators<a class="anchor" aria-label="anchor" href="#kernel-estimators"><i class="fas fa-link"></i></a>
</h3>

<div class="exercise">
<p><span id="exr:NW" class="exercise"><strong>Exercise 3.1  </strong></span>Consider a bivariate data set <span class="math inline">\((x_1, y_1), \ldots, (x_n, y_n)\)</span> and let <span class="math inline">\(K\)</span> be a
probability density with mean 0. Then
<span class="math display">\[\hat{f}(x, y) = \frac{1}{n h^2} \sum_{i=1}^n K\left(\frac{x - x_i}{h}\right) K\left(\frac{y - y_i}{h}\right)\]</span>
is a bivariate kernel density estimator of the joint density of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. Show
that the kernel density estimator
<span class="math display">\[\hat{f}_1(x) = \frac{1}{n h} \sum_{i=1}^n K\left(\frac{x - x_i}{h}\right)\]</span>
is also the marginal distribution of <span class="math inline">\(x\)</span> under <span class="math inline">\(\hat{f}\)</span>, and that the
Nadaraya-Watson kernel smoother is the conditional expectation of <span class="math inline">\(y\)</span>
given <span class="math inline">\(x\)</span> under <span class="math inline">\(\hat{f}\)</span>.</p>
</div>

<div class="exercise">
<span id="exr:Sdiag" class="exercise"><strong>Exercise 3.2  </strong></span>Suppose that <span class="math inline">\(K\)</span> is a symmetric kernel and the <span class="math inline">\(x\)</span>-s are equidistant. Implement
a function that computes the smoother matrix using the <code>toeplitz</code> function and
<span class="math inline">\(O(n)\)</span> kernel evaluations where <span class="math inline">\(n\)</span> is the number of data points. Implement also
a function that computes the diagonal elements of the smoother matrix directly
with run time <span class="math inline">\(O(n)\)</span>. <em>Hint: find inspiration in the implementation of the running
mean</em>.
</div>

</div>
</div>
</div>



<div class="chapter-nav">
<div class="prev"><a href="density.html"><span class="header-section-number">2</span> Density estimation</a></div>
<div class="next"><a href="univariate-random-variables.html"><span class="header-section-number">4</span> Univariate random variables</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#bivariate"><span class="header-section-number">3</span> Bivariate smoothing</a></li>
<li>
<a class="nav-link" href="#nearest-neighbor-smoothers"><span class="header-section-number">3.1</span> Nearest neighbor smoothers</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-smoothers"><span class="header-section-number">3.1.1</span> Linear smoothers</a></li>
<li><a class="nav-link" href="#implementing-the-running-mean"><span class="header-section-number">3.1.2</span> Implementing the running mean</a></li>
<li><a class="nav-link" href="#choose-k-by-cross-validation"><span class="header-section-number">3.1.3</span> Choose \(k\) by cross-validation</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#kernel-methods"><span class="header-section-number">3.2</span> Kernel methods</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#nadarayawatson-kernel-smoothing"><span class="header-section-number">3.2.1</span> Nadaraya–Watson kernel smoothing</a></li>
<li><a class="nav-link" href="#local-regression-smoothers"><span class="header-section-number">3.2.2</span> Local regression smoothers</a></li>
</ul>
</li>
<li><a class="nav-link" href="#sparse-linear-algebra"><span class="header-section-number">3.3</span> Sparse linear algebra</a></li>
<li>
<a class="nav-link" href="#onb"><span class="header-section-number">3.4</span> Orthogonal basis expansions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#polynomial-expansions"><span class="header-section-number">3.4.1</span> Polynomial expansions</a></li>
<li><a class="nav-link" href="#fourier-expansions"><span class="header-section-number">3.4.2</span> Fourier expansions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#splines"><span class="header-section-number">3.5</span> Splines</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#smoothing-splines"><span class="header-section-number">3.5.1</span> Smoothing splines</a></li>
<li><a class="nav-link" href="#splines-in-r"><span class="header-section-number">3.5.2</span> Splines in R</a></li>
<li><a class="nav-link" href="#efficient-splines"><span class="header-section-number">3.5.3</span> Efficient computation with splines</a></li>
</ul>
</li>
<li><a class="nav-link" href="#gaussian-processes"><span class="header-section-number">3.6</span> Gaussian processes</a></li>
<li>
<a class="nav-link" href="#the-kalman-filter"><span class="header-section-number">3.7</span> The Kalman filter</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ar1-example"><span class="header-section-number">3.7.1</span> AR(1)-example</a></li>
<li><a class="nav-link" href="#the-kalman-smoother"><span class="header-section-number">3.7.2</span> The Kalman smoother</a></li>
<li><a class="nav-link" href="#implementation"><span class="header-section-number">3.7.3</span> Implementation</a></li>
<li><a class="nav-link" href="#the-kalman-filter-1"><span class="header-section-number">3.7.4</span> The Kalman filter</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#bivariate:ex"><span class="header-section-number">3.8</span> Exercises</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#nearest-neighbors">Nearest neighbors</a></li>
<li><a class="nav-link" href="#kernel-estimators">Kernel estimators</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/nielsrhansen/CSwR/blob/master/08-Bivariate.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/nielsrhansen/CSwR/edit/master/08-Bivariate.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>
</div>
  

  

</div>
 <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Computational Statistics with R</strong>" was written by Niels Richard Hansen. It was last built on 2021-10-20, Git version: 86c4ccf.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>

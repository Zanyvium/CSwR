<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.3 Rejection sampling | Computational Statistics with R</title>
  <meta name="description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="4.3 Rejection sampling | Computational Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.3 Rejection sampling | Computational Statistics with R" />
  
  <meta name="twitter:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

<meta name="author" content="Niels Richard Hansen" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="transformation-techniques.html"/>
<link rel="next" href="adaptive.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro-smooth.html"><a href="intro-smooth.html"><i class="fa fa-check"></i><b>1.1</b> Smoothing</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro-smooth.html"><a href="intro-smooth.html#intro-angles"><i class="fa fa-check"></i><b>1.1.1</b> Angle distributions in proteins</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro-smooth.html"><a href="intro-smooth.html#using-ggplot2"><i class="fa fa-check"></i><b>1.1.2</b> Using ggplot2</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro-smooth.html"><a href="intro-smooth.html#changing-the-defaults"><i class="fa fa-check"></i><b>1.1.3</b> Changing the defaults</a></li>
<li class="chapter" data-level="1.1.4" data-path="intro-smooth.html"><a href="intro-smooth.html#multivariate-smoothing"><i class="fa fa-check"></i><b>1.1.4</b> Multivariate methods</a></li>
<li class="chapter" data-level="1.1.5" data-path="intro-smooth.html"><a href="intro-smooth.html#large-scale-smoothing"><i class="fa fa-check"></i><b>1.1.5</b> Large scale smoothing</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html"><i class="fa fa-check"></i><b>1.2</b> Monte Carlo Methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#vM"><i class="fa fa-check"></i><b>1.2.1</b> Univariate von Mises distributions</a></li>
<li class="chapter" data-level="1.2.2" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#mixtures-of-von-mises-distributions"><i class="fa fa-check"></i><b>1.2.2</b> Mixtures of von Mises distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>1.3</b> Optimization</a><ul>
<li class="chapter" data-level="1.3.1" data-path="optimization.html"><a href="optimization.html#the-em-algorithm"><i class="fa fa-check"></i><b>1.3.1</b> The EM-algorithm</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.4</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#r-training-exercises"><i class="fa fa-check"></i>R training exercises</a></li>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#histograms-with-non-equidistant-breaks"><i class="fa fa-check"></i>Histograms with non-equidistant breaks</a></li>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#functions-and-functional-programming"><i class="fa fa-check"></i>Functions and functional programming</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Smoothing</b></span></li>
<li class="chapter" data-level="2" data-path="density.html"><a href="density.html"><i class="fa fa-check"></i><b>2</b> Density estimation</a><ul>
<li class="chapter" data-level="2.1" data-path="unidens.html"><a href="unidens.html"><i class="fa fa-check"></i><b>2.1</b> Univariate density estimation</a><ul>
<li class="chapter" data-level="2.1.1" data-path="unidens.html"><a href="unidens.html#likelihood"><i class="fa fa-check"></i><b>2.1.1</b> Likelihood considerations</a></li>
<li class="chapter" data-level="2.1.2" data-path="unidens.html"><a href="unidens.html#sieves"><i class="fa fa-check"></i><b>2.1.2</b> Method of sieves</a></li>
<li class="chapter" data-level="2.1.3" data-path="unidens.html"><a href="unidens.html#basis-density"><i class="fa fa-check"></i><b>2.1.3</b> Basis expansions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="kernel-density.html"><a href="kernel-density.html"><i class="fa fa-check"></i><b>2.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="kernel-density.html"><a href="kernel-density.html#implementation"><i class="fa fa-check"></i><b>2.2.1</b> Implementation</a></li>
<li class="chapter" data-level="2.2.2" data-path="kernel-density.html"><a href="kernel-density.html#benchmarking"><i class="fa fa-check"></i><b>2.2.2</b> Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bandwidth.html"><a href="bandwidth.html"><i class="fa fa-check"></i><b>2.3</b> Bandwidth selection</a><ul>
<li class="chapter" data-level="2.3.1" data-path="bandwidth.html"><a href="bandwidth.html#rectangular"><i class="fa fa-check"></i><b>2.3.1</b> Revisiting the rectangular kernel</a></li>
<li class="chapter" data-level="2.3.2" data-path="bandwidth.html"><a href="bandwidth.html#ise-mise-and-mse-for-kernel-estimators"><i class="fa fa-check"></i><b>2.3.2</b> ISE, MISE and MSE for kernel estimators</a></li>
<li class="chapter" data-level="2.3.3" data-path="bandwidth.html"><a href="bandwidth.html#plug-in-estimation-of-the-oracle-bandwidth"><i class="fa fa-check"></i><b>2.3.3</b> Plug-in estimation of the oracle bandwidth</a></li>
<li class="chapter" data-level="2.3.4" data-path="bandwidth.html"><a href="bandwidth.html#cross-validation"><i class="fa fa-check"></i><b>2.3.4</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.4</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#kernel-density-estimation"><i class="fa fa-check"></i>Kernel density estimation</a></li>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#benchmarking-1"><i class="fa fa-check"></i>Benchmarking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bivariate.html"><a href="bivariate.html"><i class="fa fa-check"></i><b>3</b> Bivariate smoothing</a><ul>
<li class="chapter" data-level="3.1" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html"><i class="fa fa-check"></i><b>3.1</b> Nearest neighbor smoothers</a><ul>
<li class="chapter" data-level="3.1.1" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html#linear-smoothers"><i class="fa fa-check"></i><b>3.1.1</b> Linear smoothers</a></li>
<li class="chapter" data-level="3.1.2" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html#implementing-the-running-mean"><i class="fa fa-check"></i><b>3.1.2</b> Implementing the running mean</a></li>
<li class="chapter" data-level="3.1.3" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html#choose-k-by-cross-validation"><i class="fa fa-check"></i><b>3.1.3</b> Choose <span class="math inline">\(k\)</span> by cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="kernel-methods.html"><a href="kernel-methods.html"><i class="fa fa-check"></i><b>3.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="kernel-methods.html"><a href="kernel-methods.html#nadarayawatson-kernel-smoothing"><i class="fa fa-check"></i><b>3.2.1</b> Nadaraya–Watson kernel smoothing</a></li>
<li class="chapter" data-level="3.2.2" data-path="kernel-methods.html"><a href="kernel-methods.html#local-regression-smoothers"><i class="fa fa-check"></i><b>3.2.2</b> Local regression smoothers</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sparse-linear-algebra.html"><a href="sparse-linear-algebra.html"><i class="fa fa-check"></i><b>3.3</b> Sparse linear algebra</a></li>
<li class="chapter" data-level="3.4" data-path="onb.html"><a href="onb.html"><i class="fa fa-check"></i><b>3.4</b> Orthogonal basis expansions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="onb.html"><a href="onb.html#polynomial-expansions"><i class="fa fa-check"></i><b>3.4.1</b> Polynomial expansions</a></li>
<li class="chapter" data-level="3.4.2" data-path="onb.html"><a href="onb.html#fourier-expansions"><i class="fa fa-check"></i><b>3.4.2</b> Fourier expansions</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>3.5</b> Splines</a><ul>
<li class="chapter" data-level="3.5.1" data-path="splines.html"><a href="splines.html#smoothing-splines"><i class="fa fa-check"></i><b>3.5.1</b> Smoothing splines</a></li>
<li class="chapter" data-level="3.5.2" data-path="splines.html"><a href="splines.html#splines-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Splines in R</a></li>
<li class="chapter" data-level="3.5.3" data-path="splines.html"><a href="splines.html#efficient-splines"><i class="fa fa-check"></i><b>3.5.3</b> Efficient computation with splines</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="gaussian-processes.html"><a href="gaussian-processes.html"><i class="fa fa-check"></i><b>3.6</b> Gaussian processes</a></li>
<li class="chapter" data-level="3.7" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html"><i class="fa fa-check"></i><b>3.7</b> The Kalman filter</a><ul>
<li class="chapter" data-level="3.7.1" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#ar1-example"><i class="fa fa-check"></i><b>3.7.1</b> AR(1)-example</a></li>
<li class="chapter" data-level="3.7.2" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#the-kalman-smoother"><i class="fa fa-check"></i><b>3.7.2</b> The Kalman smoother</a></li>
<li class="chapter" data-level="3.7.3" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#implementation-1"><i class="fa fa-check"></i><b>3.7.3</b> Implementation</a></li>
<li class="chapter" data-level="3.7.4" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#the-kalman-filter-1"><i class="fa fa-check"></i><b>3.7.4</b> The Kalman filter</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#nearest-neighbors"><i class="fa fa-check"></i>Nearest neighbors</a></li>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#kernel-estimators"><i class="fa fa-check"></i>Kernel estimators</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Monte Carlo Methods</b></span></li>
<li class="chapter" data-level="4" data-path="univariate-random-variables.html"><a href="univariate-random-variables.html"><i class="fa fa-check"></i><b>4</b> Univariate random variables</a><ul>
<li class="chapter" data-level="4.1" data-path="pseudorandom-number-generators.html"><a href="pseudorandom-number-generators.html"><i class="fa fa-check"></i><b>4.1</b> Pseudorandom number generators</a><ul>
<li class="chapter" data-level="4.1.1" data-path="pseudorandom-number-generators.html"><a href="pseudorandom-number-generators.html#implementing-a-pseudorandom-number-generator"><i class="fa fa-check"></i><b>4.1.1</b> Implementing a pseudorandom number generator</a></li>
<li class="chapter" data-level="4.1.2" data-path="pseudorandom-number-generators.html"><a href="pseudorandom-number-generators.html#pseudorandom-number-packages"><i class="fa fa-check"></i><b>4.1.2</b> Pseudorandom number packages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="transformation-techniques.html"><a href="transformation-techniques.html"><i class="fa fa-check"></i><b>4.2</b> Transformation techniques</a><ul>
<li class="chapter" data-level="4.2.1" data-path="transformation-techniques.html"><a href="transformation-techniques.html#sampling-from-a-t-distribution"><i class="fa fa-check"></i><b>4.2.1</b> Sampling from a <span class="math inline">\(t\)</span>-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="reject-samp.html"><a href="reject-samp.html"><i class="fa fa-check"></i><b>4.3</b> Rejection sampling</a><ul>
<li class="chapter" data-level="4.3.1" data-path="reject-samp.html"><a href="reject-samp.html#vMsim"><i class="fa fa-check"></i><b>4.3.1</b> von Mises distribution</a></li>
<li class="chapter" data-level="4.3.2" data-path="reject-samp.html"><a href="reject-samp.html#gamma-distribution"><i class="fa fa-check"></i><b>4.3.2</b> Gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="adaptive.html"><a href="adaptive.html"><i class="fa fa-check"></i><b>4.4</b> Adaptive envelopes</a><ul>
<li class="chapter" data-level="4.4.1" data-path="adaptive.html"><a href="adaptive.html#beta-distribution"><i class="fa fa-check"></i><b>4.4.1</b> Beta distribution</a></li>
<li class="chapter" data-level="4.4.2" data-path="adaptive.html"><a href="adaptive.html#von-mises-distribution"><i class="fa fa-check"></i><b>4.4.2</b> von Mises distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.5</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises-3.html"><a href="exercises-3.html#rejection-sampling-of-gaussian-random-variables"><i class="fa fa-check"></i>Rejection sampling of Gaussian random variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mci.html"><a href="mci.html"><i class="fa fa-check"></i><b>5</b> Monte Carlo integration</a><ul>
<li class="chapter" data-level="5.1" data-path="assessment.html"><a href="assessment.html"><i class="fa fa-check"></i><b>5.1</b> Assessment</a><ul>
<li class="chapter" data-level="5.1.1" data-path="assessment.html"><a href="assessment.html#using-the-central-limit-theorem"><i class="fa fa-check"></i><b>5.1.1</b> Using the central limit theorem</a></li>
<li class="chapter" data-level="5.1.2" data-path="assessment.html"><a href="assessment.html#concentration-inequalities"><i class="fa fa-check"></i><b>5.1.2</b> Concentration inequalities</a></li>
<li class="chapter" data-level="5.1.3" data-path="assessment.html"><a href="assessment.html#exponential-tail-bound-for-gamma-distributed-variables"><i class="fa fa-check"></i><b>5.1.3</b> Exponential tail bound for Gamma distributed variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>5.2</b> Importance sampling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="importance-sampling.html"><a href="importance-sampling.html#unknown-normalization-constants"><i class="fa fa-check"></i><b>5.2.1</b> Unknown normalization constants</a></li>
<li class="chapter" data-level="5.2.2" data-path="importance-sampling.html"><a href="importance-sampling.html#hd-int"><i class="fa fa-check"></i><b>5.2.2</b> Computing a high-dimensional integral</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="network-failure.html"><a href="network-failure.html"><i class="fa fa-check"></i><b>5.3</b> Network failure</a><ul>
<li class="chapter" data-level="5.3.1" data-path="network-failure.html"><a href="network-failure.html#object-oriented-implementation"><i class="fa fa-check"></i><b>5.3.1</b> Object oriented implementation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part III: Optimization</b></span></li>
<li class="chapter" data-level="6" data-path="four-examples.html"><a href="four-examples.html"><i class="fa fa-check"></i><b>6</b> Four Examples</a><ul>
<li class="chapter" data-level="6.1" data-path="exp-fam.html"><a href="exp-fam.html"><i class="fa fa-check"></i><b>6.1</b> Exponential families</a><ul>
<li class="chapter" data-level="6.1.1" data-path="exp-fam.html"><a href="exp-fam.html#full-exponential-families"><i class="fa fa-check"></i><b>6.1.1</b> Full exponential families</a></li>
<li class="chapter" data-level="6.1.2" data-path="exp-fam.html"><a href="exp-fam.html#bayes-net"><i class="fa fa-check"></i><b>6.1.2</b> Exponential family Bayesian networks</a></li>
<li class="chapter" data-level="6.1.3" data-path="exp-fam.html"><a href="exp-fam.html#exp-fam-deriv"><i class="fa fa-check"></i><b>6.1.3</b> Likelihood computations</a></li>
<li class="chapter" data-level="6.1.4" data-path="exp-fam.html"><a href="exp-fam.html#curved-exponential-families"><i class="fa fa-check"></i><b>6.1.4</b> Curved exponential families</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="multinomial-models.html"><a href="multinomial-models.html"><i class="fa fa-check"></i><b>6.2</b> Multinomial models</a><ul>
<li class="chapter" data-level="6.2.1" data-path="multinomial-models.html"><a href="multinomial-models.html#pep-moth"><i class="fa fa-check"></i><b>6.2.1</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>6.3</b> Regression models</a></li>
<li class="chapter" data-level="6.4" data-path="finite-mixture-models.html"><a href="finite-mixture-models.html"><i class="fa fa-check"></i><b>6.4</b> Finite mixture models</a><ul>
<li class="chapter" data-level="6.4.1" data-path="finite-mixture-models.html"><a href="finite-mixture-models.html#Gaus-mix-ex"><i class="fa fa-check"></i><b>6.4.1</b> Gaussian mixtures</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>6.5</b> Mixed models</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="numopt.html"><a href="numopt.html"><i class="fa fa-check"></i><b>7</b> Numerical optimization</a><ul>
<li class="chapter" data-level="7.1" data-path="algorithms-and-convergence.html"><a href="algorithms-and-convergence.html"><i class="fa fa-check"></i><b>7.1</b> Algorithms and convergence</a><ul>
<li class="chapter" data-level="7.1.1" data-path="algorithms-and-convergence.html"><a href="algorithms-and-convergence.html#descent-algorithms"><i class="fa fa-check"></i><b>7.1.1</b> Descent algorithms</a></li>
<li class="chapter" data-level="7.1.2" data-path="algorithms-and-convergence.html"><a href="algorithms-and-convergence.html#maps-and-fixed-points"><i class="fa fa-check"></i><b>7.1.2</b> Maps and fixed points</a></li>
<li class="chapter" data-level="7.1.3" data-path="algorithms-and-convergence.html"><a href="algorithms-and-convergence.html#convergence-rate"><i class="fa fa-check"></i><b>7.1.3</b> Convergence rate</a></li>
<li class="chapter" data-level="7.1.4" data-path="algorithms-and-convergence.html"><a href="algorithms-and-convergence.html#stopping-criteria"><i class="fa fa-check"></i><b>7.1.4</b> Stopping criteria</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="descent-direction-algorithms.html"><a href="descent-direction-algorithms.html"><i class="fa fa-check"></i><b>7.2</b> Descent direction algorithms</a><ul>
<li class="chapter" data-level="7.2.1" data-path="descent-direction-algorithms.html"><a href="descent-direction-algorithms.html#line-search"><i class="fa fa-check"></i><b>7.2.1</b> Line search</a></li>
<li class="chapter" data-level="7.2.2" data-path="descent-direction-algorithms.html"><a href="descent-direction-algorithms.html#gradient-descent"><i class="fa fa-check"></i><b>7.2.2</b> Gradient descent</a></li>
<li class="chapter" data-level="7.2.3" data-path="descent-direction-algorithms.html"><a href="descent-direction-algorithms.html#conjugate-gradients"><i class="fa fa-check"></i><b>7.2.3</b> Conjugate gradients</a></li>
<li class="chapter" data-level="7.2.4" data-path="descent-direction-algorithms.html"><a href="descent-direction-algorithms.html#pep-moth-descent"><i class="fa fa-check"></i><b>7.2.4</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="newton-type-algorithms.html"><a href="newton-type-algorithms.html"><i class="fa fa-check"></i><b>7.3</b> Newton-type algorithms</a><ul>
<li class="chapter" data-level="7.3.1" data-path="newton-type-algorithms.html"><a href="newton-type-algorithms.html#poisson-regression"><i class="fa fa-check"></i><b>7.3.1</b> Poisson regression</a></li>
<li class="chapter" data-level="7.3.2" data-path="newton-type-algorithms.html"><a href="newton-type-algorithms.html#quasi-newton-algorithms"><i class="fa fa-check"></i><b>7.3.2</b> Quasi-Newton algorithms</a></li>
<li class="chapter" data-level="7.3.3" data-path="newton-type-algorithms.html"><a href="newton-type-algorithms.html#sparsity"><i class="fa fa-check"></i><b>7.3.3</b> Sparsity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="misc-.html"><a href="misc-.html"><i class="fa fa-check"></i><b>7.4</b> Misc.</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="em.html"><a href="em.html"><i class="fa fa-check"></i><b>8</b> Expectation maximization algorithms</a><ul>
<li class="chapter" data-level="8.1" data-path="basic-properties.html"><a href="basic-properties.html"><i class="fa fa-check"></i><b>8.1</b> Basic properties</a><ul>
<li class="chapter" data-level="8.1.1" data-path="basic-properties.html"><a href="basic-properties.html#incomplete-data-likelihood"><i class="fa fa-check"></i><b>8.1.1</b> Incomplete data likelihood</a></li>
<li class="chapter" data-level="8.1.2" data-path="basic-properties.html"><a href="basic-properties.html#monotonicity-of-the-em-algorithm"><i class="fa fa-check"></i><b>8.1.2</b> Monotonicity of the EM algorithm</a></li>
<li class="chapter" data-level="8.1.3" data-path="basic-properties.html"><a href="basic-properties.html#peppered-moths"><i class="fa fa-check"></i><b>8.1.3</b> Peppered moths</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="EM-exp.html"><a href="EM-exp.html"><i class="fa fa-check"></i><b>8.2</b> Exponential families</a></li>
<li class="chapter" data-level="8.3" data-path="fisher-information.html"><a href="fisher-information.html"><i class="fa fa-check"></i><b>8.3</b> Fisher information</a></li>
<li class="chapter" data-level="8.4" data-path="revisiting-gaussian-mixtures.html"><a href="revisiting-gaussian-mixtures.html"><i class="fa fa-check"></i><b>8.4</b> Revisiting Gaussian mixtures</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reject-samp" class="section level2">
<h2><span class="header-section-number">4.3</span> Rejection sampling</h2>
<p>This section deals with a general algorithm for simulating variables
from a distribution with density <span class="math inline">\(f\)</span>. We call <span class="math inline">\(f\)</span> the target density
and the corresponding distribution is called the target distribution.
The idea is to simulate <em>proposals</em> from a different distribution
with density <span class="math inline">\(g\)</span> (the proposal distribution) and then according to
a criterion decide to accept or reject the proposals. It is assumed
throughout that the proposal density <span class="math inline">\(g\)</span> is a density fulfilling that</p>
<p><span class="math display" id="eq:gfnull">\[\begin{equation}
g(x) = 0 \Rightarrow f(x) = 0.
\tag{4.1}
\end{equation}\]</span></p>
<p>Let <span class="math inline">\(Y_1, Y_2, \ldots\)</span> be i.i.d. with density <span class="math inline">\(g\)</span> on <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(U_1, U_2, \ldots\)</span>
be i.i.d. uniformly distributed on <span class="math inline">\((0,1)\)</span> and independent of the <span class="math inline">\(Y_i\)</span>s. Define
<span class="math display">\[T(\mathbf{Y}, \mathbf{U}) = Y_{\sigma}\]</span>
with
<span class="math display">\[\sigma = \inf\{n \geq 1 \mid U_n \leq \alpha f(Y_n) / g(Y_n)\},\]</span>
for <span class="math inline">\(\alpha \in (0, 1]\)</span> and <span class="math inline">\(f\)</span> a density. Rejection sampling then consists
of simulating independent pairs <span class="math inline">\((Y_n, U_n)\)</span> as long as we <em>reject</em> the
proposals <span class="math inline">\(Y_n\)</span> sampled from <span class="math inline">\(g\)</span>,
that is, as long as
<span class="math display">\[U_n &gt; \alpha f(Y_n) / g(Y_n).\]</span>
The first time we <em>accept</em> a proposal is <span class="math inline">\(\sigma\)</span>, and then we stop the
sampling and return the proposal <span class="math inline">\(Y_{\sigma}\)</span>. The result is, indeed,
a sample from the distribution with density <span class="math inline">\(f\)</span> as the following theorem states.</p>


<div class="theorem">
<p><span id="thm:reject" class="theorem"><strong>Theorem 4.2  </strong></span>If <span class="math inline">\(\alpha f(y) \leq g(y)\)</span> for all <span class="math inline">\(y \in \mathbb{R}\)</span> and <span class="math inline">\(\alpha &gt; 0\)</span>
then the distribution of <span class="math inline">\(Y_{\sigma}\)</span> has density <span class="math inline">\(f\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Note that <span class="math inline">\(g\)</span> automatically fulfills <a href="reject-samp.html#eq:gfnull">(4.1)</a>. The formal proof decomposes
the event <span class="math inline">\((Y_{\sigma} \leq y)\)</span> according to the value of <span class="math inline">\(\sigma\)</span> as follows</p>
<p><span class="math display">\[\begin{align}
P(Y_{\sigma} \leq y) &amp; = \sum_{n = 1}^{\infty} P(Y_{n} \leq y, \ \sigma = n) \\
&amp; = \sum_{n = 1}^{\infty} P(Y_{n} \leq y, \ U_n \leq \alpha f(Y_n) / g(Y_n)) P(\sigma &gt; n - 1) \\
&amp; = P(Y_{1} \leq y, \ U_1 \leq \alpha f(Y_1) / g(Y_1)) \sum_{n = 1}^{\infty} P(\sigma &gt; n - 1).
\end{align}\]</span></p>
<p>By independence of the pairs <span class="math inline">\((Y_n, U_n)\)</span> we find that
<span class="math display">\[P(\sigma &gt; n - 1) = p^{(n-1)}\]</span>
where <span class="math inline">\(p = P(U_1 &gt; \alpha f(Y_1) / g(Y_1))\)</span>, and
<span class="math display">\[\sum_{n = 1}^{\infty} P(\sigma &gt; n - 1) = \sum_{n = 1}^{\infty} p^{(n-1)} = \frac{1}{1 - p}.\]</span></p>
<p>We further find using Tonelli’s theorem that</p>
<p><span class="math display">\[\begin{align}
P(Y_{1} \leq y, \ U_1 \leq \alpha f(Y_1) / g(Y_1)) &amp; = \int_{-\infty}^y \alpha \frac{f(z)}{g(z)} g(z) \mathrm{d}z \\
&amp; = \alpha \int_{-\infty}^y f(z) \mathrm{d} z.
\end{align}\]</span></p>
<p>It also follows from this, by taking <span class="math inline">\(y = \infty\)</span>, that <span class="math inline">\(1 - p = \alpha\)</span>,
and we conclude that
<span class="math display">\[P(Y_{\sigma} \leq y) = \int_{-\infty}^y f(z) \mathrm{d} z,\]</span>
and the density for the distribution of <span class="math inline">\(Y_{\sigma}\)</span> is, indeed, <span class="math inline">\(f\)</span>.</p>
</div>

<p>Note that if <span class="math inline">\(\alpha f \leq g\)</span> for <em>densities</em> <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>, then
<span class="math display">\[\alpha = \int \alpha f(x) \mathrm{d}x \leq \int g(x) \mathrm{d}x = 1,\]</span>
whence it follows automatically that <span class="math inline">\(\alpha \leq 1\)</span> whenever <span class="math inline">\(\alpha f\)</span> is
dominated by <span class="math inline">\(g\)</span>. The function <span class="math inline">\(g/\alpha\)</span> is called the <em>envelope</em> of <span class="math inline">\(f\)</span>.
The tighter the envelope, the smaller is the probability of rejecting
a sample from <span class="math inline">\(g\)</span>, and this is quantified explicitly by <span class="math inline">\(\alpha\)</span> as <span class="math inline">\(1 - \alpha\)</span>
is the rejection probability. Thus <span class="math inline">\(\alpha\)</span> should preferably be as close to
one as possible.</p>
<p>If <span class="math inline">\(f(y) = c q(y)\)</span> and <span class="math inline">\(g(y) = d p(y)\)</span> for (unknown) normalizing constants
<span class="math inline">\(c, d &gt; 0\)</span> and <span class="math inline">\(\alpha&#39; q \leq p\)</span> for <span class="math inline">\(\alpha&#39; &gt; 0\)</span> then
<span class="math display">\[\underbrace{\left(\frac{\alpha&#39; d}{c}\right)}_{= \alpha} \ f \leq g.\]</span>
The constant <span class="math inline">\(\alpha&#39;\)</span> may be larger than 1, but from the argument above
we know that <span class="math inline">\(\alpha \leq 1\)</span>, and Theorem <a href="reject-samp.html#thm:reject">4.2</a> gives that
<span class="math inline">\(Y_{\sigma}\)</span> has distribution with density <span class="math inline">\(f\)</span>. It appears that we need to
compute the normalizing constants to implement rejection sampling. However,
observe that
<span class="math display">\[u \leq \frac{\alpha f(y)}{g(y)} \Leftrightarrow u \leq \frac{\alpha&#39; q(y)}{p(y)},\]</span>
whence rejection sampling can actually be implemented with knowledge
of the unnormalized densities and <span class="math inline">\(\alpha&#39;\)</span> only and without computing <span class="math inline">\(c\)</span> or <span class="math inline">\(d\)</span>.
This is one great advantage of rejection sampling. We should
note, though, that when we don’t know the normalizing constants, <span class="math inline">\(\alpha&#39;\)</span> does not tell
us anything about how tight the envelope is, and thus how small the rejection
probability is.</p>
<p>Given two functions <span class="math inline">\(q\)</span> and <span class="math inline">\(p\)</span>, how do we then find <span class="math inline">\(\alpha&#39;\)</span> so that
<span class="math inline">\(\alpha&#39; q \leq p\)</span>? Consider the function
<span class="math display">\[y \mapsto \frac{p(y)}{q(y)}\]</span>
for <span class="math inline">\(q(y) &gt; 0\)</span>. If this function is lower bounded by a value strictly larger than
zero, we can take
<span class="math display">\[\alpha&#39; = \inf_{y: q(y) &gt; 0} \frac{p(y)}{q(y)} &gt; 0.\]</span>
We can in practice often find this value by minimizing <span class="math inline">\(p(y)/q(y)\)</span>. If
the minimum is zero, there is no <span class="math inline">\(\alpha&#39;\)</span>, and <span class="math inline">\(p\)</span> cannot be
used to construct an envelope. If the minimum is strictly positive
it is the best possible choice of <span class="math inline">\(\alpha&#39;\)</span>.</p>
<div id="vMsim" class="section level3">
<h3><span class="header-section-number">4.3.1</span> von Mises distribution</h3>
<p>Recall the <a href="monte-carlo-methods.html#vM">von Mises distribution</a> from Section <a href="monte-carlo-methods.html#vM">1.2.1</a>. It is a
distribution on <span class="math inline">\((-\pi, \pi]\)</span> with density
<span class="math display">\[f(x) \propto e^{\kappa \cos(x - \mu)}\]</span>
for parameters <span class="math inline">\(\kappa &gt; 0\)</span> and <span class="math inline">\(\mu \in (-\pi, \pi]\)</span>. Clearly, <span class="math inline">\(\mu\)</span> is a
location parameter, and we fix <span class="math inline">\(\mu = 0\)</span> in the following. Simulating random variables
with <span class="math inline">\(\mu \neq 0\)</span> can be achieved by (wrapped) translation of variables
with <span class="math inline">\(\mu = 0\)</span>.</p>
<p>Thus the target density is <span class="math inline">\(f(x) \propto e^{\kappa \cos(x)}\)</span>. In this section
we will use the uniform distribution on <span class="math inline">\((-\pi, \pi)\)</span> as proposal distribution.
It has constant density <span class="math inline">\(g(x) = (2\pi)^{-1}\)</span>, but all we need is, in fact, that
<span class="math inline">\(g(x) \propto 1\)</span>. Since <span class="math inline">\(x \mapsto 1 / \exp(\kappa \cos(x)) = \exp(-\kappa \cos(x))\)</span> attains its
minimum <span class="math inline">\(\exp(-\kappa)\)</span> for <span class="math inline">\(x = 0\)</span>, we find that
<span class="math display">\[\alpha&#39; e^{\kappa \cos(x)} = e^{\kappa(\cos(x) - 1)} \leq 1,\]</span>
with <span class="math inline">\(\alpha&#39; = \exp(-\kappa)\)</span>. The rejection test of the
proposal <span class="math inline">\(Y \sim g\)</span> can therefore be carried out
by testing if a uniformly distributed random variable <span class="math inline">\(U\)</span> on <span class="math inline">\((0,1)\)</span>
satisfies
<span class="math display">\[U &gt; e^{\kappa(\cos(Y) - 1)}.\]</span></p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb166-1" data-line-number="1">vMsim_slow &lt;-<span class="st"> </span><span class="cf">function</span>(n, kappa) {</a>
<a class="sourceLine" id="cb166-2" data-line-number="2">  y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)</a>
<a class="sourceLine" id="cb166-3" data-line-number="3">  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb166-4" data-line-number="4">    reject &lt;-<span class="st"> </span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb166-5" data-line-number="5">    <span class="cf">while</span>(reject) {</a>
<a class="sourceLine" id="cb166-6" data-line-number="6">      y0 &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="op">-</span><span class="st"> </span>pi, pi)</a>
<a class="sourceLine" id="cb166-7" data-line-number="7">      u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb166-8" data-line-number="8">      reject &lt;-<span class="st"> </span>u <span class="op">&gt;</span><span class="st"> </span><span class="kw">exp</span>(kappa <span class="op">*</span><span class="st"> </span>(<span class="kw">cos</span>(y0) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb166-9" data-line-number="9">    }</a>
<a class="sourceLine" id="cb166-10" data-line-number="10">    y[i] &lt;-<span class="st"> </span>y0</a>
<a class="sourceLine" id="cb166-11" data-line-number="11">  }</a>
<a class="sourceLine" id="cb166-12" data-line-number="12">  y</a>
<a class="sourceLine" id="cb166-13" data-line-number="13">}</a></code></pre></div>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" data-line-number="1">f &lt;-<span class="st"> </span><span class="cf">function</span>(x, k) <span class="kw">exp</span>(k <span class="op">*</span><span class="st"> </span><span class="kw">cos</span>(x)) <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span><span class="kw">besselI</span>(k, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb167-2" data-line-number="2">x &lt;-<span class="st"> </span><span class="kw">vMsim_slow</span>(<span class="dv">100000</span>, <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb167-3" data-line-number="3"><span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb167-4" data-line-number="4"><span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="fl">0.5</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb167-5" data-line-number="5">x &lt;-<span class="st"> </span><span class="kw">vMsim_slow</span>(<span class="dv">100000</span>, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb167-6" data-line-number="6"><span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb167-7" data-line-number="7"><span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="dv">2</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vMsim"></span>
<img src="CSwR_files/figure-html/vMsim-1.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right). The true densities (blue) are added to the plots." width="49%" /><img src="CSwR_files/figure-html/vMsim-2.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right). The true densities (blue) are added to the plots." width="49%" />
<p class="caption">
Figure 4.1: Histograms of 100,000 simulated data points from von Mises distributions with parameters <span class="math inline">\(\kappa = 0.5\)</span> (left) and <span class="math inline">\(\kappa = 2\)</span> (right). The true densities (blue) are added to the plots.
</p>
</div>

<p>Figure <a href="reject-samp.html#fig:vMsim">4.1</a> confirms that the implementation simulates
from the von Mises distribution.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb168-1" data-line-number="1"><span class="kw">system.time</span>(<span class="kw">vMsim_slow</span>(<span class="dv">100000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>))</a></code></pre></div>
<pre><code>##    user  system elapsed 
##   2.545   0.715   3.265</code></pre>
<p>Though the implementation can easily simulate 100,000 variables in a couple of
seconds, it might still be possible to improve it. To investigate what most
of the run time is spent on we use the line profiling tool as implemented in
the profvis package.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" data-line-number="1"><span class="kw">library</span>(profvis)</a>
<a class="sourceLine" id="cb170-2" data-line-number="2"><span class="kw">profvis</span>(<span class="kw">vMsim_slow</span>(<span class="dv">10000</span>, <span class="dv">5</span>))</a></code></pre></div>
<p><img src="figures/vMsim-profile.png" width="90%" style="display: block; margin: auto;" /></p>
<p>The <a href="https://cswr.nrhstat.org/figures/vMsim-profile.html">profiling result</a> shows that almost all the time
is spent on simulating uniformly distributed random variables. It is, perhaps,
expected that this should take some time, but that it takes so much more time
than computing the ratio, say, used for the rejection test is a bit surprising.
What might be even more surprising is the large amount of memory allocation
and deallocation associated with the simulation of the variables.</p>
<p>The culprit is <code>runif</code> that has some overhead associated with each call.
The function performs much better if called once to return a vector than
if called repeatedly as above to return just single numbers. We could
rewrite the rejection sampler to make better use of <code>runif</code>, but it would
make the code a bit more complicated because we don’t know upfront
how many uniform variables we need. This will introduce some bookkeeping
that it is possible to abstract away from the implementation of any
rejection sampler. Therefore we implement a generic
wrapper of the random number generator that will cache a suitable amount
of random variables. This function will take care of some bookkeeping
and variables can then be extracted as needed. This also nicely
illustrates a use of <a href="http://adv-r.had.co.nz/Functional-programming.html#closures">closures and a function factory</a>.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" data-line-number="1">rng_stream &lt;-<span class="st"> </span><span class="cf">function</span>(m, rng, ...) {</a>
<a class="sourceLine" id="cb171-2" data-line-number="2">  args &lt;-<span class="st"> </span><span class="kw">list</span>(...)</a>
<a class="sourceLine" id="cb171-3" data-line-number="3">  cache &lt;-<span class="st"> </span><span class="kw">do.call</span>(rng, <span class="kw">c</span>(m, args))</a>
<a class="sourceLine" id="cb171-4" data-line-number="4">  j &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb171-5" data-line-number="5">  fact &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb171-6" data-line-number="6">  next_rn &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">r =</span> m) {</a>
<a class="sourceLine" id="cb171-7" data-line-number="7">    j &lt;&lt;-<span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb171-8" data-line-number="8">    <span class="cf">if</span>(j <span class="op">&gt;</span><span class="st"> </span>m) {</a>
<a class="sourceLine" id="cb171-9" data-line-number="9">      <span class="cf">if</span>(fact <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;&amp;</span><span class="st"> </span>r <span class="op">&lt;</span><span class="st"> </span>m) fact &lt;&lt;-<span class="st"> </span>m <span class="op">/</span><span class="st"> </span>(m <span class="op">-</span><span class="st"> </span>r)</a>
<a class="sourceLine" id="cb171-10" data-line-number="10">      m &lt;&lt;-<span class="st"> </span><span class="kw">floor</span>(fact <span class="op">*</span><span class="st"> </span>(r <span class="op">+</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb171-11" data-line-number="11">      cache &lt;&lt;-<span class="st"> </span><span class="kw">do.call</span>(rng, <span class="kw">c</span>(m, args))</a>
<a class="sourceLine" id="cb171-12" data-line-number="12">      j &lt;&lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb171-13" data-line-number="13">    }</a>
<a class="sourceLine" id="cb171-14" data-line-number="14">    cache[j] </a>
<a class="sourceLine" id="cb171-15" data-line-number="15">  }</a>
<a class="sourceLine" id="cb171-16" data-line-number="16">  next_rn</a>
<a class="sourceLine" id="cb171-17" data-line-number="17">}</a></code></pre></div>
<p>The implementation above is a function that returns a function. The returned
function, <code>next_rn</code> comes with its own environment, where it stores the
cached variables and extracts and returns one variable whenever called.
It generates a new vector of random variables
whenever it “runs out”. The first time it does so, the function estimates a
factor of how many variables is needed in total based on the argument <code>r</code>, and
then it generates the estimated number of variables needed. This may be
repeated a couple of times.</p>
<p>We can then reimplement <code>vMsim</code> using <code>rng_stream</code>. For later usage we add the
possibility of printing out some tracing information.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb172-1" data-line-number="1">vMsim &lt;-<span class="st"> </span><span class="cf">function</span>(n, kappa, <span class="dt">trace =</span> <span class="ot">FALSE</span>) {</a>
<a class="sourceLine" id="cb172-2" data-line-number="2">  count &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb172-3" data-line-number="3">  y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)</a>
<a class="sourceLine" id="cb172-4" data-line-number="4">  y0 &lt;-<span class="st"> </span><span class="kw">rng_stream</span>(n, runif, <span class="op">-</span><span class="st"> </span>pi, pi)</a>
<a class="sourceLine" id="cb172-5" data-line-number="5">  u &lt;-<span class="st"> </span><span class="kw">rng_stream</span>(n, runif)</a>
<a class="sourceLine" id="cb172-6" data-line-number="6">  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb172-7" data-line-number="7">    reject &lt;-<span class="st"> </span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb172-8" data-line-number="8">    <span class="cf">while</span>(reject) {</a>
<a class="sourceLine" id="cb172-9" data-line-number="9">      count &lt;-<span class="st"> </span>count <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb172-10" data-line-number="10">      z &lt;-<span class="st"> </span><span class="kw">y0</span>(n <span class="op">-</span><span class="st"> </span>i)</a>
<a class="sourceLine" id="cb172-11" data-line-number="11">      reject &lt;-<span class="st"> </span><span class="kw">u</span>(n <span class="op">-</span><span class="st"> </span>i) <span class="op">&gt;</span><span class="st"> </span><span class="kw">exp</span>(kappa <span class="op">*</span><span class="st"> </span>(<span class="kw">cos</span>(z) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb172-12" data-line-number="12">    }</a>
<a class="sourceLine" id="cb172-13" data-line-number="13">    y[i] &lt;-<span class="st"> </span>z</a>
<a class="sourceLine" id="cb172-14" data-line-number="14">  }</a>
<a class="sourceLine" id="cb172-15" data-line-number="15">  <span class="cf">if</span>(trace)</a>
<a class="sourceLine" id="cb172-16" data-line-number="16">    <span class="kw">cat</span>(<span class="st">&quot;kappa =&quot;</span>, kappa, <span class="st">&quot;:&quot;</span>, (count <span class="op">-</span><span class="st"> </span>n)<span class="op">/</span><span class="st"> </span>count, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)  <span class="co">## Rejection frequency</span></a>
<a class="sourceLine" id="cb172-17" data-line-number="17">  y</a>
<a class="sourceLine" id="cb172-18" data-line-number="18">}</a></code></pre></div>
<p>We should, of course, remember to test that the new implementation still
generates variables from the von Mises distribution.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb173-2" data-line-number="2"><span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb173-3" data-line-number="3"><span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="fl">0.5</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb173-4" data-line-number="4">x &lt;-<span class="st"> </span><span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb173-5" data-line-number="5"><span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb173-6" data-line-number="6"><span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="dv">2</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vMsim2"></span>
<img src="CSwR_files/figure-html/vMsim2-1.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using vectorized generation of random variables." width="49%" /><img src="CSwR_files/figure-html/vMsim2-2.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using vectorized generation of random variables." width="49%" />
<p class="caption">
Figure 4.2: Histograms of 100,000 simulated data points from von Mises distributions with parameters <span class="math inline">\(\kappa = 0.5\)</span> (left) and <span class="math inline">\(\kappa = 2\)</span> (right), simulated using vectorized generation of random variables.
</p>
</div>

<p>Then we can compare the run time of this new implementation to the
run time of the first implementation.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb174-1" data-line-number="1"><span class="kw">system.time</span>(<span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>))</a></code></pre></div>
<pre><code>##    user  system elapsed 
##   0.573   0.002   0.576</code></pre>
<p>As we see from the time estimate above, using a vectorized call of <code>runif</code>
reduces the run time by a factor 4-5. It is possible to get a further factor 2-3
run time improvement (not shown) by implementing the computations done by
<code>rng_stream</code> directly inside <code>vMsim</code>. However, we prioritize here to have
modular code so that we can reuse <code>rng_stream</code> for other rejection samplers without
repeating code. A pure R implementation based on a loop will never be able to
compete with a C++ implementation anyway when the accept-reject step is such a
simple computation.</p>
<p>In fact, to write a pure R function that is run time efficient, we need to
turn the entire rejection sampler into a vectorized computation. That is,
it is not just the generation of random numbers that need to be vectorized.
There is no way around some form of loop as we don’t known upfront how many
rejections there will be. We can, however, benefit from the ideas in <code>rng_stream</code>
on how to estimate the fraction of acceptances from a first round, which can be
used for subsequent simulations. This is done in the following fully
vectorized R implementation.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb176-1" data-line-number="1">vMsim_vec &lt;-<span class="st"> </span><span class="cf">function</span>(n, kappa) {</a>
<a class="sourceLine" id="cb176-2" data-line-number="2">  fact &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb176-3" data-line-number="3">  j &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb176-4" data-line-number="4">  l &lt;-<span class="st"> </span><span class="dv">0</span>  <span class="co">## The number of accepted samples</span></a>
<a class="sourceLine" id="cb176-5" data-line-number="5">  y &lt;-<span class="st"> </span><span class="kw">list</span>()</a>
<a class="sourceLine" id="cb176-6" data-line-number="6">  <span class="cf">while</span>(l <span class="op">&lt;</span><span class="st"> </span>n) {</a>
<a class="sourceLine" id="cb176-7" data-line-number="7">    m &lt;-<span class="st"> </span><span class="kw">floor</span>(fact <span class="op">*</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>l))  <span class="co">## equals n the first time</span></a>
<a class="sourceLine" id="cb176-8" data-line-number="8">    y0 &lt;-<span class="st"> </span><span class="kw">runif</span>(m, <span class="op">-</span><span class="st"> </span>pi, pi)</a>
<a class="sourceLine" id="cb176-9" data-line-number="9">    u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)</a>
<a class="sourceLine" id="cb176-10" data-line-number="10">    accept &lt;-<span class="st"> </span>u <span class="op">&lt;=</span><span class="st"> </span><span class="kw">exp</span>(kappa <span class="op">*</span><span class="st"> </span>(<span class="kw">cos</span>(y0) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb176-11" data-line-number="11">    l &lt;-<span class="st"> </span>l <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(accept)</a>
<a class="sourceLine" id="cb176-12" data-line-number="12">    y[[j]] &lt;-<span class="st"> </span>y0[accept]</a>
<a class="sourceLine" id="cb176-13" data-line-number="13">    j &lt;-<span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb176-14" data-line-number="14">    <span class="cf">if</span>(fact <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) fact &lt;-<span class="st"> </span>n <span class="op">/</span><span class="st"> </span>l</a>
<a class="sourceLine" id="cb176-15" data-line-number="15">  }</a>
<a class="sourceLine" id="cb176-16" data-line-number="16">  <span class="kw">unlist</span>(y)[<span class="dv">1</span><span class="op">:</span>n]</a>
<a class="sourceLine" id="cb176-17" data-line-number="17">}</a></code></pre></div>
<p>The implementation above incrementally grows a list, whose entries contain
vectors of accepted samples. It is usually not advisable to dynamically
grow objects (vectors or list), as this will lead to a lot of memory
allocation, copying and deallocation. Thus it is better to initialize a vector
of the correct size upfront. In this particular case the list will only contain
few entries, and it is inconsequential that it is grown dynamically.</p>
<p>Finally, a C++ implementation via Rcpp is given below where the random variables are
then again generated one at a time via the C-interface to R’s random number
generators. There is no (substantial) overhead of doing so in C++.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb177-1" data-line-number="1"><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span></a>
<a class="sourceLine" id="cb177-2" data-line-number="2"><span class="kw">using</span> <span class="kw">namespace</span> Rcpp;</a>
<a class="sourceLine" id="cb177-3" data-line-number="3"><span class="co">// [[Rcpp::export]]</span></a>
<a class="sourceLine" id="cb177-4" data-line-number="4">NumericVector vMsim_cpp(<span class="dt">int</span> n, <span class="dt">double</span> kappa) {</a>
<a class="sourceLine" id="cb177-5" data-line-number="5">  NumericVector y(n);</a>
<a class="sourceLine" id="cb177-6" data-line-number="6">  <span class="dt">double</span> y0;</a>
<a class="sourceLine" id="cb177-7" data-line-number="7">  <span class="dt">bool</span> reject;</a>
<a class="sourceLine" id="cb177-8" data-line-number="8">  <span class="cf">for</span>(<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; ++i) {</a>
<a class="sourceLine" id="cb177-9" data-line-number="9">    <span class="cf">do</span> {</a>
<a class="sourceLine" id="cb177-10" data-line-number="10">      y0 = R::runif(- M_PI, M_PI);</a>
<a class="sourceLine" id="cb177-11" data-line-number="11">      reject = R::runif(<span class="dv">0</span>, <span class="dv">1</span>) &gt; exp(kappa * (cos(y0) - <span class="dv">1</span>));</a>
<a class="sourceLine" id="cb177-12" data-line-number="12">    } <span class="cf">while</span>(reject);</a>
<a class="sourceLine" id="cb177-13" data-line-number="13">    y[i] = y0;</a>
<a class="sourceLine" id="cb177-14" data-line-number="14">  }</a>
<a class="sourceLine" id="cb177-15" data-line-number="15">  <span class="cf">return</span> y;</a>
<a class="sourceLine" id="cb177-16" data-line-number="16">}</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vMsim3"></span>
<img src="CSwR_files/figure-html/vMsim3-1.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using the Rcpp implementation (top) and the fully vectorized R implementation (bottom)." width="49%" /><img src="CSwR_files/figure-html/vMsim3-2.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using the Rcpp implementation (top) and the fully vectorized R implementation (bottom)." width="49%" /><img src="CSwR_files/figure-html/vMsim3-3.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using the Rcpp implementation (top) and the fully vectorized R implementation (bottom)." width="49%" /><img src="CSwR_files/figure-html/vMsim3-4.png" alt="Histograms of 100,000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using the Rcpp implementation (top) and the fully vectorized R implementation (bottom)." width="49%" />
<p class="caption">
Figure 4.3: Histograms of 100,000 simulated data points from von Mises distributions with parameters <span class="math inline">\(\kappa = 0.5\)</span> (left) and <span class="math inline">\(\kappa = 2\)</span> (right), simulated using the Rcpp implementation (top) and the fully vectorized R implementation (bottom).
</p>
</div>

<p>Figure <a href="reject-samp.html#fig:vMsim3">4.3</a> shows the results from testing the C++ implementation
and the fast R implementation,
and confirms that the implementations do simulate from the von Mises distribution.
We conclude by measurering the run time of the implementations using
<code>system.time</code> and a combined microbenchmark of all four different implementations.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" data-line-number="1"><span class="kw">system.time</span>(<span class="kw">vMsim_cpp</span>(<span class="dv">100000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>))</a></code></pre></div>
<pre><code>##    user  system elapsed 
##   0.047   0.000   0.047</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" data-line-number="1"><span class="kw">microbenchmark</span>(</a>
<a class="sourceLine" id="cb180-2" data-line-number="2">  <span class="kw">vMsim_slow</span>(<span class="dv">1000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb180-3" data-line-number="3">  <span class="kw">vMsim</span>(<span class="dv">1000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb180-4" data-line-number="4">  <span class="kw">vMsim_vec</span>(<span class="dv">1000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb180-5" data-line-number="5">  <span class="kw">vMsim_cpp</span>(<span class="dv">1000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb180-6" data-line-number="6">)</a></code></pre></div>
<pre><code>## Unit: microseconds
##                         expr   min    lq  mean median    uq    max neval
##  vMsim_slow(1000, kappa = 5) 16610 18807 24588  19903 20738 100044   100
##       vMsim(1000, kappa = 5)  5031  5584  7250   5869  6091  72535   100
##   vMsim_vec(1000, kappa = 5)   401   449   497    479   506    970   100
##   vMsim_cpp(1000, kappa = 5)   289   317   333    327   339    563   100</code></pre>
<p>The C++ implementation is only a factor 1.5 faster than the fully
vectorized R implementation, while it is around a factor 15 faster
than the loop-based <code>vMsim</code> and a factor 85 or so faster than the
first implementation <code>vMsim_slow</code>. Rejection sampling is a good example
of an algorithm for which a naive loop-based R implementation
performs rather poorly in terms of run time, while a completely vectorized
implementation is competitive with an Rcpp implementation.</p>
</div>
<div id="gamma-distribution" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Gamma distribution</h3>
<p>It may be possible to find a suitable envelope of the density for the
gamma distribution on <span class="math inline">\((0, \infty)\)</span>, but it turns out that there is a
very efficient rejection sampler of a non-standard distribution that
can be transformed into a gamma distribution by a simple transformation.</p>
<p>Let <span class="math inline">\(t(y) = a(1 + by)^3\)</span> for <span class="math inline">\(y \in (-b^{-1}, \infty)\)</span>, then <span class="math inline">\(t(Y) \sim \Gamma(r,1)\)</span> if <span class="math inline">\(r \geq 1\)</span>
and <span class="math inline">\(Y\)</span> has density
<span class="math display">\[f(y) \propto t(y)^{r-1}t&#39;(y) e^{-t(y)} = e^{(r-1)\log t(y) + \log t&#39;(y) - t(y)}.\]</span></p>
<p>The proof of this follows from a simple univariate density transformation theorem,
but see also the original paper <span class="citation">Marsaglia and Tsang (<a href="#ref-Marsaglia:2000">2000</a>)</span> that proposed the rejection
sampler discussed in this section. The density <span class="math inline">\(f\)</span> will be the <em>target density</em>
for a rejection sampler.</p>
<p>With
<span class="math display">\[f(y) \propto e^{(r-1)\log t(y) + \log t&#39;(y) - t(y)},\]</span>
<span class="math inline">\(a = r - 1/3\)</span> and <span class="math inline">\(b = 1/(3 \sqrt{a})\)</span>
<span class="math display">\[f(y) \propto e^{a \log t(y)/a - t(y) + a \log a} \propto \underbrace{e^{a \log t(y)/a - t(y) + a}}_{q(y)}.\]</span></p>
<p>An analysis of <span class="math inline">\(w(y) := - y^2/2 - \log q(y)\)</span> shows that it is convex on <span class="math inline">\((-b^{-1}, \infty)\)</span>
and it attains its minimum in <span class="math inline">\(0\)</span> with <span class="math inline">\(w(0) = 0\)</span>, whence
<span class="math display">\[q(y) \leq e^{-y^2/2}.\]</span>
This gives us an envelope expressed in terms of unnormalized densities
with <span class="math inline">\(\alpha&#39; = 1\)</span>.</p>
<p>The implementation of a rejection sampler based on this analysis is relatively
straightforward. The rejection sampler will simulate from the distribution
with density <span class="math inline">\(f\)</span> by simulating from the Gaussian distribution (the envelope).
For the rejection step we need to implement <span class="math inline">\(q\)</span>. Finally, we also need
to implement <span class="math inline">\(t\)</span> to transform the result from the rejection sampler to be
gamma distributed. The rejection sampler is otherwise implemented as for
the non-vectorized von Mises distribution. To investigate rejection probabilities below
we additionally implement the possibility of printing out some tracing
information.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" data-line-number="1"><span class="co">## r &gt;= 1 </span></a>
<a class="sourceLine" id="cb182-2" data-line-number="2">tfun &lt;-<span class="st"> </span><span class="cf">function</span>(y, a) {</a>
<a class="sourceLine" id="cb182-3" data-line-number="3">  b &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(a))</a>
<a class="sourceLine" id="cb182-4" data-line-number="4">  (y <span class="op">&gt;</span><span class="st"> </span><span class="dv">-1</span><span class="op">/</span>b) <span class="op">*</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span>y)<span class="op">^</span><span class="dv">3</span>  <span class="co">## 0 when y &lt;= -1/b</span></a>
<a class="sourceLine" id="cb182-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb182-6" data-line-number="6"></a>
<a class="sourceLine" id="cb182-7" data-line-number="7">qfun &lt;-<span class="st"> </span><span class="cf">function</span>(y, r) {</a>
<a class="sourceLine" id="cb182-8" data-line-number="8">  a &lt;-<span class="st"> </span>r <span class="op">-</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span></a>
<a class="sourceLine" id="cb182-9" data-line-number="9">  tval &lt;-<span class="st"> </span><span class="kw">tfun</span>(y, a)</a>
<a class="sourceLine" id="cb182-10" data-line-number="10">  <span class="kw">exp</span>(a <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(tval <span class="op">/</span><span class="st"> </span>a) <span class="op">-</span><span class="st"> </span>tval <span class="op">+</span><span class="st"> </span>a)</a>
<a class="sourceLine" id="cb182-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb182-12" data-line-number="12"></a>
<a class="sourceLine" id="cb182-13" data-line-number="13">gammasim &lt;-<span class="st"> </span><span class="cf">function</span>(n, r, <span class="dt">trace =</span> <span class="ot">FALSE</span>) {</a>
<a class="sourceLine" id="cb182-14" data-line-number="14">  count &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb182-15" data-line-number="15">  y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)</a>
<a class="sourceLine" id="cb182-16" data-line-number="16">  y0 &lt;-<span class="st"> </span><span class="kw">rng_stream</span>(n, rnorm)</a>
<a class="sourceLine" id="cb182-17" data-line-number="17">  u &lt;-<span class="st"> </span><span class="kw">rng_stream</span>(n, runif)</a>
<a class="sourceLine" id="cb182-18" data-line-number="18">  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb182-19" data-line-number="19">    reject &lt;-<span class="st"> </span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb182-20" data-line-number="20">    <span class="cf">while</span>(reject) {</a>
<a class="sourceLine" id="cb182-21" data-line-number="21">      count &lt;-<span class="st"> </span>count <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb182-22" data-line-number="22">      z &lt;-<span class="st"> </span><span class="kw">y0</span>(n <span class="op">-</span><span class="st"> </span>i)</a>
<a class="sourceLine" id="cb182-23" data-line-number="23">      reject &lt;-<span class="st"> </span><span class="kw">u</span>(n <span class="op">-</span><span class="st"> </span>i) <span class="op">&gt;</span><span class="st"> </span><span class="kw">qfun</span>(z, r) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(z<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb182-24" data-line-number="24">    }</a>
<a class="sourceLine" id="cb182-25" data-line-number="25">    y[i] &lt;-<span class="st"> </span>z</a>
<a class="sourceLine" id="cb182-26" data-line-number="26">  }</a>
<a class="sourceLine" id="cb182-27" data-line-number="27">  <span class="cf">if</span>(trace)</a>
<a class="sourceLine" id="cb182-28" data-line-number="28">    <span class="kw">cat</span>(<span class="st">&quot;r =&quot;</span>, r, <span class="st">&quot;:&quot;</span>, (count <span class="op">-</span><span class="st"> </span>n)<span class="op">/</span><span class="st"> </span>count, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)  <span class="co">## Rejection frequency</span></a>
<a class="sourceLine" id="cb182-29" data-line-number="29">  <span class="kw">tfun</span>(y, r <span class="op">-</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb182-30" data-line-number="30">}</a></code></pre></div>
<p>We test the implementation by simulating <span class="math inline">\(100,000\)</span> values
with parameters <span class="math inline">\(r = 8\)</span> as well as <span class="math inline">\(r = 1\)</span> and compare the resulting histograms
to the respective theoretical densities.</p>
<div class="figure" style="text-align: center"><span id="fig:gammaBench"></span>
<img src="CSwR_files/figure-html/gammaBench-1.png" alt="Histograms of simulated gamma distributed variables with shape parameters $r = 8$ (left) and $r = 1$ (right) with corresponding theoretical densities (blue)." width="49%" /><img src="CSwR_files/figure-html/gammaBench-2.png" alt="Histograms of simulated gamma distributed variables with shape parameters $r = 8$ (left) and $r = 1$ (right) with corresponding theoretical densities (blue)." width="49%" />
<p class="caption">
Figure 4.4: Histograms of simulated gamma distributed variables with shape parameters <span class="math inline">\(r = 8\)</span> (left) and <span class="math inline">\(r = 1\)</span> (right) with corresponding theoretical densities (blue).
</p>
</div>
<p>Though this is only a simple and informal test, it indicates that the implementation
correctly simulates from the gamma distribution.</p>
<p>Rejection sampling can be computationally expensive if many samples are rejected.
A very tight envelope will lead to fewer rejections, while a loose envelope will
lead to many rejections. Using the tracing option as implemented we obtain
estimates of the rejection probability and thus a quantification of
how tight the envelope is.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" data-line-number="1">y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">16</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb183-2" data-line-number="2">y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">8</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb183-3" data-line-number="3">y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">4</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb183-4" data-line-number="4">y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">1</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## r = 16 : 0.001836621 
## r = 8 : 0.003606943 
## r = 4 : 0.007798702 
## r = 1 : 0.04811765</code></pre>
<p>We observe that the rejection frequencies are small with <span class="math inline">\(r = 1\)</span> being the
worst case with around 5% rejections. For the other cases the rejection
frequencies are all below 1%, thus rejection is rare.</p>
<p>A visual comparison of <span class="math inline">\(q\)</span> to the (unnormalized) Gaussian density also
shows that the two (unnormalized) densities are very close except
in the tails where there is very little probability mass.</p>
<div class="figure" style="text-align: center"><span id="fig:densComparison"></span>
<img src="CSwR_files/figure-html/densComparison-1.png" alt="Comparisons of the Gaussian proposal (red) and the target density (blue) used for eventually simulating gamma distributed variables via a transformation." width="100%" />
<p class="caption">
Figure 4.5: Comparisons of the Gaussian proposal (red) and the target density (blue) used for eventually simulating gamma distributed variables via a transformation.
</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Marsaglia:2000">
<p>Marsaglia, George, and Wai Wan Tsang. 2000. “A Simple Method for Generating Gamma Variables.” <em>ACM Trans. Math. Softw.</em> 26 (3). New York, NY, USA: ACM: 363–72. <a href="https://doi.org/10.1145/358407.358414">https://doi.org/10.1145/358407.358414</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="transformation-techniques.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="adaptive.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

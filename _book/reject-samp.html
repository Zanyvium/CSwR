<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Computational Statistics with R</title>
  <meta name="description" content="Lecture notes providing an introduction to computational statistics using the R programming language.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Computational Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Computational Statistics with R" />
  
  <meta name="twitter:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

<meta name="author" content="Niels Richard Hansen">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="transformation-techniques.html">
<link rel="next" href="adaptive.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro-smooth.html"><a href="intro-smooth.html"><i class="fa fa-check"></i><b>1.1</b> Smoothing</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro-smooth.html"><a href="intro-smooth.html#intro-angles"><i class="fa fa-check"></i><b>1.1.1</b> Angle distributions in proteins</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro-smooth.html"><a href="intro-smooth.html#using-ggplot2"><i class="fa fa-check"></i><b>1.1.2</b> Using ggplot2</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro-smooth.html"><a href="intro-smooth.html#changing-the-defaults"><i class="fa fa-check"></i><b>1.1.3</b> Changing the defaults</a></li>
<li class="chapter" data-level="1.1.4" data-path="intro-smooth.html"><a href="intro-smooth.html#large-scale-smoothing"><i class="fa fa-check"></i><b>1.1.4</b> Large scale smoothing</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html"><i class="fa fa-check"></i><b>1.2</b> Monte Carlo Methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#vM"><i class="fa fa-check"></i><b>1.2.1</b> Univariate von Mises distributions</a></li>
<li class="chapter" data-level="1.2.2" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#mixtures-of-von-mises-distributions"><i class="fa fa-check"></i><b>1.2.2</b> Mixtures of von Mises distributions</a></li>
<li class="chapter" data-level="1.2.3" data-path="monte-carlo-methods.html"><a href="monte-carlo-methods.html#large-scale-simulation"><i class="fa fa-check"></i><b>1.2.3</b> Large scale simulation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>1.3</b> Optimization</a><ul>
<li class="chapter" data-level="1.3.1" data-path="optimization.html"><a href="optimization.html#the-em-algorithm"><i class="fa fa-check"></i><b>1.3.1</b> The EM-algorithm</a></li>
<li class="chapter" data-level="1.3.2" data-path="optimization.html"><a href="optimization.html#large-scale-optimization"><i class="fa fa-check"></i><b>1.3.2</b> Large scale optimization</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.4</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#r-training-exercises"><i class="fa fa-check"></i>R training exercises</a></li>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#histograms-with-non-equidistant-breaks"><i class="fa fa-check"></i>Histograms with non-equidistant breaks</a></li>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#functions-and-functional-programming"><i class="fa fa-check"></i>Functions and functional programming</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Smoothing</b></span></li>
<li class="chapter" data-level="2" data-path="density.html"><a href="density.html"><i class="fa fa-check"></i><b>2</b> Density estimation</a><ul>
<li class="chapter" data-level="2.1" data-path="unidens.html"><a href="unidens.html"><i class="fa fa-check"></i><b>2.1</b> Univariate density estimation</a><ul>
<li class="chapter" data-level="2.1.1" data-path="unidens.html"><a href="unidens.html#likelihood"><i class="fa fa-check"></i><b>2.1.1</b> Likelihood considerations</a></li>
<li class="chapter" data-level="2.1.2" data-path="unidens.html"><a href="unidens.html#sieves"><i class="fa fa-check"></i><b>2.1.2</b> Method of sieves</a></li>
<li class="chapter" data-level="2.1.3" data-path="unidens.html"><a href="unidens.html#basis-density"><i class="fa fa-check"></i><b>2.1.3</b> Basis expansions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="kernel-density.html"><a href="kernel-density.html"><i class="fa fa-check"></i><b>2.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="kernel-density.html"><a href="kernel-density.html#implementation"><i class="fa fa-check"></i><b>2.2.1</b> Implementation</a></li>
<li class="chapter" data-level="2.2.2" data-path="kernel-density.html"><a href="kernel-density.html#benchmarking"><i class="fa fa-check"></i><b>2.2.2</b> Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bandwidth.html"><a href="bandwidth.html"><i class="fa fa-check"></i><b>2.3</b> Bandwidth selection</a><ul>
<li class="chapter" data-level="2.3.1" data-path="bandwidth.html"><a href="bandwidth.html#rectangular"><i class="fa fa-check"></i><b>2.3.1</b> Revisiting the rectangular kernel</a></li>
<li class="chapter" data-level="2.3.2" data-path="bandwidth.html"><a href="bandwidth.html#ise-mise-and-mse-for-kernel-estimators"><i class="fa fa-check"></i><b>2.3.2</b> ISE, MISE and MSE for kernel estimators</a></li>
<li class="chapter" data-level="2.3.3" data-path="bandwidth.html"><a href="bandwidth.html#plug-in-estimation-of-the-oracle-bandwidth"><i class="fa fa-check"></i><b>2.3.3</b> Plug-in estimation of the oracle bandwidth</a></li>
<li class="chapter" data-level="2.3.4" data-path="bandwidth.html"><a href="bandwidth.html#cross-validation"><i class="fa fa-check"></i><b>2.3.4</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="multivariate-smoothing.html"><a href="multivariate-smoothing.html"><i class="fa fa-check"></i><b>2.4</b> Multivariate methods</a></li>
<li class="chapter" data-level="2.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#kernel-density-estimation"><i class="fa fa-check"></i>Kernel density estimation</a></li>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#benchmarking-1"><i class="fa fa-check"></i>Benchmarking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bivariate.html"><a href="bivariate.html"><i class="fa fa-check"></i><b>3</b> Bivariate smoothing</a><ul>
<li class="chapter" data-level="3.1" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html"><i class="fa fa-check"></i><b>3.1</b> Nearest neighbor smoothers</a><ul>
<li class="chapter" data-level="3.1.1" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html#linear-smoothers"><i class="fa fa-check"></i><b>3.1.1</b> Linear smoothers</a></li>
<li class="chapter" data-level="3.1.2" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html#implementing-the-running-mean"><i class="fa fa-check"></i><b>3.1.2</b> Implementing the running mean</a></li>
<li class="chapter" data-level="3.1.3" data-path="nearest-neighbor-smoothers.html"><a href="nearest-neighbor-smoothers.html#choose-k-by-cross-validation"><i class="fa fa-check"></i><b>3.1.3</b> Choose <span class="math inline">\(k\)</span> by cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="kernel-methods.html"><a href="kernel-methods.html"><i class="fa fa-check"></i><b>3.2</b> Kernel methods</a></li>
<li class="chapter" data-level="3.3" data-path="sparse-linear-algebra.html"><a href="sparse-linear-algebra.html"><i class="fa fa-check"></i><b>3.3</b> Sparse linear algebra</a></li>
<li class="chapter" data-level="3.4" data-path="onb.html"><a href="onb.html"><i class="fa fa-check"></i><b>3.4</b> Orthogonal basis expansions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="onb.html"><a href="onb.html#polynomial-expansions"><i class="fa fa-check"></i><b>3.4.1</b> Polynomial expansions</a></li>
<li class="chapter" data-level="3.4.2" data-path="onb.html"><a href="onb.html#fourier-expansions"><i class="fa fa-check"></i><b>3.4.2</b> Fourier expansions</a></li>
<li class="chapter" data-level="3.4.3" data-path="onb.html"><a href="onb.html#wavelets"><i class="fa fa-check"></i><b>3.4.3</b> Wavelets</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>3.5</b> Splines</a><ul>
<li class="chapter" data-level="3.5.1" data-path="splines.html"><a href="splines.html#smoothing-splines"><i class="fa fa-check"></i><b>3.5.1</b> Smoothing splines</a></li>
<li class="chapter" data-level="3.5.2" data-path="splines.html"><a href="splines.html#splines-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Splines in R</a></li>
<li class="chapter" data-level="3.5.3" data-path="splines.html"><a href="splines.html#efficient-computation-with-splines"><i class="fa fa-check"></i><b>3.5.3</b> Efficient computation with splines</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="gaussian-processes.html"><a href="gaussian-processes.html"><i class="fa fa-check"></i><b>3.6</b> Gaussian processes</a></li>
<li class="chapter" data-level="3.7" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html"><i class="fa fa-check"></i><b>3.7</b> The Kalman filter</a><ul>
<li class="chapter" data-level="3.7.1" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#ar1-example"><i class="fa fa-check"></i><b>3.7.1</b> AR(1)-example</a></li>
<li class="chapter" data-level="3.7.2" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#the-kalman-smoother"><i class="fa fa-check"></i><b>3.7.2</b> The Kalman smoother</a></li>
<li class="chapter" data-level="3.7.3" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#implementation-1"><i class="fa fa-check"></i><b>3.7.3</b> Implementation</a></li>
<li class="chapter" data-level="3.7.4" data-path="the-kalman-filter.html"><a href="the-kalman-filter.html#the-kalman-filter-1"><i class="fa fa-check"></i><b>3.7.4</b> The Kalman filter</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Monte Carlo Methods</b></span></li>
<li class="chapter" data-level="4" data-path="univariate-random-variables.html"><a href="univariate-random-variables.html"><i class="fa fa-check"></i><b>4</b> Univariate random variables</a><ul>
<li class="chapter" data-level="4.1" data-path="pseudo-random-numbers.html"><a href="pseudo-random-numbers.html"><i class="fa fa-check"></i><b>4.1</b> Pseudo random numbers</a></li>
<li class="chapter" data-level="4.2" data-path="transformation-techniques.html"><a href="transformation-techniques.html"><i class="fa fa-check"></i><b>4.2</b> Transformation techniques</a><ul>
<li class="chapter" data-level="4.2.1" data-path="transformation-techniques.html"><a href="transformation-techniques.html#sampling-from-a-t-distribution"><i class="fa fa-check"></i><b>4.2.1</b> Sampling from a <span class="math inline">\(t\)</span>-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="reject-samp.html"><a href="reject-samp.html"><i class="fa fa-check"></i><b>4.3</b> Rejection sampling</a><ul>
<li class="chapter" data-level="4.3.1" data-path="reject-samp.html"><a href="reject-samp.html#vMsim"><i class="fa fa-check"></i><b>4.3.1</b> von Mises distribution</a></li>
<li class="chapter" data-level="4.3.2" data-path="reject-samp.html"><a href="reject-samp.html#gamma-distribution"><i class="fa fa-check"></i><b>4.3.2</b> Gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="adaptive.html"><a href="adaptive.html"><i class="fa fa-check"></i><b>4.4</b> Adaptive envelopes</a><ul>
<li class="chapter" data-level="4.4.1" data-path="adaptive.html"><a href="adaptive.html#beta-distribution"><i class="fa fa-check"></i><b>4.4.1</b> Beta distribution</a></li>
<li class="chapter" data-level="4.4.2" data-path="adaptive.html"><a href="adaptive.html#von-mises-distribution"><i class="fa fa-check"></i><b>4.4.2</b> von Mises distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.5</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#rejection-sampling-of-gaussian-random-variables"><i class="fa fa-check"></i>Rejection sampling of Gaussian random variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="MCI.html"><a href="MCI.html"><i class="fa fa-check"></i><b>5</b> Monte Carlo integration</a><ul>
<li class="chapter" data-level="5.1" data-path="assessment.html"><a href="assessment.html"><i class="fa fa-check"></i><b>5.1</b> Assessment</a><ul>
<li class="chapter" data-level="5.1.1" data-path="assessment.html"><a href="assessment.html#using-the-central-limit-theorem"><i class="fa fa-check"></i><b>5.1.1</b> Using the central limit theorem</a></li>
<li class="chapter" data-level="5.1.2" data-path="assessment.html"><a href="assessment.html#concentration-inequalities"><i class="fa fa-check"></i><b>5.1.2</b> Concentration inequalities</a></li>
<li class="chapter" data-level="5.1.3" data-path="assessment.html"><a href="assessment.html#exponential-tail-bound-for-gamma-distributed-variables"><i class="fa fa-check"></i><b>5.1.3</b> Exponential tail bound for Gamma distributed variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>5.2</b> Importance sampling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="importance-sampling.html"><a href="importance-sampling.html#unknown-normalization-constants"><i class="fa fa-check"></i><b>5.2.1</b> Unknown normalization constants</a></li>
<li class="chapter" data-level="5.2.2" data-path="importance-sampling.html"><a href="importance-sampling.html#computing-a-high-dimensional-integral"><i class="fa fa-check"></i><b>5.2.2</b> Computing a high-dimensional integral</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="network-failure.html"><a href="network-failure.html"><i class="fa fa-check"></i><b>5.3</b> Network failure</a><ul>
<li class="chapter" data-level="5.3.1" data-path="network-failure.html"><a href="network-failure.html#object-oriented-implementation"><i class="fa fa-check"></i><b>5.3.1</b> Object oriented implementation</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="design-of-experiments.html"><a href="design-of-experiments.html"><i class="fa fa-check"></i><b>5.4</b> Design of experiments</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-random-variables.html"><a href="multivariate-random-variables.html"><i class="fa fa-check"></i><b>6</b> Multivariate random variables</a><ul>
<li class="chapter" data-level="6.1" data-path="sequential-simulation.html"><a href="sequential-simulation.html"><i class="fa fa-check"></i><b>6.1</b> Sequential simulation</a><ul>
<li class="chapter" data-level="6.1.1" data-path="sequential-simulation.html"><a href="sequential-simulation.html#sequential-mc-for-the-ar1-process"><i class="fa fa-check"></i><b>6.1.1</b> Sequential MC for the AR(1)-process</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="gaussian-random-variables.html"><a href="gaussian-random-variables.html"><i class="fa fa-check"></i><b>6.2</b> Gaussian random variables</a></li>
</ul></li>
<li class="part"><span><b>Part III: Optimization</b></span></li>
<li class="chapter" data-level="7" data-path="five-examples.html"><a href="five-examples.html"><i class="fa fa-check"></i><b>7</b> Five Examples</a><ul>
<li class="chapter" data-level="7.1" data-path="exp-fam.html"><a href="exp-fam.html"><i class="fa fa-check"></i><b>7.1</b> Exponential families</a><ul>
<li class="chapter" data-level="7.1.1" data-path="exp-fam.html"><a href="exp-fam.html#full-exponential-families"><i class="fa fa-check"></i><b>7.1.1</b> Full exponential families</a></li>
<li class="chapter" data-level="7.1.2" data-path="exp-fam.html"><a href="exp-fam.html#exponential-family-bayesian-networks"><i class="fa fa-check"></i><b>7.1.2</b> Exponential family Bayesian networks</a></li>
<li class="chapter" data-level="7.1.3" data-path="exp-fam.html"><a href="exp-fam.html#exp-fam-deriv"><i class="fa fa-check"></i><b>7.1.3</b> Likelihood computations</a></li>
<li class="chapter" data-level="7.1.4" data-path="exp-fam.html"><a href="exp-fam.html#curved-exponential-families"><i class="fa fa-check"></i><b>7.1.4</b> Curved exponential families</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multinomial-models.html"><a href="multinomial-models.html"><i class="fa fa-check"></i><b>7.2</b> Multinomial models</a><ul>
<li class="chapter" data-level="7.2.1" data-path="multinomial-models.html"><a href="multinomial-models.html#peppered-moths"><i class="fa fa-check"></i><b>7.2.1</b> Peppered Moths</a></li>
<li class="chapter" data-level="7.2.2" data-path="multinomial-models.html"><a href="multinomial-models.html#multinomial-cell-collapsing"><i class="fa fa-check"></i><b>7.2.2</b> Multinomial cell collapsing</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>7.3</b> Regression models</a></li>
<li class="chapter" data-level="7.4" data-path="finite-mixture-models.html"><a href="finite-mixture-models.html"><i class="fa fa-check"></i><b>7.4</b> Finite mixture models</a><ul>
<li class="chapter" data-level="7.4.1" data-path="finite-mixture-models.html"><a href="finite-mixture-models.html#gaussian-mixtures"><i class="fa fa-check"></i><b>7.4.1</b> Gaussian mixtures</a></li>
<li class="chapter" data-level="7.4.2" data-path="finite-mixture-models.html"><a href="finite-mixture-models.html#von-mises-mixtures"><i class="fa fa-check"></i><b>7.4.2</b> von Mises mixtures</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>7.5</b> Mixed models</a></li>
<li class="chapter" data-level="7.6" data-path="state-space-models.html"><a href="state-space-models.html"><i class="fa fa-check"></i><b>7.6</b> State space models</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="NumOpt.html"><a href="NumOpt.html"><i class="fa fa-check"></i><b>8</b> Numerical optimization</a><ul>
<li class="chapter" data-level="8.1" data-path="gradient-based-algorithms.html"><a href="gradient-based-algorithms.html"><i class="fa fa-check"></i><b>8.1</b> Gradient based algorithms</a><ul>
<li class="chapter" data-level="8.1.1" data-path="gradient-based-algorithms.html"><a href="gradient-based-algorithms.html#gradient-descent-and-conjugate-gradient"><i class="fa fa-check"></i><b>8.1.1</b> Gradient descent and conjugate gradient</a></li>
<li class="chapter" data-level="8.1.2" data-path="gradient-based-algorithms.html"><a href="gradient-based-algorithms.html#peppered-moths-1"><i class="fa fa-check"></i><b>8.1.2</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="newton-type-algorithms.html"><a href="newton-type-algorithms.html"><i class="fa fa-check"></i><b>8.2</b> Newton-type algorithms</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="EM.html"><a href="EM.html"><i class="fa fa-check"></i><b>9</b> Expectation Maximization algorithms</a><ul>
<li class="chapter" data-level="9.1" data-path="basic-properties.html"><a href="basic-properties.html"><i class="fa fa-check"></i><b>9.1</b> Basic properties</a><ul>
<li class="chapter" data-level="9.1.1" data-path="basic-properties.html"><a href="basic-properties.html#incomplete-data-likelihood"><i class="fa fa-check"></i><b>9.1.1</b> Incomplete data likelihood</a></li>
<li class="chapter" data-level="9.1.2" data-path="basic-properties.html"><a href="basic-properties.html#the-em-algorithm-is-ascending"><i class="fa fa-check"></i><b>9.1.2</b> The EM-algorithm is ascending</a></li>
<li class="chapter" data-level="9.1.3" data-path="basic-properties.html"><a href="basic-properties.html#multinomial-cell-collapsing-1"><i class="fa fa-check"></i><b>9.1.3</b> Multinomial cell collapsing</a></li>
<li class="chapter" data-level="9.1.4" data-path="basic-properties.html"><a href="basic-properties.html#peppered-moths-e--and-m-steps"><i class="fa fa-check"></i><b>9.1.4</b> Peppered Moths E- and M-steps</a></li>
<li class="chapter" data-level="9.1.5" data-path="basic-properties.html"><a href="basic-properties.html#inside-the-em"><i class="fa fa-check"></i><b>9.1.5</b> Inside the EM</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="EM-exp.html"><a href="EM-exp.html"><i class="fa fa-check"></i><b>9.2</b> Exponential families</a></li>
<li class="chapter" data-level="9.3" data-path="fisher-information.html"><a href="fisher-information.html"><i class="fa fa-check"></i><b>9.3</b> Fisher information</a></li>
<li class="chapter" data-level="9.4" data-path="two-examples-revisited.html"><a href="two-examples-revisited.html"><i class="fa fa-check"></i><b>9.4</b> Two examples revisited</a><ul>
<li class="chapter" data-level="9.4.1" data-path="two-examples-revisited.html"><a href="two-examples-revisited.html#gaussian-mixtures-1"><i class="fa fa-check"></i><b>9.4.1</b> Gaussian mixtures</a></li>
<li class="chapter" data-level="9.4.2" data-path="two-examples-revisited.html"><a href="two-examples-revisited.html#gaussian-state-space"><i class="fa fa-check"></i><b>9.4.2</b> Gaussian state space</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="StochOpt.html"><a href="StochOpt.html"><i class="fa fa-check"></i><b>10</b> Stochastic Optimization</a><ul>
<li class="chapter" data-level="10.1" data-path="stochastic-gradient.html"><a href="stochastic-gradient.html"><i class="fa fa-check"></i><b>10.1</b> Stochastic gradient</a></li>
<li class="chapter" data-level="10.2" data-path="stochastic-em.html"><a href="stochastic-em.html"><i class="fa fa-check"></i><b>10.2</b> Stochastic EM</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reject-samp" class="section level2">
<h2><span class="header-section-number">4.3</span> Rejection sampling</h2>
<p>This section deals with a general algorithm for simulating variables from a distribution with density <span class="math inline">\(f\)</span>. We call <span class="math inline">\(f\)</span> the target density and the corresponding distribution is called the target distribution. The idea is to simulate <em>proposals</em> from a different distribution with density <span class="math inline">\(g\)</span> (the proposal distribution) and then according to a criterion decide to accept or reject the proposals. It is assumed throughout that the proposal density <span class="math inline">\(g\)</span> is a density fulfilling that</p>
<span class="math display" id="eq:gfnull">\[\begin{equation}
g(x) = 0 \Rightarrow f(x) = 0.
\tag{4.1}
\end{equation}\]</span>
<p>Let <span class="math inline">\(Y_1, Y_2, \ldots\)</span> be i.i.d. with density <span class="math inline">\(g\)</span> on <span class="math inline">\(\mathbb{R}\)</span> and <span class="math inline">\(U_1, U_2, \ldots\)</span> be i.i.d. uniformly distributed on <span class="math inline">\((0,1)\)</span> and independent of the <span class="math inline">\(Y_i\)</span>s. Define <span class="math display">\[T(\mathbf{Y}, \mathbf{U}) = Y_{\sigma}\]</span> with <span class="math display">\[\sigma = \inf\{n \geq 1 \mid U_n \leq \alpha f(Y_n) / g(Y_n)\},\]</span> for <span class="math inline">\(\alpha \in (0, 1]\)</span> and <span class="math inline">\(f\)</span> a density. Rejection sampling then consists of simulating independent pairs <span class="math inline">\((Y_n, U_n)\)</span> as long as we <em>reject</em> the proposals <span class="math inline">\(Y_n\)</span> sampled from <span class="math inline">\(g\)</span>, that is, as long as <span class="math display">\[U_n &gt; \alpha f(Y_n) / g(Y_n).\]</span> The first time we <em>accept</em> a proposal is <span class="math inline">\(\sigma\)</span>, and then we stop the sampling and return the proposal <span class="math inline">\(Y_{\sigma}\)</span>. The result is, indeed, a sample from the distribution with density <span class="math inline">\(f\)</span> as the following theorem states.</p>

<div class="theorem">
<p><span id="thm:reject" class="theorem"><strong>Theorem 4.2  </strong></span>If <span class="math inline">\(\alpha f(y) \leq g(y)\)</span> for all <span class="math inline">\(y \in \mathbb{R}\)</span> and <span class="math inline">\(\alpha &gt; 0\)</span> then the distribution of <span class="math inline">\(Y_{\sigma}\)</span> has density <span class="math inline">\(f\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Note that <span class="math inline">\(g\)</span> automatically fulfills <a href="reject-samp.html#eq:gfnull">(4.1)</a>. The formal proof decomposes the event <span class="math inline">\((Y_{\sigma} \leq y)\)</span> according to the value of <span class="math inline">\(\sigma\)</span> as follows</p>
<span class="math display">\[\begin{align}
P(Y_{\sigma} \leq y) &amp; = \sum_{n = 1}^{\infty} P(Y_{n} \leq y, \ \sigma = n) \\
&amp; = \sum_{n = 1}^{\infty} P(Y_{n} \leq y, \ U_n \leq \alpha f(Y_n) / g(Y_n)) P(\sigma &gt; n - 1) \\
&amp; = P(Y_{1} \leq y, \ U_1 \leq \alpha f(Y_1) / g(Y_1)) \sum_{n = 1}^{\infty} P(\sigma &gt; n - 1).
\end{align}\]</span>
<p>By independence of the pairs <span class="math inline">\((Y_n, U_n)\)</span> we find that <span class="math display">\[P(\sigma &gt; n - 1) = p^{(n-1)}\]</span> where <span class="math inline">\(p = P(U_1 &gt; \alpha f(Y_1) / g(Y_1))\)</span>, and <span class="math display">\[\sum_{n = 1}^{\infty} P(\sigma &gt; n - 1) = \sum_{n = 1}^{\infty} p^{(n-1)} = \frac{1}{1 - p}.\]</span></p>
<p>We further find using Tonelli’s theorem that</p>
<span class="math display">\[\begin{align}
P(Y_{1} \leq y, \ U_1 \leq \alpha f(Y_1) / g(Y_1)) &amp; = \int_{-\infty}^y \alpha \frac{f(z)}{g(z)} g(z) \mathrm{d}z \\
&amp; = \alpha \int_{-\infty}^y f(z) \mathrm{d} z.
\end{align}\]</span>
<p>It also follows from this, by taking <span class="math inline">\(y = \infty\)</span>, that <span class="math inline">\(1 - p = \alpha\)</span>, and we conclude that <span class="math display">\[P(Y_{\sigma} \leq y) = \int_{-\infty}^y f(z) \mathrm{d} z,\]</span> and the density for the distribution of <span class="math inline">\(Y_{\sigma}\)</span> is, indeed, <span class="math inline">\(f\)</span>.</p>
</div>

<p>Note that if <span class="math inline">\(\alpha f \leq g\)</span> for <em>densities</em> <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>, then <span class="math display">\[\alpha = \int \alpha f(x) \mathrm{d}x \leq \int g(x) \mathrm{d}x = 1,\]</span> whence it follows automatically that <span class="math inline">\(\alpha \leq 1\)</span> whenever <span class="math inline">\(\alpha f\)</span> is dominated by <span class="math inline">\(g\)</span>. The function <span class="math inline">\(g/\alpha\)</span> is called the <em>envelope</em> of <span class="math inline">\(f\)</span>. The tighter the envelope, the smaller is the probability of rejecting a sample from <span class="math inline">\(g\)</span>, and this is quantified explicitly by <span class="math inline">\(\alpha\)</span> as <span class="math inline">\(1 - \alpha\)</span> is the rejection probability. Thus <span class="math inline">\(\alpha\)</span> should preferably be as close to one as possible.</p>
<p>If <span class="math inline">\(f(y) = c q(y)\)</span> and <span class="math inline">\(g(y) = d p(y)\)</span> for (unknown) normalizing constants <span class="math inline">\(c, d &gt; 0\)</span> and <span class="math inline">\(\alpha&#39; q \leq p\)</span> for <span class="math inline">\(\alpha&#39; &gt; 0\)</span> then <span class="math display">\[\underbrace{\left(\frac{\alpha&#39; d}{c}\right)}_{= \alpha} \ f \leq g.\]</span> The constant <span class="math inline">\(\alpha&#39;\)</span> may be larger than 1, but from the argument above we know that <span class="math inline">\(\alpha \leq 1\)</span>, and Theorem <a href="reject-samp.html#thm:reject">4.2</a> gives that <span class="math inline">\(Y_{\sigma}\)</span> has distribution with density <span class="math inline">\(f\)</span>. It appears that we need to compute the normalizing constants to implement rejection sampling. However, observe that <span class="math display">\[u \leq \frac{\alpha f(y)}{g(y)} \Leftrightarrow u \leq \frac{\alpha&#39; q(y)}{p(y)},\]</span> whence rejection sampling can actually be implemented with knowledge of the unnormalized densities and <span class="math inline">\(\alpha&#39;\)</span> only and without computing <span class="math inline">\(c\)</span> or <span class="math inline">\(d\)</span>. This is one great advantage of rejection sampling, though we should note that when we don’t know the normalizing constants, <span class="math inline">\(\alpha&#39;\)</span> does not tell us anything about how tight the envelope is, and thus how small the rejection probability is.</p>
<p>Given two functions <span class="math inline">\(q\)</span> and <span class="math inline">\(p\)</span>, how do we then find <span class="math inline">\(\alpha&#39;\)</span> so that <span class="math inline">\(\alpha&#39; q \leq p\)</span>? Consider the function <span class="math display">\[y \mapsto \frac{p(y)}{q(y)}\]</span> for <span class="math inline">\(q(y) &gt; 0\)</span>. If this function is lower bounded by a value strictly larger than zero, we can take <span class="math display">\[\alpha&#39; = \inf_{y: q(y) &gt; 0} \frac{p(y)}{q(y)} &gt; 0.\]</span> We can in practice often find this value by minimizing <span class="math inline">\(p(y)/q(y)\)</span>. If the minimum is zero, there is no <span class="math inline">\(\alpha&#39;\)</span>, and <span class="math inline">\(p\)</span> cannot be used to construct an envelope. If the minimum is strictly positive it is the best possible choice of <span class="math inline">\(\alpha&#39;\)</span>.</p>
<div id="vMsim" class="section level3">
<h3><span class="header-section-number">4.3.1</span> von Mises distribution</h3>
<p>Recall the <a href="monte-carlo-methods.html#vM">von Mises distribution</a> from Section <a href="monte-carlo-methods.html#vM">1.2.1</a>. It is a distribution on <span class="math inline">\((-\pi, \pi]\)</span> with density <span class="math display">\[f(x) \propto e^{\kappa \cos(x - \mu)}\]</span> for parameters <span class="math inline">\(\kappa &gt; 0\)</span> and <span class="math inline">\(\mu \in (-\pi, \pi]\)</span>. Clearly, <span class="math inline">\(\mu\)</span> is a location parameter, and we fix <span class="math inline">\(\mu = 0\)</span> in the following. Simulating random variables with <span class="math inline">\(\mu \neq 0\)</span> can be achieved by (wrapped) translation of variables with <span class="math inline">\(\mu = 0\)</span>.</p>
<p>Thus the target density is <span class="math inline">\(f(x) \propto e^{\kappa \cos(x)}\)</span>. In this section we will use the uniform distribution on <span class="math inline">\((-\pi, \pi)\)</span> as proposal distribution. It has constant density <span class="math inline">\(g(x) = (2\pi)^{-1}\)</span>, but all we need is, in fact, that <span class="math inline">\(g(x) \propto 1\)</span>. Since <span class="math inline">\(x \mapsto 1 / \exp(\kappa \cos(x)) = \exp(-\kappa \cos(x))\)</span> attains its minimum <span class="math inline">\(\exp(-\kappa)\)</span> for <span class="math inline">\(x = 0\)</span>, we find that <span class="math display">\[\alpha&#39; e^{\kappa \cos(x)} = e^{\kappa(\cos(x) - 1)} \leq 1,\]</span> with <span class="math inline">\(\alpha&#39; = \exp(-\kappa)\)</span>. The rejection test of the proposal <span class="math inline">\(Y \sim g\)</span> can therefore be carried out by testing if a uniformly distributed random variable <span class="math inline">\(U\)</span> on <span class="math inline">\((0,1)\)</span> satisfies <span class="math display">\[U &gt; e^{\kappa(\cos(Y) - 1)}.\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vMsim &lt;-<span class="st"> </span><span class="cf">function</span>(n, kappa) {
  y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
    ratio &lt;-<span class="st"> </span><span class="dv">0</span> 
    u &lt;-<span class="st"> </span><span class="dv">1</span>
    <span class="cf">while</span>(u <span class="op">&gt;</span><span class="st"> </span>ratio) {
      y0 &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="op">-</span><span class="st"> </span>pi, pi)
      ratio &lt;-<span class="st"> </span><span class="kw">exp</span>(kappa <span class="op">*</span><span class="st"> </span>(<span class="kw">cos</span>(y0) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
      u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>)
    }
    y[i] &lt;-<span class="st"> </span>y0
  }
  y
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(x, k) <span class="kw">exp</span>(k <span class="op">*</span><span class="st"> </span><span class="kw">cos</span>(x)) <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span><span class="kw">besselI</span>(k, <span class="dv">0</span>))
x &lt;-<span class="st"> </span><span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="fl">0.5</span>)
<span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="fl">0.5</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)
x &lt;-<span class="st"> </span><span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="dv">2</span>)
<span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="dv">2</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vMsim"></span>
<img src="CSwR_files/figure-html/vMsim-1.png" alt="Histograms of 100000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right). The true densities (blue) are added to the plots." width="50%" /><img src="CSwR_files/figure-html/vMsim-2.png" alt="Histograms of 100000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right). The true densities (blue) are added to the plots." width="50%" />
<p class="caption">
Figure 4.1: Histograms of 100000 simulated data points from von Mises distributions with parameters <span class="math inline">\(\kappa = 0.5\)</span> (left) and <span class="math inline">\(\kappa = 2\)</span> (right). The true densities (blue) are added to the plots.
</p>
</div>

<p>Figure <a href="reject-samp.html#fig:vMsim">4.1</a> confirms that the implementation simulates from the von Mises distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(<span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>))</code></pre></div>
<pre><code>##    user  system elapsed 
##   2.271   0.396   2.680</code></pre>
<p>Though the implementation can easily simulate 100000 variables in a couple of seconds, it might still be possible to improve it. To investigate what most of the run time is spent on we use the line profiling tool as implemented in the profvis package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(profvis)
<span class="kw">profvis</span>(<span class="kw">vMsim</span>(<span class="dv">10000</span>, <span class="dv">5</span>))</code></pre></div>
<p><img src="figures/vMsim-profile.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The <a href="vMsim-profile.html">profiling result</a> shows that almost all the time is spent on simulating uniformly distributed random variables. It is, perhaps, expected that this should take some time, but that it takes so much more time than computing the ratio, say, used for the rejection test is a bit surprising. What might be even more surprising is the large amount of memory allocation and deallocation associated with the simulation of the variables.</p>
<p>The culprit is <code>runif</code> that has some overhead associated with each call. The function performs much better if called once to return a vector than if called repeatedly as above to return just single numbers. We can rewrite the rejection sampler to make better use of <code>runif</code>, but it does make the function a bit more complicated because we don’t know upfront how many uniform variables we need. For later usage we add the possibility of printing out some tracing information.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vMsim &lt;-<span class="st"> </span><span class="cf">function</span>(n, kappa, <span class="dt">trace =</span> <span class="ot">FALSE</span>) {
  m &lt;-<span class="st"> </span>n  
  fact &lt;-<span class="st"> </span><span class="dv">1</span>
  count &lt;-<span class="st"> </span><span class="dv">0</span>
  j &lt;-<span class="st"> </span><span class="dv">1</span>
  y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
  y0 &lt;-<span class="st"> </span><span class="kw">runif</span>(m, <span class="op">-</span><span class="st"> </span>pi, pi)
  u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
    <span class="cf">repeat</span> {
      z &lt;-<span class="st"> </span>y0[j]
      accept &lt;-<span class="st"> </span>u[j] <span class="op">&lt;=</span><span class="st"> </span><span class="kw">exp</span>(kappa <span class="op">*</span><span class="st"> </span>(<span class="kw">cos</span>(z) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
      j &lt;-<span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
      count &lt;-<span class="st"> </span>count <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
      <span class="cf">if</span>(j <span class="op">&gt;</span><span class="st"> </span>m) {
        <span class="cf">if</span>(fact <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) fact &lt;-<span class="st"> </span>n <span class="op">/</span><span class="st"> </span>i
        m &lt;-<span class="st"> </span><span class="kw">floor</span>(fact <span class="op">*</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span>))
        y0 &lt;-<span class="st"> </span><span class="kw">runif</span>(m, <span class="op">-</span><span class="st"> </span>pi, pi)
        u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)
        j &lt;-<span class="st"> </span><span class="dv">1</span>
      }
      <span class="cf">if</span>(accept) <span class="cf">break</span>
    }
    y[i] &lt;-<span class="st"> </span>z
  }
  <span class="cf">if</span>(trace)
    <span class="kw">cat</span>(<span class="st">&quot;kappa =&quot;</span>, kappa, <span class="st">&quot;:&quot;</span>, (count <span class="op">-</span><span class="st"> </span>n)<span class="op">/</span><span class="st"> </span>count, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)  ## Rejection frequency
  y
}</code></pre></div>
<p>The implementation above generates new vectors of uniform random variables whenever it “runs out”. The first time it needs to do so it estimates a factor of how many variables is needed per accept, and then it generates the estimated number of variables needed. This may be repeated a couple of times.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(<span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="dt">kappa =</span> <span class="dv">5</span>))</code></pre></div>
<pre><code>##    user  system elapsed 
##   0.193   0.004   0.197</code></pre>
<p>As we see from the time estimate above, using a vectorized call of <code>runif</code> reduces the run time by more than a factor 10.</p>
<p>We should, of course, remember to test that the new implementation still generates variables from the von Mises distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="fl">0.5</span>)
<span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="fl">0.5</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)
x &lt;-<span class="st"> </span><span class="kw">vMsim</span>(<span class="dv">100000</span>, <span class="dv">2</span>)
<span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">20</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">f</span>(x, <span class="dv">2</span>), <span class="op">-</span>pi, pi, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vMsim2"></span>
<img src="CSwR_files/figure-html/vMsim2-1.png" alt="Histograms of 100000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using the fast implementation." width="50%" /><img src="CSwR_files/figure-html/vMsim2-2.png" alt="Histograms of 100000 simulated data points from von Mises distributions with parameters \(\kappa = 0.5\) (left) and \(\kappa = 2\) (right), simulated using the fast implementation." width="50%" />
<p class="caption">
Figure 4.2: Histograms of 100000 simulated data points from von Mises distributions with parameters <span class="math inline">\(\kappa = 0.5\)</span> (left) and <span class="math inline">\(\kappa = 2\)</span> (right), simulated using the fast implementation.
</p>
</div>

</div>
<div id="gamma-distribution" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Gamma distribution</h3>
<p>It may be possible to find a suitable envelope of the density for the gamma distribution on <span class="math inline">\((0, \infty)\)</span>, but it turns out that there is a very efficient rejection sampler of a non-standard distribution that can be transformed into a gamma distribution by a simple transformation.</p>
<p>Let <span class="math inline">\(t(y) = a(1 + by)^3\)</span> for <span class="math inline">\(y \in (-b^{-1}, \infty)\)</span>, then <span class="math inline">\(t(Y) \sim \Gamma(r,1)\)</span> if <span class="math inline">\(r \geq 1\)</span> and <span class="math inline">\(Y\)</span> has density <span class="math display">\[f(y) \propto t(y)^{r-1}t&#39;(y) e^{-t(y)} = e^{(r-1)\log t(y) + \log t&#39;(y) - t(y)}.\]</span></p>
<p>[Proof: Use univariate density transformation theorem.]</p>
<p>The density <span class="math inline">\(f\)</span> will be the <em>target density</em> for a rejection sampler.</p>
<p>With <span class="math display">\[f(y) \propto e^{(r-1)\log t(y) + \log t&#39;(y) - t(y)},\]</span> <span class="math inline">\(a = r - 1/3\)</span> and <span class="math inline">\(b = 1/(3 \sqrt{a})\)</span> <span class="math display">\[f(y) \propto e^{a \log t(y)/a - t(y) + a \log a} \propto \underbrace{e^{a \log t(y)/a - t(y) + a}}_{q(y)}.\]</span></p>
<p>An analysis of <span class="math inline">\(w(y) := - y^2/2 - \log q(y)\)</span> shows that it is convex on <span class="math inline">\((-b^{-1}, \infty)\)</span> and it attains its minimum in <span class="math inline">\(0\)</span> with <span class="math inline">\(w(0) = 0\)</span>, whence <span class="math display">\[q(y) \leq e^{-y^2/2}.\]</span> This gives us an envelope expressed in terms of unnormalized densities with <span class="math inline">\(\alpha&#39; = 1\)</span>.</p>
<p>The implementation of a rejection sampler based on this analysis is relatively straightforward. The rejection sampler will simulate from the distribution with density <span class="math inline">\(f\)</span> by simulating from the Gaussian distribution (the envelope). For the rejection step we need to implement <span class="math inline">\(q\)</span>. Finally, we also need to implement <span class="math inline">\(t\)</span> to transform the result from the rejection sampler to be gamma distributed. The rejection sampler is otherwise implemented as for the von Mises distribution. To investigate rejection probabilities below we additionally implement the possibility of printing out some tracing information.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## r &gt;= 1 
tfun &lt;-<span class="st"> </span><span class="cf">function</span>(y, a) {
  b &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(a))
  (y <span class="op">&gt;</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span><span class="op">/</span>b) <span class="op">*</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span>y)<span class="op">^</span><span class="dv">3</span>  ## 0 when y &lt;= -1/b
}

qfun &lt;-<span class="st"> </span><span class="cf">function</span>(y, r) {
  a &lt;-<span class="st"> </span>r <span class="op">-</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span>
  tval &lt;-<span class="st"> </span><span class="kw">tfun</span>(y, a)
  <span class="kw">exp</span>(a <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(tval <span class="op">/</span><span class="st"> </span>a) <span class="op">-</span><span class="st"> </span>tval <span class="op">+</span><span class="st"> </span>a)
}

gammasim &lt;-<span class="st"> </span><span class="cf">function</span>(n, r, <span class="dt">trace =</span> <span class="ot">FALSE</span>) {
  m &lt;-<span class="st"> </span>n  
  fact &lt;-<span class="st"> </span><span class="dv">1</span>
  count &lt;-<span class="st"> </span><span class="dv">0</span>
  j &lt;-<span class="st"> </span><span class="dv">1</span>
  y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
  y0 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(m)
  u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)
  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
    <span class="cf">repeat</span> {
      z &lt;-<span class="st"> </span>y0[j]
      accept &lt;-<span class="st"> </span>u[j] <span class="op">&lt;=</span><span class="st"> </span><span class="kw">qfun</span>(z, r) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(z<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)
      j &lt;-<span class="st"> </span>j <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
      count &lt;-<span class="st"> </span>count <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
      <span class="cf">if</span>(j <span class="op">&gt;</span><span class="st"> </span>m) {
        <span class="cf">if</span>(fact <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) fact &lt;-<span class="st"> </span>n <span class="op">/</span><span class="st"> </span>i
        m &lt;-<span class="st"> </span><span class="kw">floor</span>(fact <span class="op">*</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span>))
        y0 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(m)
        u &lt;-<span class="st"> </span><span class="kw">runif</span>(m)
        j &lt;-<span class="st"> </span><span class="dv">1</span>
      }
      <span class="cf">if</span>(accept) <span class="cf">break</span>
    }
    y[i] &lt;-<span class="st"> </span>z
  }
  <span class="cf">if</span>(trace)
      <span class="kw">cat</span>(<span class="st">&quot;r =&quot;</span>, r, <span class="st">&quot;:&quot;</span>, (count <span class="op">-</span><span class="st"> </span>n)<span class="op">/</span><span class="st"> </span>count, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)  ## Rejection frequency
  <span class="kw">tfun</span>(y, r <span class="op">-</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)
}</code></pre></div>
<p>We test the implementation by simulating 100000 values with parameters <span class="math inline">\(r = 8\)</span> as well as <span class="math inline">\(r = 1\)</span> and compare the resulting histograms to the respective theoretical densities.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">8</span>))</code></pre></div>
<pre><code>##    user  system elapsed 
##   0.202   0.018   0.222</code></pre>
<p><img src="CSwR_files/figure-html/gammaBench-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">1</span>))</code></pre></div>
<pre><code>##    user  system elapsed 
##   0.174   0.001   0.175</code></pre>
<p><img src="CSwR_files/figure-html/gammaBench2-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Though this is only a simple and informal test, it indicates that the implementation correctly simulates from the gamma distribution.</p>
<p>Rejection sampling can be computationally expensive if many samples are rejected. A very tight envelope will lead to fewer rejections, while a loose envelope will lead to many rejections. Using the tracing option as implemented we obtain estimates of the rejection probability and thus a quantification of how tight the envelope is.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">16</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)
y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">8</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)
y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">4</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)
y &lt;-<span class="st"> </span><span class="kw">gammasim</span>(<span class="dv">100000</span>, <span class="dv">1</span>, <span class="dt">trace =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## r = 16 : 0.002105557 
## r = 8 : 0.003507653 
## r = 4 : 0.008133307 
## r = 1 : 0.04815389</code></pre>
<p>We observe that the rejection frequencies are small with <span class="math inline">\(r = 1\)</span> being the worst case with around 5% rejections. For the other cases the rejection frequencies are all below 1%, thus rejection is rare.</p>
<p>A visual comparison of <span class="math inline">\(q\)</span> to the (unnormalized) Gaussian density also shows that the two (unnormalized) densities are very close except in the tails where there is very little probability mass.</p>
<div class="figure" style="text-align: center"><span id="fig:densComparison"></span>
<img src="CSwR_files/figure-html/densComparison-1.png" alt="Comparisons of the Gaussian proposal (red) and the target density (blue) used for eventually simulating gamma distributed variables via a transformation." width="100%" />
<p class="caption">
Figure 4.3: Comparisons of the Gaussian proposal (red) and the target density (blue) used for eventually simulating gamma distributed variables via a transformation.
</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="transformation-techniques.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="adaptive.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

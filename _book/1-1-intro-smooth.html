<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Smoothing | Computational Statistics with R</title>
  <meta name="description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Smoothing | Computational Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Smoothing | Computational Statistics with R" />
  
  <meta name="twitter:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

<meta name="author" content="Niels Richard Hansen" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="1-intro.html"/>
<link rel="next" href="1-2-monte-carlo-methods.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-intro.html"><a href="1-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html"><i class="fa fa-check"></i><b>1.1</b> Smoothing</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#intro-angles"><i class="fa fa-check"></i><b>1.1.1</b> Angle distributions in proteins</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#using-ggplot2"><i class="fa fa-check"></i><b>1.1.2</b> Using ggplot2</a></li>
<li class="chapter" data-level="1.1.3" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#changing-the-defaults"><i class="fa fa-check"></i><b>1.1.3</b> Changing the defaults</a></li>
<li class="chapter" data-level="1.1.4" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#multivariate-smoothing"><i class="fa fa-check"></i><b>1.1.4</b> Multivariate methods</a></li>
<li class="chapter" data-level="1.1.5" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#large-scale-smoothing"><i class="fa fa-check"></i><b>1.1.5</b> Large scale smoothing</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html"><i class="fa fa-check"></i><b>1.2</b> Monte Carlo methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html#vM"><i class="fa fa-check"></i><b>1.2.1</b> Univariate von Mises distributions</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html#mixtures-of-von-mises-distributions"><i class="fa fa-check"></i><b>1.2.2</b> Mixtures of von Mises distributions</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html#large-scale-monte-carlo-methods"><i class="fa fa-check"></i><b>1.2.3</b> Large scale Monte Carlo methods</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-3-optimization.html"><a href="1-3-optimization.html"><i class="fa fa-check"></i><b>1.3</b> Optimization</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-3-optimization.html"><a href="1-3-optimization.html#the-em-algorithm"><i class="fa fa-check"></i><b>1.3.1</b> The EM-algorithm</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-3-optimization.html"><a href="1-3-optimization.html#large-scale-optimization"><i class="fa fa-check"></i><b>1.3.2</b> Large scale optimization</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Smoothing</b></span></li>
<li class="chapter" data-level="2" data-path="2-density.html"><a href="2-density.html"><i class="fa fa-check"></i><b>2</b> Density estimation</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-unidens.html"><a href="2-1-unidens.html"><i class="fa fa-check"></i><b>2.1</b> Univariate density estimation</a></li>
<li class="chapter" data-level="2.2" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html"><i class="fa fa-check"></i><b>2.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html#implementation"><i class="fa fa-check"></i><b>2.2.1</b> Implementation</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html#benchmarking"><i class="fa fa-check"></i><b>2.2.2</b> Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html"><i class="fa fa-check"></i><b>2.3</b> Bandwidth selection</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#rectangular"><i class="fa fa-check"></i><b>2.3.1</b> Revisiting the rectangular kernel</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#ise-mise-and-mse-for-kernel-estimators"><i class="fa fa-check"></i><b>2.3.2</b> ISE, MISE and MSE for kernel estimators</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#plug-in-estimation-of-the-oracle-bandwidth"><i class="fa fa-check"></i><b>2.3.3</b> Plug-in estimation of the oracle bandwidth</a></li>
<li class="chapter" data-level="2.3.4" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#cross-validation"><i class="fa fa-check"></i><b>2.3.4</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-4-likelihood.html"><a href="2-4-likelihood.html"><i class="fa fa-check"></i><b>2.4</b> Likelihood considerations</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-4-likelihood.html"><a href="2-4-likelihood.html#sieves"><i class="fa fa-check"></i><b>2.4.1</b> Method of sieves</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-4-likelihood.html"><a href="2-4-likelihood.html#basis-density"><i class="fa fa-check"></i><b>2.4.2</b> Basis expansions</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-5-density-ex.html"><a href="2-5-density-ex.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="2-5-density-ex.html"><a href="2-5-density-ex.html#kernel-density-estimation"><i class="fa fa-check"></i>Kernel density estimation</a></li>
<li class="chapter" data-level="" data-path="2-5-density-ex.html"><a href="2-5-density-ex.html#benchmarking-1"><i class="fa fa-check"></i>Benchmarking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-bivariate.html"><a href="3-bivariate.html"><i class="fa fa-check"></i><b>3</b> Bivariate smoothing</a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html"><i class="fa fa-check"></i><b>3.1</b> Nearest neighbor smoothers</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html#linear-smoothers"><i class="fa fa-check"></i><b>3.1.1</b> Linear smoothers</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html#implementing-the-running-mean"><i class="fa fa-check"></i><b>3.1.2</b> Implementing the running mean</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html#choose-k-by-cross-validation"><i class="fa fa-check"></i><b>3.1.3</b> Choose <span class="math inline">\(k\)</span> by cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-2-kernel-methods.html"><a href="3-2-kernel-methods.html"><i class="fa fa-check"></i><b>3.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-2-kernel-methods.html"><a href="3-2-kernel-methods.html#nadarayawatson-kernel-smoothing"><i class="fa fa-check"></i><b>3.2.1</b> Nadaraya–Watson kernel smoothing</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-2-kernel-methods.html"><a href="3-2-kernel-methods.html#local-regression-smoothers"><i class="fa fa-check"></i><b>3.2.2</b> Local regression smoothers</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-3-sparse-linear-algebra.html"><a href="3-3-sparse-linear-algebra.html"><i class="fa fa-check"></i><b>3.3</b> Sparse linear algebra</a></li>
<li class="chapter" data-level="3.4" data-path="3-4-onb.html"><a href="3-4-onb.html"><i class="fa fa-check"></i><b>3.4</b> Orthogonal basis expansions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-4-onb.html"><a href="3-4-onb.html#polynomial-expansions"><i class="fa fa-check"></i><b>3.4.1</b> Polynomial expansions</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-4-onb.html"><a href="3-4-onb.html#fourier-expansions"><i class="fa fa-check"></i><b>3.4.2</b> Fourier expansions</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-5-splines.html"><a href="3-5-splines.html"><i class="fa fa-check"></i><b>3.5</b> Splines</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-5-splines.html"><a href="3-5-splines.html#smoothing-splines"><i class="fa fa-check"></i><b>3.5.1</b> Smoothing splines</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-5-splines.html"><a href="3-5-splines.html#splines-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Splines in R</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-5-splines.html"><a href="3-5-splines.html#efficient-splines"><i class="fa fa-check"></i><b>3.5.3</b> Efficient computation with splines</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-6-gaussian-processes.html"><a href="3-6-gaussian-processes.html"><i class="fa fa-check"></i><b>3.6</b> Gaussian processes</a></li>
<li class="chapter" data-level="3.7" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html"><i class="fa fa-check"></i><b>3.7</b> The Kalman filter</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html#ar1-example"><i class="fa fa-check"></i><b>3.7.1</b> AR(1)-example</a></li>
<li class="chapter" data-level="3.7.2" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html#the-kalman-smoother"><i class="fa fa-check"></i><b>3.7.2</b> The Kalman smoother</a></li>
<li class="chapter" data-level="3.7.3" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html#implementation"><i class="fa fa-check"></i><b>3.7.3</b> Implementation</a></li>
<li class="chapter" data-level="3.7.4" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html#the-kalman-filter-1"><i class="fa fa-check"></i><b>3.7.4</b> The Kalman filter</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3-8-bivariate-ex.html"><a href="3-8-bivariate-ex.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="3-8-bivariate-ex.html"><a href="3-8-bivariate-ex.html#nearest-neighbors"><i class="fa fa-check"></i>Nearest neighbors</a></li>
<li class="chapter" data-level="" data-path="3-8-bivariate-ex.html"><a href="3-8-bivariate-ex.html#kernel-estimators"><i class="fa fa-check"></i>Kernel estimators</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Monte Carlo Methods</b></span></li>
<li class="chapter" data-level="4" data-path="4-univariate-random-variables.html"><a href="4-univariate-random-variables.html"><i class="fa fa-check"></i><b>4</b> Univariate random variables</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-pseudorandom-number-generators.html"><a href="4-1-pseudorandom-number-generators.html"><i class="fa fa-check"></i><b>4.1</b> Pseudorandom number generators</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4-1-pseudorandom-number-generators.html"><a href="4-1-pseudorandom-number-generators.html#implementing-a-pseudorandom-number-generator"><i class="fa fa-check"></i><b>4.1.1</b> Implementing a pseudorandom number generator</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-1-pseudorandom-number-generators.html"><a href="4-1-pseudorandom-number-generators.html#pseudorandom-number-packages"><i class="fa fa-check"></i><b>4.1.2</b> Pseudorandom number packages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-2-transformation-techniques.html"><a href="4-2-transformation-techniques.html"><i class="fa fa-check"></i><b>4.2</b> Transformation techniques</a><ul>
<li class="chapter" data-level="4.2.1" data-path="4-2-transformation-techniques.html"><a href="4-2-transformation-techniques.html#sampling-from-a-t-distribution"><i class="fa fa-check"></i><b>4.2.1</b> Sampling from a <span class="math inline">\(t\)</span>-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-reject-samp.html"><a href="4-3-reject-samp.html"><i class="fa fa-check"></i><b>4.3</b> Rejection sampling</a><ul>
<li class="chapter" data-level="4.3.1" data-path="4-3-reject-samp.html"><a href="4-3-reject-samp.html#vMsim"><i class="fa fa-check"></i><b>4.3.1</b> von Mises distribution</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-3-reject-samp.html"><a href="4-3-reject-samp.html#gamma-distribution"><i class="fa fa-check"></i><b>4.3.2</b> Gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-4-adaptive.html"><a href="4-4-adaptive.html"><i class="fa fa-check"></i><b>4.4</b> Adaptive envelopes</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-4-adaptive.html"><a href="4-4-adaptive.html#beta-distribution"><i class="fa fa-check"></i><b>4.4.1</b> Beta distribution</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-4-adaptive.html"><a href="4-4-adaptive.html#von-mises-distribution"><i class="fa fa-check"></i><b>4.4.2</b> von Mises distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-5-univariate-ex.html"><a href="4-5-univariate-ex.html"><i class="fa fa-check"></i><b>4.5</b> Exercises</a><ul>
<li class="chapter" data-level="4.5.1" data-path="4-5-univariate-ex.html"><a href="4-5-univariate-ex.html#rejection-sampling-of-gaussian-random-variables"><i class="fa fa-check"></i><b>4.5.1</b> Rejection sampling of Gaussian random variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-mci.html"><a href="5-mci.html"><i class="fa fa-check"></i><b>5</b> Monte Carlo integration</a><ul>
<li class="chapter" data-level="5.1" data-path="5-1-assessment.html"><a href="5-1-assessment.html"><i class="fa fa-check"></i><b>5.1</b> Assessment</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-1-assessment.html"><a href="5-1-assessment.html#using-the-central-limit-theorem"><i class="fa fa-check"></i><b>5.1.1</b> Using the central limit theorem</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-1-assessment.html"><a href="5-1-assessment.html#concentration-inequalities"><i class="fa fa-check"></i><b>5.1.2</b> Concentration inequalities</a></li>
<li class="chapter" data-level="5.1.3" data-path="5-1-assessment.html"><a href="5-1-assessment.html#exponential-tail-bound-for-gamma-distributed-variables"><i class="fa fa-check"></i><b>5.1.3</b> Exponential tail bound for Gamma distributed variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-2-importance-sampling.html"><a href="5-2-importance-sampling.html"><i class="fa fa-check"></i><b>5.2</b> Importance sampling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-2-importance-sampling.html"><a href="5-2-importance-sampling.html#unknown-normalization-constants"><i class="fa fa-check"></i><b>5.2.1</b> Unknown normalization constants</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-2-importance-sampling.html"><a href="5-2-importance-sampling.html#hd-int"><i class="fa fa-check"></i><b>5.2.2</b> Computing a high-dimensional integral</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-3-network-failure.html"><a href="5-3-network-failure.html"><i class="fa fa-check"></i><b>5.3</b> Network failure</a><ul>
<li class="chapter" data-level="5.3.1" data-path="5-3-network-failure.html"><a href="5-3-network-failure.html#object-oriented-implementation"><i class="fa fa-check"></i><b>5.3.1</b> Object oriented implementation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part III: Optimization</b></span></li>
<li class="chapter" data-level="6" data-path="6-four-examples.html"><a href="6-four-examples.html"><i class="fa fa-check"></i><b>6</b> Four Examples</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html"><i class="fa fa-check"></i><b>6.1</b> Exponential families</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#full-exponential-families"><i class="fa fa-check"></i><b>6.1.1</b> Full exponential families</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#bayes-net"><i class="fa fa-check"></i><b>6.1.2</b> Exponential family Bayesian networks</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#exp-fam-deriv"><i class="fa fa-check"></i><b>6.1.3</b> Likelihood computations</a></li>
<li class="chapter" data-level="6.1.4" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#curved-exponential-families"><i class="fa fa-check"></i><b>6.1.4</b> Curved exponential families</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-2-multinomial-models.html"><a href="6-2-multinomial-models.html"><i class="fa fa-check"></i><b>6.2</b> Multinomial models</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-2-multinomial-models.html"><a href="6-2-multinomial-models.html#pep-moth"><i class="fa fa-check"></i><b>6.2.1</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-3-regression.html"><a href="6-3-regression.html"><i class="fa fa-check"></i><b>6.3</b> Regression models</a></li>
<li class="chapter" data-level="6.4" data-path="6-4-finite-mixture-models.html"><a href="6-4-finite-mixture-models.html"><i class="fa fa-check"></i><b>6.4</b> Finite mixture models</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-4-finite-mixture-models.html"><a href="6-4-finite-mixture-models.html#Gaus-mix-ex"><i class="fa fa-check"></i><b>6.4.1</b> Gaussian mixtures</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-5-mixed-models.html"><a href="6-5-mixed-models.html"><i class="fa fa-check"></i><b>6.5</b> Mixed models</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-numopt.html"><a href="7-numopt.html"><i class="fa fa-check"></i><b>7</b> Numerical optimization</a><ul>
<li class="chapter" data-level="7.1" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html"><i class="fa fa-check"></i><b>7.1</b> Algorithms and convergence</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#descent-algorithms"><i class="fa fa-check"></i><b>7.1.1</b> Descent algorithms</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#maps-and-fixed-points"><i class="fa fa-check"></i><b>7.1.2</b> Maps and fixed points</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#convergence-rate"><i class="fa fa-check"></i><b>7.1.3</b> Convergence rate</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#stopping-criteria"><i class="fa fa-check"></i><b>7.1.4</b> Stopping criteria</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html"><i class="fa fa-check"></i><b>7.2</b> Descent direction algorithms</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#line-search"><i class="fa fa-check"></i><b>7.2.1</b> Line search</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#gradient-descent"><i class="fa fa-check"></i><b>7.2.2</b> Gradient descent</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#conjugate-gradients"><i class="fa fa-check"></i><b>7.2.3</b> Conjugate gradients</a></li>
<li class="chapter" data-level="7.2.4" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#pep-moth-descent"><i class="fa fa-check"></i><b>7.2.4</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-3-newton-type-algorithms.html"><a href="7-3-newton-type-algorithms.html"><i class="fa fa-check"></i><b>7.3</b> Newton-type algorithms</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-3-newton-type-algorithms.html"><a href="7-3-newton-type-algorithms.html#poisson-regression"><i class="fa fa-check"></i><b>7.3.1</b> Poisson regression</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-3-newton-type-algorithms.html"><a href="7-3-newton-type-algorithms.html#quasi-newton-algorithms"><i class="fa fa-check"></i><b>7.3.2</b> Quasi-Newton algorithms</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-3-newton-type-algorithms.html"><a href="7-3-newton-type-algorithms.html#sparsity"><i class="fa fa-check"></i><b>7.3.3</b> Sparsity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-4-misc-.html"><a href="7-4-misc-.html"><i class="fa fa-check"></i><b>7.4</b> Misc.</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-em.html"><a href="8-em.html"><i class="fa fa-check"></i><b>8</b> Expectation maximization algorithms</a><ul>
<li class="chapter" data-level="8.1" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html"><i class="fa fa-check"></i><b>8.1</b> Basic properties</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html#incomplete-data-likelihood"><i class="fa fa-check"></i><b>8.1.1</b> Incomplete data likelihood</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html#monotonicity-of-the-em-algorithm"><i class="fa fa-check"></i><b>8.1.2</b> Monotonicity of the EM algorithm</a></li>
<li class="chapter" data-level="8.1.3" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html#peppered-moths"><i class="fa fa-check"></i><b>8.1.3</b> Peppered moths</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-2-EM-exp.html"><a href="8-2-EM-exp.html"><i class="fa fa-check"></i><b>8.2</b> Exponential families</a></li>
<li class="chapter" data-level="8.3" data-path="8-3-fisher-information.html"><a href="8-3-fisher-information.html"><i class="fa fa-check"></i><b>8.3</b> Fisher information</a></li>
<li class="chapter" data-level="8.4" data-path="8-4-revisiting-gaussian-mixtures.html"><a href="8-4-revisiting-gaussian-mixtures.html"><i class="fa fa-check"></i><b>8.4</b> Revisiting Gaussian mixtures</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-StochOpt.html"><a href="9-StochOpt.html"><i class="fa fa-check"></i><b>9</b> Stochastic Optimization</a><ul>
<li class="chapter" data-level="9.1" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html"><i class="fa fa-check"></i><b>9.1</b> Stochastic gradient algorithms</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html#section"><i class="fa fa-check"></i><b>9.1.1</b> </a></li>
<li class="chapter" data-level="9.1.2" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html#online-stochastic-gradient-descent"><i class="fa fa-check"></i><b>9.1.2</b> Online stochastic gradient descent</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>9.1.3</b> Stochastic gradient descent</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-2-nonlinear-least-squares.html"><a href="9-2-nonlinear-least-squares.html"><i class="fa fa-check"></i><b>9.2</b> Nonlinear least squares</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-app-R.html"><a href="A-app-R.html"><i class="fa fa-check"></i><b>A</b> R programming</a><ul>
<li class="chapter" data-level="A.1" data-path="A-1-functions.html"><a href="A-1-functions.html"><i class="fa fa-check"></i><b>A.1</b> Functions</a><ul>
<li class="chapter" data-level="A.1.1" data-path="A-1-functions.html"><a href="A-1-functions.html#vectorization"><i class="fa fa-check"></i><b>A.1.1</b> Vectorization</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="A-2-objects-and-methods.html"><a href="A-2-objects-and-methods.html"><i class="fa fa-check"></i><b>A.2</b> Objects and methods</a></li>
<li class="chapter" data-level="A.3" data-path="A-3-environments.html"><a href="A-3-environments.html"><i class="fa fa-check"></i><b>A.3</b> Environments</a><ul>
<li class="chapter" data-level="A.3.1" data-path="A-3-environments.html"><a href="A-3-environments.html#function-factories"><i class="fa fa-check"></i><b>A.3.1</b> Function factories</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="A-4-performance.html"><a href="A-4-performance.html"><i class="fa fa-check"></i><b>A.4</b> Performance</a><ul>
<li class="chapter" data-level="A.4.1" data-path="A-4-performance.html"><a href="A-4-performance.html#parallel-computations"><i class="fa fa-check"></i><b>A.4.1</b> Parallel computations</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html"><i class="fa fa-check"></i><b>A.5</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#functions-1"><i class="fa fa-check"></i>Functions</a></li>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#histograms-with-non-equidistant-breaks"><i class="fa fa-check"></i>Histograms with non-equidistant breaks</a></li>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#functions-and-objects"><i class="fa fa-check"></i>Functions and objects</a></li>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#functions-and-environments"><i class="fa fa-check"></i>Functions and environments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro-smooth" class="section level2">
<h2><span class="header-section-number">1.1</span> Smoothing</h2>
<p>Smoothing is a descriptive statistical tool for summarizing data, a practical
visualization technique, as well as a nonparametric estimation methodology.
The basic idea is that data is representative of an underlying distribution
with some smoothness properties, and we would like to approximate or
estimate this underlying distribution from data.</p>
<p>There are two related but slightly different approaches. Either we attempt to estimate
a smooth density of the observed variables, or we attempt to estimate a smooth
conditional density of one variable given others. The latter can in principle
be done by computing the conditional density from a smooth estimate of the
joint density. Thus it appears that we really just need a way of
computing smooth density estimates. In practice it may, however, be better
to solve the conditional smoothing problem directly instead of solving a
strictly more complicated problem. This is particularly so, if
the conditioning variables are fixed e.g. by a design, or if our main interest is
in the conditional mean or median, say, and not the entire conditional distribution.
Conditional smoothing is dealt with in Chapter <a href="3-bivariate.html#bivariate">3</a>.</p>
<p>In this introduction we focus on the univariate case, where there really only
is one problem: smooth density estimation. Moreover, this is a very
basic problem, and one viewpoint is that we simply need to “smooth out
the jumps of the histogram”. Indeed, it does not need to be made more
sophisticated than that! Humans are able to do this quite well using just
a pen and a printed histogram, but it is a bit more complicated to automatize
such a smoothing procedure. Moreover, an automatized procedure is likely
to need calibration to yield a good tradeoff between smoothness
and data fit. This is again something that humans can do quite well
by eyeballing visualizations, but that approach does not scale,
neither in terms of the number of density estimates we want to consider,
nor in terms of going from univariate to multivariate densities.</p>
<p>If we want to really discuss how a smoothing
procedure works not just as a heuristic but also as an estimator of an
underlying density, it is necessary to formalize how to quantify
the performance of the procedure. This increases the level of
mathematical sophistication, but it allows us to discuss optimality, and
it lets us develop fully automatized procedures that do not rely on human
calibration. While human inspection of visualizations is always a good
idea, computational statistics is also about offloading humans from all
computational tasks that can be automatized. This is true for smoothing
as well, hence the need for automatic and robust smoothing
procedures that produce well calibrated results with a minimum of human effort.</p>
<div id="intro-angles" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Angle distributions in proteins</h3>
<p>We will illustrate smoothing using a small data set on angles formed between
two subsequent peptide planes in 3D protein structures. This data set is selected
because the angle distributions are multimodal and slightly non-standard, and
these properties are well suited for illustrating fundamental considerations
regarding smooth density estimation in practice.</p>

<div class="figure" style="text-align: center"><span id="fig:phipsiangles"></span>
<img src="figures/PhiPsi_creative.jpg" alt="The 3D structure of proteins is largely given by the \(\phi\)- and \(\psi\)-angles of the peptide planes. (By Dcrjsr, CC BY 3.0 via Wikimedia Commons.)" width="40%" />
<p class="caption">
Figure 1.1: The 3D structure of proteins is largely given by the <span class="math inline">\(\phi\)</span>- and <span class="math inline">\(\psi\)</span>-angles of the peptide planes. (By <a href="https://commons.wikimedia.org/wiki/File%3APhiPsi_drawing_with_plane_and_labels.jpg">Dcrjsr</a>, <a href="http://creativecommons.org/licenses/by/3.0">CC BY 3.0</a> via Wikimedia Commons.)
</p>
</div>
<p>A protein is a large molecule consisting of a backbone with carbon and nitrogen
atoms arranged sequentially:
<img src="figures/backbone.png" width="70%" style="display: block; margin: auto;" /></p>
<p>A hydrogen atom binds to each nitrogen (N) and an oxygen atom binds to each
carbon without the <span class="math inline">\(\alpha\)</span> subscript (C), see Figure <a href="1-1-intro-smooth.html#fig:phipsiangles">1.1</a>,
and such four atoms form together what is known as a peptide bond between two
alpha-carbon atoms (C<span class="math inline">\(_{\alpha}\)</span>). Each C<span class="math inline">\(_{\alpha}\)</span> atom binds a hydrogen
atom and an amino acid <em>side chain</em>. There are 20
naturally occurring amino acids in genetically encoded proteins,
each having a three letter code (such as Gly for Glycine, Pro for Proline, etc.).
The protein will typically form a complicated 3D structure determined by the
amino acids, which in turn determine the <span class="math inline">\(\phi\)</span>- and the <span class="math inline">\(\psi\)</span>-angles between
the peptide planes as shown on Figure <a href="1-1-intro-smooth.html#fig:phipsiangles">1.1</a>.</p>
<p>We will consider a small data set, <code>phipsi</code>, of experimentally determined angles from a
single protein, the human protein <a href="https://www.rcsb.org/structure/1HMP">1HMP</a>,
which is composed of two chains (denoted A and B). Figure <a href="1-1-intro-smooth.html#fig:1HMP">1.2</a> shows
the 3D structure of the protein.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="1-1-intro-smooth.html#cb1-1"></a><span class="kw">head</span>(phipsi)</span></code></pre></div>
<pre><code>##   chain  AA pos        phi        psi
## 1     A Pro   5 -1.6218794  0.2258685
## 2     A Gly   6  1.1483709 -2.8314426
## 3     A Val   7 -1.4160220  2.1190570
## 4     A Val   8 -1.4926720  2.3941331
## 5     A Ile   9 -2.1814653  1.4877618
## 6     A Ser  10 -0.7525375  2.5676186</code></pre>
<div class="figure" style="text-align: center"><span id="fig:1HMP"></span>
<img src="figures/1HMP.png" alt="The 3D structure of the atoms constituting the protein 1HMP. The colors indicate the two different chains." width="30%" />
<p class="caption">
Figure 1.2: The 3D structure of the atoms constituting the protein 1HMP. The colors indicate the two different chains.
</p>
</div>
<p>We can use base R functions such as <code>hist</code> and <code>density</code> to visualize the
marginal distributions of the two angles.</p>

<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="1-1-intro-smooth.html#cb3-1"></a><span class="kw">hist</span>(phipsi<span class="op">$</span>phi, <span class="dt">prob =</span> <span class="ot">TRUE</span>)</span>
<span id="cb3-2"><a href="1-1-intro-smooth.html#cb3-2"></a><span class="kw">rug</span>(phipsi<span class="op">$</span>phi)</span>
<span id="cb3-3"><a href="1-1-intro-smooth.html#cb3-3"></a><span class="kw">density</span>(phipsi<span class="op">$</span>phi) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb3-4"><a href="1-1-intro-smooth.html#cb3-4"></a></span>
<span id="cb3-5"><a href="1-1-intro-smooth.html#cb3-5"></a><span class="kw">hist</span>(phipsi<span class="op">$</span>psi, <span class="dt">prob =</span> <span class="ot">TRUE</span>)</span>
<span id="cb3-6"><a href="1-1-intro-smooth.html#cb3-6"></a><span class="kw">rug</span>(phipsi<span class="op">$</span>psi)</span>
<span id="cb3-7"><a href="1-1-intro-smooth.html#cb3-7"></a><span class="kw">density</span>(phipsi<span class="op">$</span>psi) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:phipsiDens"></span>
<img src="CSwR_files/figure-html/phipsiDens-1.png" alt="Histograms equipped with a rug plot and smoothed density estimate (red line) of the distribution of \(\phi\)-angles (left) and \(\psi\)-angles (right)." width="49%" /><img src="CSwR_files/figure-html/phipsiDens-2.png" alt="Histograms equipped with a rug plot and smoothed density estimate (red line) of the distribution of \(\phi\)-angles (left) and \(\psi\)-angles (right)." width="49%" />
<p class="caption">
Figure 1.3: Histograms equipped with a rug plot and smoothed density estimate (red line) of the distribution of <span class="math inline">\(\phi\)</span>-angles (left) and <span class="math inline">\(\psi\)</span>-angles (right).
</p>
</div>
<p>The smooth red density curve shown in Figure <a href="1-1-intro-smooth.html#fig:phipsiDens">1.3</a> can be thought
of as a smooth version of a histogram. It is surprisingly difficult to find
automatic smoothing procedures that perform uniformly
well – it is even quite difficult to automatically select the number and
positions of the breaks used for histograms. This is one of the important
points that is taken up in this book: how to implement good default choices
of various <em>tuning parameters</em> that are required by any smoothing procedure.</p>
</div>
<div id="using-ggplot2" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Using ggplot2</h3>
<p>It is also possible to use <code>ggplot2</code> to achieve similar results.</p>

<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="1-1-intro-smooth.html#cb4-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb4-2"><a href="1-1-intro-smooth.html#cb4-2"></a><span class="kw">ggplot</span>(phipsi, <span class="kw">aes</span>(<span class="dt">x =</span> phi)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb4-3"><a href="1-1-intro-smooth.html#cb4-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..), <span class="dt">bins =</span> <span class="dv">13</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb4-4"><a href="1-1-intro-smooth.html#cb4-4"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb4-5"><a href="1-1-intro-smooth.html#cb4-5"></a><span class="st">  </span><span class="kw">geom_rug</span>()</span>
<span id="cb4-6"><a href="1-1-intro-smooth.html#cb4-6"></a></span>
<span id="cb4-7"><a href="1-1-intro-smooth.html#cb4-7"></a><span class="kw">ggplot</span>(phipsi, <span class="kw">aes</span>(<span class="dt">x =</span> psi)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb4-8"><a href="1-1-intro-smooth.html#cb4-8"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..), <span class="dt">bins =</span> <span class="dv">13</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb4-9"><a href="1-1-intro-smooth.html#cb4-9"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb4-10"><a href="1-1-intro-smooth.html#cb4-10"></a><span class="st">  </span><span class="kw">geom_rug</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:phipsiggplot"></span>
<img src="CSwR_files/figure-html/phipsiggplot-1.png" alt="Histograms and density estimates of \(\phi\)-angles (left) and \(\psi\)-angles (right) made with ggplot2." width="49%" /><img src="CSwR_files/figure-html/phipsiggplot-2.png" alt="Histograms and density estimates of \(\phi\)-angles (left) and \(\psi\)-angles (right) made with ggplot2." width="49%" />
<p class="caption">
Figure 1.4: Histograms and density estimates of <span class="math inline">\(\phi\)</span>-angles (left) and <span class="math inline">\(\psi\)</span>-angles (right) made with ggplot2.
</p>
</div>
<p>Histograms produced by ggplot2 have a non adaptive default number of bins equal
to 30 (number of breaks equal to 31), which is different from <code>hist</code> that uses
<a href="https://en.wikipedia.org/wiki/Histogram#Sturges&#39;_formula">Sturges’ formula</a>
<span class="math display">\[\text{number of breaks} = \lceil \log_2(n) + 1 \rceil\]</span>
with <span class="math inline">\(n\)</span> the number of observations in the data set. In addition, this number is
further modified by
the function <code>pretty</code> that generates “nice” breaks, which results in 14 breaks
for the angle data. For easier comparison, the number of bins used by
<code>geom_histogram</code> above is set to 13, though it should be
noticed that the breaks are not chosen in exactly the
same way by <code>geom_histogram</code> and <code>hist</code>. Automatic and data adaptive bin
selection is difficult, and <code>geom_histogram</code> implements a simple and fixed, but
likely suboptimal, default while notifying the user that this default choice
can be improved by setting <code>binwidth</code>.</p>
<p>For the density, <code>geom_density</code> actually relies on the <code>density</code> function and its
default choices of how and how much to smooth. Thus the figure
may have a slightly different appearance, but the estimated density obtained by
<code>geom_density</code> is identical to the one obtained by <code>density</code>.</p>
</div>
<div id="changing-the-defaults" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Changing the defaults</h3>
<p>The range of the angle data is known to be <span class="math inline">\((-\pi, \pi]\)</span>, which neither
the histogram nor the density smoother take advantage of. The <code>pretty</code> function,
used by <code>hist</code> chooses, for instance, breaks in <span class="math inline">\(-3\)</span> and <span class="math inline">\(3\)</span>, which results in
the two extreme
bars in the histogram to be misleading. Note also that for the <span class="math inline">\(\psi\)</span>-angle
it appears that the defaults result in oversmoothing of the density
estimate. That is, the density is more
smoothed out than the data (and the histogram) appears to support.</p>
<p>To obtain different – and perhaps better – results, we can try to change some
of the defaults of the histogram and density functions. The two most important
defaults to consider are the <em>bandwidth</em> and the <em>kernel</em>.
Postponing the mathematics to Chapter <a href="2-density.html#density">2</a>, the kernel controls how
neighboring data points are weighted relatively to each other, and the
bandwidth controls the size of neighborhoods. A bandwidth can be specified
manually as a specific numerical value, but for a fully automatic procedure,
it is selected by a bandwidth selection algorithm. The <code>density</code> default
is a rather simplistic algorithm known as Silverman’s rule-of-thumb.</p>

<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="1-1-intro-smooth.html#cb5-1"></a><span class="kw">hist</span>(phipsi<span class="op">$</span>psi, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">15</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)</span>
<span id="cb5-2"><a href="1-1-intro-smooth.html#cb5-2"></a><span class="kw">rug</span>(phipsi<span class="op">$</span>psi)</span>
<span id="cb5-3"><a href="1-1-intro-smooth.html#cb5-3"></a><span class="kw">density</span>(phipsi<span class="op">$</span>psi, <span class="dt">adjust =</span> <span class="dv">1</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb5-4"><a href="1-1-intro-smooth.html#cb5-4"></a><span class="kw">density</span>(phipsi<span class="op">$</span>psi, <span class="dt">adjust =</span> <span class="fl">0.5</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb5-5"><a href="1-1-intro-smooth.html#cb5-5"></a><span class="kw">density</span>(phipsi<span class="op">$</span>psi, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;purple&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb5-6"><a href="1-1-intro-smooth.html#cb5-6"></a></span>
<span id="cb5-7"><a href="1-1-intro-smooth.html#cb5-7"></a><span class="kw">hist</span>(phipsi<span class="op">$</span>psi, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">15</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)</span>
<span id="cb5-8"><a href="1-1-intro-smooth.html#cb5-8"></a><span class="kw">rug</span>(phipsi<span class="op">$</span>psi)</span>
<span id="cb5-9"><a href="1-1-intro-smooth.html#cb5-9"></a><span class="co"># Default kernel is &quot;gaussian&quot;</span></span>
<span id="cb5-10"><a href="1-1-intro-smooth.html#cb5-10"></a><span class="kw">density</span>(phipsi<span class="op">$</span>psi, <span class="dt">bw =</span> <span class="st">&quot;SJ&quot;</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb5-11"><a href="1-1-intro-smooth.html#cb5-11"></a><span class="kw">density</span>(phipsi<span class="op">$</span>psi, <span class="dt">kernel =</span> <span class="st">&quot;epanechnikov&quot;</span>, <span class="dt">bw =</span> <span class="st">&quot;SJ&quot;</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-12"><a href="1-1-intro-smooth.html#cb5-12"></a><span class="st">  </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb5-13"><a href="1-1-intro-smooth.html#cb5-13"></a><span class="kw">density</span>(phipsi<span class="op">$</span>psi, <span class="dt">kernel =</span> <span class="st">&quot;rectangular&quot;</span>, <span class="dt">bw =</span> <span class="st">&quot;SJ&quot;</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-14"><a href="1-1-intro-smooth.html#cb5-14"></a><span class="st">  </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;purple&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:psiDens"></span>
<img src="CSwR_files/figure-html/psiDens-1.png" alt="Histograms and various density estimates for the \(\psi\)-angles. The colors indicate different choices of bandwidth adjustments using the otherwise default bandwidth selection (left) and different choices of kernels using Sheather-Jones bandwidth selection (right)." width="49%" /><img src="CSwR_files/figure-html/psiDens-2.png" alt="Histograms and various density estimates for the \(\psi\)-angles. The colors indicate different choices of bandwidth adjustments using the otherwise default bandwidth selection (left) and different choices of kernels using Sheather-Jones bandwidth selection (right)." width="49%" />
<p class="caption">
Figure 1.5: Histograms and various density estimates for the <span class="math inline">\(\psi\)</span>-angles. The colors indicate different choices of bandwidth adjustments using the otherwise default bandwidth selection (left) and different choices of kernels using Sheather-Jones bandwidth selection (right).
</p>
</div>
<p>Figure
<a href="1-1-intro-smooth.html#fig:psiDens">1.5</a> shows examples of several different density estimates
that can be obtained by changing the defaults of <code>density</code>. The breaks for
the histogram have also been chosen manually to make sure that they match
the range of the data. Note, in particular, that Sheather-Jones bandwidth
selection appears to work better than the default bandwidth for this example.
This is generally the
case for multimodal distributions, where the default bandwidth tends to oversmooth.
Note also that the choice of bandwidth is far more consequential than
the choice of kernel, the latter mostly affecting how wiggly the density
estimate is locally.</p>
<p>It should be noted that defaults arise as
a combination of historically sensible choices and backward compatibility. Thought
should go into choosing a good, robust default, but once a default is chosen,
it should not be changed haphazardly, as this might break existing code. That is
why not all defaults used in R are by today’s standards the best known
choices. You see this argument made in the documentation of <code>density</code> regarding the
default for bandwidth selection, where Sheather-Jones is suggested as a
better default than the current, but for compatibility reasons Silverman’s
rule-of-thumb is the default and is likely to remain being so.</p>
</div>
<div id="multivariate-smoothing" class="section level3">
<h3><span class="header-section-number">1.1.4</span> Multivariate methods</h3>
<p>This section provides a single illustration of how to use the
bivariate kernel smoother <code>kde2d</code> from the MASS package
for bivariate density estimation of the <span class="math inline">\((\phi, \psi)\)</span>-angle distribution.
A scatter plot of <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\psi\)</span> angles is known as a <a href="https://en.wikipedia.org/wiki/Ramachandran_plot">Ramachandran plot</a>, and it provides
a classical and important way of visualizing local structural
constraints of proteins in structural biochemistry. The density estimate
can be understood as an estimate of the distribution of <span class="math inline">\((\phi, \psi)\)</span>-angles
in naturally occuring proteins from the small sample of angles in our
data set.</p>
<p>We compute the density estimate in a grid of size 100 by 100 using a bandwidth
of 2 and using the <code>kde2d</code> function that uses a bivariate normal kernel.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="1-1-intro-smooth.html#cb6-1"></a>denshat &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">kde2d</span>(phipsi<span class="op">$</span>phi, phipsi<span class="op">$</span>psi, <span class="dt">h =</span> <span class="dv">2</span>, <span class="dt">n =</span> <span class="dv">100</span>)</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="1-1-intro-smooth.html#cb7-1"></a>denshat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb7-2"><a href="1-1-intro-smooth.html#cb7-2"></a>  <span class="kw">cbind</span>(</span>
<span id="cb7-3"><a href="1-1-intro-smooth.html#cb7-3"></a>    denshat<span class="op">$</span>x, </span>
<span id="cb7-4"><a href="1-1-intro-smooth.html#cb7-4"></a>    <span class="kw">rep</span>(denshat<span class="op">$</span>y, <span class="dt">each =</span> <span class="kw">length</span>(denshat<span class="op">$</span>x)), </span>
<span id="cb7-5"><a href="1-1-intro-smooth.html#cb7-5"></a>    <span class="kw">as.vector</span>(denshat<span class="op">$</span>z)</span>
<span id="cb7-6"><a href="1-1-intro-smooth.html#cb7-6"></a>    )</span>
<span id="cb7-7"><a href="1-1-intro-smooth.html#cb7-7"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="1-1-intro-smooth.html#cb8-1"></a><span class="kw">colnames</span>(denshat) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;phi&quot;</span>, <span class="st">&quot;psi&quot;</span>, <span class="st">&quot;dens&quot;</span>)</span>
<span id="cb8-2"><a href="1-1-intro-smooth.html#cb8-2"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(denshat, <span class="kw">aes</span>(phi, psi)) <span class="op">+</span></span>
<span id="cb8-3"><a href="1-1-intro-smooth.html#cb8-3"></a><span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> dens), <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></span>
<span id="cb8-4"><a href="1-1-intro-smooth.html#cb8-4"></a><span class="st">  </span><span class="kw">geom_contour</span>(<span class="kw">aes</span>(<span class="dt">z =</span> <span class="kw">sqrt</span>(dens))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb8-5"><a href="1-1-intro-smooth.html#cb8-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> phipsi, <span class="kw">aes</span>(<span class="dt">fill =</span> <span class="ot">NULL</span>)) <span class="op">+</span></span>
<span id="cb8-6"><a href="1-1-intro-smooth.html#cb8-6"></a><span class="st">  </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">high =</span> <span class="st">&quot;darkblue&quot;</span>, <span class="dt">trans =</span> <span class="st">&quot;sqrt&quot;</span>)</span></code></pre></div>
<p>We then recompute the density estimate in the same grid of size using
the smaller bandwidth of 0.5.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="1-1-intro-smooth.html#cb9-1"></a>denshat &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">kde2d</span>(phipsi<span class="op">$</span>phi, phipsi<span class="op">$</span>psi, <span class="dt">h =</span> <span class="fl">0.5</span>, <span class="dt">n =</span> <span class="dv">100</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bidens2"></span>
<img src="CSwR_files/figure-html/bidens2-1.png" alt="Bivariate density estimates of protein backbone angles using a bivariate Gaussian kernel with bandwiths $2$ (left) and $0.5$ (right)." width="49%" /><img src="CSwR_files/figure-html/bidens2-2.png" alt="Bivariate density estimates of protein backbone angles using a bivariate Gaussian kernel with bandwiths $2$ (left) and $0.5$ (right)." width="49%" />
<p class="caption">
Figure 1.6: Bivariate density estimates of protein backbone angles using a bivariate Gaussian kernel with bandwiths <span class="math inline">\(2\)</span> (left) and <span class="math inline">\(0.5\)</span> (right).
</p>
</div>
<p>The Ramachandran plot in Figure <a href="1-1-intro-smooth.html#fig:bidens2">1.6</a> shows how structural constraints
of a protein, such as steric effects, induce a non-standard bivariate distribution
of <span class="math inline">\((\phi, \psi)\)</span>-angles.</p>
</div>
<div id="large-scale-smoothing" class="section level3">
<h3><span class="header-section-number">1.1.5</span> Large scale smoothing</h3>
<p>With small data sets of less than 10,000 data points, say, univariate
smooth density estimation requires a very modest amount of computation. That is true
even with rather naive implementations of the standard methods. The R function
<code>density</code> is implemented using a number of computational tricks like
binning and the fast Fourier transform, and it can compute density
estimates with a million data points (around 8 MB) within a fraction of a second.</p>
<p>It is
unclear if we ever need truly large scale <em>univariate</em> density
estimation with terabytes of data points, say. If we have that amount of
(heterogeneous) data it is likely that we are better off breaking the data down
into smaller and more homogeneous groups. That is, we should turn a big data computation
into a large number of small data computations. That does not remove the
computational challenge but it does diminish it somewhat e.g. by parallelization.</p>
<p>Deng and Wickham did a review in 2011 on <a href="http://www2.cs.uh.edu/~ceick/7362/T2-4.pdf">Density estimation in R</a>,
where they assessed the performance of a number of R packages including the
<code>density</code> function. The <a href="https://cran.r-project.org/web/packages/KernSmooth/index.html">KernSmooth</a>
package was singled out in terms of speed as well as accuracy
for computing <em>smooth</em> density estimates with <code>density</code> performing quite well too. (Histograms
are non-smooth density estimates and generally faster to compute).
The assessment was based on using defaults for the different packages, which is meaningful
in the sense of representing the
performance that the occasional user will experience. It is, however,
also an evaluation of the combination of default choices and the implementation,
and as different packages rely on e.g. different bandwidth selection algorithms,
this assessment is not the complete story. The <code>bkde</code> function from the KernSmooth
package, as well as <code>density</code>, are solid choices, but
the point is that performance assessment is a multifaceted problem.</p>
<p>To be a little more specific about the computational complexity of density
estimators, suppose that we have <span class="math inline">\(n\)</span> data points and want to evaluate the
density in <span class="math inline">\(m\)</span> points. A naive implementation of kernel smoothing,
Section <a href="2-2-kernel-density.html#kernel-density">2.2</a>, has <span class="math inline">\(O(mn)\)</span> time complexity, while
a naive implementation of the best bandwidth selection algorithms have
<span class="math inline">\(O(n^2)\)</span> time complexity. As a simple rule-of-thumb, anything beyond <span class="math inline">\(O(n)\)</span>
will not scale to very large data sets. A quadratic time complexity for bandwidth
selection will, in particular, be a serious bottleneck. Kernel smoothing
illustrates perfectly that a literal implementation of the mathematics behind
a statistical method may not always be computationally viable. Even
the <span class="math inline">\(O(mn)\)</span> time complexity may be quite a bottleneck as it reflects
<span class="math inline">\(mn\)</span> kernel evaluations, each being potentially a computationally
relatively expensive operation.</p>
<p>The binning trick, with the number of bins set to <span class="math inline">\(m\)</span>, is a grouping of the data
points into <span class="math inline">\(m\)</span> sets of neighbor points (bins) with each bin
representing the points in the bin via a single point and a weight. If <span class="math inline">\(m \ll n\)</span>,
this can reduce the time complexity substantially to <span class="math inline">\(O(m^2) + O(n)\)</span>. The fast
Fourier transform may reduce the <span class="math inline">\(O(m^2)\)</span> term even further to <span class="math inline">\(O(m\log(m))\)</span>.
Some approximations are involved, and it is of importance
to evaluate the tradeoff between time and memory complexity on one
side and accuracy on the other side.</p>
<p>Multivariate smoothing is a different story. While it is possible to
generalize the basic ideas of univariate density estimation to arbitrary dimensions, the
<a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">curse-of-dimensionality</a>
hits unconstrained smoothing hard – statistically as well as
computationally. Multivariate smoothing is therefore still an active research
area developing computationally tractable and novel ways of fitting smooth
densities or conditional densities to multivariate
or even high-dimensional data. A key technique is to make structural
assumptions to alleviate the challenge of a large dimension, but there are many
different assumptions possible, which makes the body of methods and theory
richer and the practical choices much more difficult.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="1-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="1-2-monte-carlo-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 Monte Carlo methods | Computational Statistics with R</title>
  <meta name="description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 Monte Carlo methods | Computational Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 Monte Carlo methods | Computational Statistics with R" />
  
  <meta name="twitter:description" content="Lecture notes providing an introduction to computational statistics using the R programming language." />
  

<meta name="author" content="Niels Richard Hansen" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="1-1-intro-smooth.html"/>
<link rel="next" href="1-3-optimization.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computational Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-intro.html"><a href="1-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html"><i class="fa fa-check"></i><b>1.1</b> Smoothing</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#intro-angles"><i class="fa fa-check"></i><b>1.1.1</b> Angle distributions in proteins</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#using-ggplot2"><i class="fa fa-check"></i><b>1.1.2</b> Using ggplot2</a></li>
<li class="chapter" data-level="1.1.3" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#changing-the-defaults"><i class="fa fa-check"></i><b>1.1.3</b> Changing the defaults</a></li>
<li class="chapter" data-level="1.1.4" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#multivariate-smoothing"><i class="fa fa-check"></i><b>1.1.4</b> Multivariate methods</a></li>
<li class="chapter" data-level="1.1.5" data-path="1-1-intro-smooth.html"><a href="1-1-intro-smooth.html#large-scale-smoothing"><i class="fa fa-check"></i><b>1.1.5</b> Large scale smoothing</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html"><i class="fa fa-check"></i><b>1.2</b> Monte Carlo methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html#vM"><i class="fa fa-check"></i><b>1.2.1</b> Univariate von Mises distributions</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html#mixtures-of-von-mises-distributions"><i class="fa fa-check"></i><b>1.2.2</b> Mixtures of von Mises distributions</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-2-monte-carlo-methods.html"><a href="1-2-monte-carlo-methods.html#large-scale-monte-carlo-methods"><i class="fa fa-check"></i><b>1.2.3</b> Large scale Monte Carlo methods</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-3-optimization.html"><a href="1-3-optimization.html"><i class="fa fa-check"></i><b>1.3</b> Optimization</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-3-optimization.html"><a href="1-3-optimization.html#the-em-algorithm"><i class="fa fa-check"></i><b>1.3.1</b> The EM-algorithm</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-3-optimization.html"><a href="1-3-optimization.html#large-scale-optimization"><i class="fa fa-check"></i><b>1.3.2</b> Large scale optimization</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Smoothing</b></span></li>
<li class="chapter" data-level="2" data-path="2-density.html"><a href="2-density.html"><i class="fa fa-check"></i><b>2</b> Density estimation</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-unidens.html"><a href="2-1-unidens.html"><i class="fa fa-check"></i><b>2.1</b> Univariate density estimation</a></li>
<li class="chapter" data-level="2.2" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html"><i class="fa fa-check"></i><b>2.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html#implementation"><i class="fa fa-check"></i><b>2.2.1</b> Implementation</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html#benchmarking"><i class="fa fa-check"></i><b>2.2.2</b> Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html"><i class="fa fa-check"></i><b>2.3</b> Bandwidth selection</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#rectangular"><i class="fa fa-check"></i><b>2.3.1</b> Revisiting the rectangular kernel</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#ise-mise-and-mse-for-kernel-estimators"><i class="fa fa-check"></i><b>2.3.2</b> ISE, MISE and MSE for kernel estimators</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#plug-in-estimation-of-the-oracle-bandwidth"><i class="fa fa-check"></i><b>2.3.3</b> Plug-in estimation of the oracle bandwidth</a></li>
<li class="chapter" data-level="2.3.4" data-path="2-3-bandwidth.html"><a href="2-3-bandwidth.html#cv"><i class="fa fa-check"></i><b>2.3.4</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-4-likelihood.html"><a href="2-4-likelihood.html"><i class="fa fa-check"></i><b>2.4</b> Likelihood considerations</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-4-likelihood.html"><a href="2-4-likelihood.html#sieves"><i class="fa fa-check"></i><b>2.4.1</b> Method of sieves</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-4-likelihood.html"><a href="2-4-likelihood.html#basis-density"><i class="fa fa-check"></i><b>2.4.2</b> Basis expansions</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-5-density-ex.html"><a href="2-5-density-ex.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="2-5-density-ex.html"><a href="2-5-density-ex.html#kernel-density-estimation"><i class="fa fa-check"></i>Kernel density estimation</a></li>
<li class="chapter" data-level="" data-path="2-5-density-ex.html"><a href="2-5-density-ex.html#benchmarking-1"><i class="fa fa-check"></i>Benchmarking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-bivariate.html"><a href="3-bivariate.html"><i class="fa fa-check"></i><b>3</b> Bivariate smoothing</a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html"><i class="fa fa-check"></i><b>3.1</b> Nearest neighbor smoothers</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html#linear-smoothers"><i class="fa fa-check"></i><b>3.1.1</b> Linear smoothers</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html#implementing-the-running-mean"><i class="fa fa-check"></i><b>3.1.2</b> Implementing the running mean</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-1-nearest-neighbor-smoothers.html"><a href="3-1-nearest-neighbor-smoothers.html#choose-k-by-cross-validation"><i class="fa fa-check"></i><b>3.1.3</b> Choose <span class="math inline">\(k\)</span> by cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-2-kernel-methods.html"><a href="3-2-kernel-methods.html"><i class="fa fa-check"></i><b>3.2</b> Kernel methods</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-2-kernel-methods.html"><a href="3-2-kernel-methods.html#nadarayawatson-kernel-smoothing"><i class="fa fa-check"></i><b>3.2.1</b> Nadaraya–Watson kernel smoothing</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-2-kernel-methods.html"><a href="3-2-kernel-methods.html#local-regression-smoothers"><i class="fa fa-check"></i><b>3.2.2</b> Local regression smoothers</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-3-sparse-linear-algebra.html"><a href="3-3-sparse-linear-algebra.html"><i class="fa fa-check"></i><b>3.3</b> Sparse linear algebra</a></li>
<li class="chapter" data-level="3.4" data-path="3-4-onb.html"><a href="3-4-onb.html"><i class="fa fa-check"></i><b>3.4</b> Orthogonal basis expansions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-4-onb.html"><a href="3-4-onb.html#polynomial-expansions"><i class="fa fa-check"></i><b>3.4.1</b> Polynomial expansions</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-4-onb.html"><a href="3-4-onb.html#fourier-expansions"><i class="fa fa-check"></i><b>3.4.2</b> Fourier expansions</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-5-splines.html"><a href="3-5-splines.html"><i class="fa fa-check"></i><b>3.5</b> Splines</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-5-splines.html"><a href="3-5-splines.html#smoothing-splines"><i class="fa fa-check"></i><b>3.5.1</b> Smoothing splines</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-5-splines.html"><a href="3-5-splines.html#splines-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Splines in R</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-5-splines.html"><a href="3-5-splines.html#efficient-splines"><i class="fa fa-check"></i><b>3.5.3</b> Efficient computation with splines</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-6-gaussian-processes.html"><a href="3-6-gaussian-processes.html"><i class="fa fa-check"></i><b>3.6</b> Gaussian processes</a></li>
<li class="chapter" data-level="3.7" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html"><i class="fa fa-check"></i><b>3.7</b> The Kalman filter</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html#ar1-example"><i class="fa fa-check"></i><b>3.7.1</b> AR(1)-example</a></li>
<li class="chapter" data-level="3.7.2" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html#the-kalman-smoother"><i class="fa fa-check"></i><b>3.7.2</b> The Kalman smoother</a></li>
<li class="chapter" data-level="3.7.3" data-path="2-2-kernel-density.html"><a href="2-2-kernel-density.html#implementation"><i class="fa fa-check"></i><b>3.7.3</b> Implementation</a></li>
<li class="chapter" data-level="3.7.4" data-path="3-7-the-kalman-filter.html"><a href="3-7-the-kalman-filter.html#the-kalman-filter-1"><i class="fa fa-check"></i><b>3.7.4</b> The Kalman filter</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3-8-bivariate-ex.html"><a href="3-8-bivariate-ex.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="3-8-bivariate-ex.html"><a href="3-8-bivariate-ex.html#nearest-neighbors"><i class="fa fa-check"></i>Nearest neighbors</a></li>
<li class="chapter" data-level="" data-path="3-8-bivariate-ex.html"><a href="3-8-bivariate-ex.html#kernel-estimators"><i class="fa fa-check"></i>Kernel estimators</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Monte Carlo Methods</b></span></li>
<li class="chapter" data-level="4" data-path="4-univariate-random-variables.html"><a href="4-univariate-random-variables.html"><i class="fa fa-check"></i><b>4</b> Univariate random variables</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-pseudorandom-number-generators.html"><a href="4-1-pseudorandom-number-generators.html"><i class="fa fa-check"></i><b>4.1</b> Pseudorandom number generators</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4-1-pseudorandom-number-generators.html"><a href="4-1-pseudorandom-number-generators.html#implementing-a-pseudorandom-number-generator"><i class="fa fa-check"></i><b>4.1.1</b> Implementing a pseudorandom number generator</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-1-pseudorandom-number-generators.html"><a href="4-1-pseudorandom-number-generators.html#pseudorandom-number-packages"><i class="fa fa-check"></i><b>4.1.2</b> Pseudorandom number packages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-2-transformation-techniques.html"><a href="4-2-transformation-techniques.html"><i class="fa fa-check"></i><b>4.2</b> Transformation techniques</a><ul>
<li class="chapter" data-level="4.2.1" data-path="4-2-transformation-techniques.html"><a href="4-2-transformation-techniques.html#sampling-from-a-t-distribution"><i class="fa fa-check"></i><b>4.2.1</b> Sampling from a <span class="math inline">\(t\)</span>-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-reject-samp.html"><a href="4-3-reject-samp.html"><i class="fa fa-check"></i><b>4.3</b> Rejection sampling</a><ul>
<li class="chapter" data-level="4.3.1" data-path="4-3-reject-samp.html"><a href="4-3-reject-samp.html#vMsim"><i class="fa fa-check"></i><b>4.3.1</b> von Mises distribution</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-3-reject-samp.html"><a href="4-3-reject-samp.html#gamma-distribution"><i class="fa fa-check"></i><b>4.3.2</b> Gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-4-adaptive.html"><a href="4-4-adaptive.html"><i class="fa fa-check"></i><b>4.4</b> Adaptive envelopes</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-4-adaptive.html"><a href="4-4-adaptive.html#beta-distribution"><i class="fa fa-check"></i><b>4.4.1</b> Beta distribution</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-4-adaptive.html"><a href="4-4-adaptive.html#von-mises-distribution"><i class="fa fa-check"></i><b>4.4.2</b> von Mises distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-5-univariate-ex.html"><a href="4-5-univariate-ex.html"><i class="fa fa-check"></i><b>4.5</b> Exercises</a><ul>
<li class="chapter" data-level="4.5.1" data-path="4-5-univariate-ex.html"><a href="4-5-univariate-ex.html#rejection-sampling-of-gaussian-random-variables"><i class="fa fa-check"></i><b>4.5.1</b> Rejection sampling of Gaussian random variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-mci.html"><a href="5-mci.html"><i class="fa fa-check"></i><b>5</b> Monte Carlo integration</a><ul>
<li class="chapter" data-level="5.1" data-path="5-1-assessment.html"><a href="5-1-assessment.html"><i class="fa fa-check"></i><b>5.1</b> Assessment</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-1-assessment.html"><a href="5-1-assessment.html#CLT-gamma"><i class="fa fa-check"></i><b>5.1.1</b> Using the central limit theorem</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-1-assessment.html"><a href="5-1-assessment.html#concentration-inequalities"><i class="fa fa-check"></i><b>5.1.2</b> Concentration inequalities</a></li>
<li class="chapter" data-level="5.1.3" data-path="5-1-assessment.html"><a href="5-1-assessment.html#exponential-tail-bound-for-gamma-distributed-variables"><i class="fa fa-check"></i><b>5.1.3</b> Exponential tail bound for Gamma distributed variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-2-importance-sampling.html"><a href="5-2-importance-sampling.html"><i class="fa fa-check"></i><b>5.2</b> Importance sampling</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-2-importance-sampling.html"><a href="5-2-importance-sampling.html#unknown-normalization-constants"><i class="fa fa-check"></i><b>5.2.1</b> Unknown normalization constants</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-2-importance-sampling.html"><a href="5-2-importance-sampling.html#hd-int"><i class="fa fa-check"></i><b>5.2.2</b> Computing a high-dimensional integral</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-3-network.html"><a href="5-3-network.html"><i class="fa fa-check"></i><b>5.3</b> Network failure</a><ul>
<li class="chapter" data-level="5.3.1" data-path="5-3-network.html"><a href="5-3-network.html#object-oriented-implementations"><i class="fa fa-check"></i><b>5.3.1</b> Object oriented implementations</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part III: Optimization</b></span></li>
<li class="chapter" data-level="6" data-path="6-four-examples.html"><a href="6-four-examples.html"><i class="fa fa-check"></i><b>6</b> Four Examples</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html"><i class="fa fa-check"></i><b>6.1</b> Exponential families</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#full-exponential-families"><i class="fa fa-check"></i><b>6.1.1</b> Full exponential families</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#bayes-net"><i class="fa fa-check"></i><b>6.1.2</b> Exponential family Bayesian networks</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#exp-fam-deriv"><i class="fa fa-check"></i><b>6.1.3</b> Likelihood computations</a></li>
<li class="chapter" data-level="6.1.4" data-path="6-1-exp-fam.html"><a href="6-1-exp-fam.html#curved-exponential-families"><i class="fa fa-check"></i><b>6.1.4</b> Curved exponential families</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-2-multinomial-models.html"><a href="6-2-multinomial-models.html"><i class="fa fa-check"></i><b>6.2</b> Multinomial models</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-2-multinomial-models.html"><a href="6-2-multinomial-models.html#pep-moth"><i class="fa fa-check"></i><b>6.2.1</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-3-regression.html"><a href="6-3-regression.html"><i class="fa fa-check"></i><b>6.3</b> Regression models</a></li>
<li class="chapter" data-level="6.4" data-path="6-4-finite-mixture-models.html"><a href="6-4-finite-mixture-models.html"><i class="fa fa-check"></i><b>6.4</b> Finite mixture models</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-4-finite-mixture-models.html"><a href="6-4-finite-mixture-models.html#Gaus-mix-ex"><i class="fa fa-check"></i><b>6.4.1</b> Gaussian mixtures</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-5-mixed-models.html"><a href="6-5-mixed-models.html"><i class="fa fa-check"></i><b>6.5</b> Mixed models</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-numopt.html"><a href="7-numopt.html"><i class="fa fa-check"></i><b>7</b> Numerical optimization</a><ul>
<li class="chapter" data-level="7.1" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html"><i class="fa fa-check"></i><b>7.1</b> Algorithms and convergence</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#descent-algorithms"><i class="fa fa-check"></i><b>7.1.1</b> Descent algorithms</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#maps-and-fixed-points"><i class="fa fa-check"></i><b>7.1.2</b> Maps and fixed points</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#convergence-rate"><i class="fa fa-check"></i><b>7.1.3</b> Convergence rate</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-1-algorithms-and-convergence.html"><a href="7-1-algorithms-and-convergence.html#stopping-criteria"><i class="fa fa-check"></i><b>7.1.4</b> Stopping criteria</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html"><i class="fa fa-check"></i><b>7.2</b> Descent direction algorithms</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#line-search"><i class="fa fa-check"></i><b>7.2.1</b> Line search</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#gradient-descent"><i class="fa fa-check"></i><b>7.2.2</b> Gradient descent</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#conjugate-gradients"><i class="fa fa-check"></i><b>7.2.3</b> Conjugate gradients</a></li>
<li class="chapter" data-level="7.2.4" data-path="7-2-descent-direction-algorithms.html"><a href="7-2-descent-direction-algorithms.html#pep-moth-descent"><i class="fa fa-check"></i><b>7.2.4</b> Peppered Moths</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-3-Newton.html"><a href="7-3-Newton.html"><i class="fa fa-check"></i><b>7.3</b> Newton-type algorithms</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-3-Newton.html"><a href="7-3-Newton.html#poisson-regression"><i class="fa fa-check"></i><b>7.3.1</b> Poisson regression</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-3-Newton.html"><a href="7-3-Newton.html#quasi-newton-algorithms"><i class="fa fa-check"></i><b>7.3.2</b> Quasi-Newton algorithms</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-3-Newton.html"><a href="7-3-Newton.html#sparsity"><i class="fa fa-check"></i><b>7.3.3</b> Sparsity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-4-misc-.html"><a href="7-4-misc-.html"><i class="fa fa-check"></i><b>7.4</b> Misc.</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-em.html"><a href="8-em.html"><i class="fa fa-check"></i><b>8</b> Expectation maximization algorithms</a><ul>
<li class="chapter" data-level="8.1" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html"><i class="fa fa-check"></i><b>8.1</b> Basic properties</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html#incomplete-data-likelihood"><i class="fa fa-check"></i><b>8.1.1</b> Incomplete data likelihood</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html#monotonicity-of-the-em-algorithm"><i class="fa fa-check"></i><b>8.1.2</b> Monotonicity of the EM algorithm</a></li>
<li class="chapter" data-level="8.1.3" data-path="8-1-basic-properties.html"><a href="8-1-basic-properties.html#peppered-moths"><i class="fa fa-check"></i><b>8.1.3</b> Peppered moths</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-2-EM-exp.html"><a href="8-2-EM-exp.html"><i class="fa fa-check"></i><b>8.2</b> Exponential families</a></li>
<li class="chapter" data-level="8.3" data-path="8-3-fisher-information.html"><a href="8-3-fisher-information.html"><i class="fa fa-check"></i><b>8.3</b> Fisher information</a></li>
<li class="chapter" data-level="8.4" data-path="8-4-revisiting-gaussian-mixtures.html"><a href="8-4-revisiting-gaussian-mixtures.html"><i class="fa fa-check"></i><b>8.4</b> Revisiting Gaussian mixtures</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-StochOpt.html"><a href="9-StochOpt.html"><i class="fa fa-check"></i><b>9</b> Stochastic Optimization</a><ul>
<li class="chapter" data-level="9.1" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html"><i class="fa fa-check"></i><b>9.1</b> Stochastic gradient algorithms</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html#section"><i class="fa fa-check"></i><b>9.1.1</b> </a></li>
<li class="chapter" data-level="9.1.2" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html#online-stochastic-gradient-descent"><i class="fa fa-check"></i><b>9.1.2</b> Online stochastic gradient descent</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-1-stochastic-gradient-algorithms.html"><a href="9-1-stochastic-gradient-algorithms.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>9.1.3</b> Stochastic gradient descent</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-2-nonlinear-least-squares.html"><a href="9-2-nonlinear-least-squares.html"><i class="fa fa-check"></i><b>9.2</b> Nonlinear least squares</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-app-R.html"><a href="A-app-R.html"><i class="fa fa-check"></i><b>A</b> R programming</a><ul>
<li class="chapter" data-level="A.1" data-path="A-1-functions.html"><a href="A-1-functions.html"><i class="fa fa-check"></i><b>A.1</b> Functions</a><ul>
<li class="chapter" data-level="A.1.1" data-path="A-1-functions.html"><a href="A-1-functions.html#vectorization"><i class="fa fa-check"></i><b>A.1.1</b> Vectorization</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="A-2-objects-and-methods.html"><a href="A-2-objects-and-methods.html"><i class="fa fa-check"></i><b>A.2</b> Objects and methods</a></li>
<li class="chapter" data-level="A.3" data-path="A-3-environments.html"><a href="A-3-environments.html"><i class="fa fa-check"></i><b>A.3</b> Environments</a><ul>
<li class="chapter" data-level="A.3.1" data-path="A-3-environments.html"><a href="A-3-environments.html#function-factories"><i class="fa fa-check"></i><b>A.3.1</b> Function factories</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="A-4-performance.html"><a href="A-4-performance.html"><i class="fa fa-check"></i><b>A.4</b> Performance</a><ul>
<li class="chapter" data-level="A.4.1" data-path="A-4-performance.html"><a href="A-4-performance.html#parallel-computations"><i class="fa fa-check"></i><b>A.4.1</b> Parallel computations</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html"><i class="fa fa-check"></i><b>A.5</b> Exercises</a><ul>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#functions-1"><i class="fa fa-check"></i>Functions</a></li>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#histograms-with-non-equidistant-breaks"><i class="fa fa-check"></i>Histograms with non-equidistant breaks</a></li>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#functions-and-objects"><i class="fa fa-check"></i>Functions and objects</a></li>
<li class="chapter" data-level="" data-path="A-5-app-ex.html"><a href="A-5-app-ex.html#functions-and-environments"><i class="fa fa-check"></i>Functions and environments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="monte-carlo-methods" class="section level2">
<h2><span class="header-section-number">1.2</span> Monte Carlo methods</h2>
<p>Broadly speaking, Monte Carlo methods are computations that rely on some form
of random input in order to carry out a computation. The actual
random input will be generated by a (pseudo)random number generator
according to some distributional specifications, and the precise value of the
computation will depend on the precise value of the random input but in a way
where we understand the magnitude of the dependence quite well. In most
cases we can make the dependence diminish by increasing the amount of random
input.</p>
<p>In statistics it is quite interesting in itself that we can make the computer
simulate data so that we can draw an example data set from a statistical
model. However, the real usage of such simulations is almost always as a
part of a Monte Carlo computation, where we repeat the simulation of
data sets a large number of times and compute distributional properties
of various statistics. This is just one of the most obvious applications of
Monte Carlo methods in statistics and there are many others. Disregarding
the specific computation of interest in applications, a core problem of
Monte Carlo methods is efficient simulation of random variables from a
given target distribution.</p>
<div id="vM" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Univariate von Mises distributions</h3>
<p>We will exemplify Monte Carlo computations by considering angle distributions
just as in Section <a href="1-1-intro-smooth.html#intro-smooth">1.1</a>. The angles take values in the interval
<span class="math inline">\((-\pi, \pi]\)</span>, and we will consider models based on the <a href="https://en.wikipedia.org/wiki/Von_Mises_distribution#Moments">von Mises distribution</a>
on this interval, which has density</p>
<p><span class="math display">\[f(x) = \frac{1}{\varphi(\theta)} e^{\theta_1 \cos(x) + \theta_2 \sin(x)}\]</span></p>
<p>for <span class="math inline">\(\theta = (\theta_1, \theta_2)^T \in \mathbb{R}^2\)</span>. A common
alternative parametrization is obtained by introducing
<span class="math inline">\(\kappa = \|\theta\|_2 = \sqrt{\theta_1^2 + \theta_2^2}\)</span>, and
(whenever <span class="math inline">\(\kappa \neq 0\)</span>)
<span class="math inline">\(\nu = \theta / \kappa = (\cos(\mu), \sin(\mu))^T\)</span> for <span class="math inline">\(\mu \in (-\pi, \pi]\)</span>.
Using the <span class="math inline">\((\kappa, \mu)\)</span>-parametrization the density becomes<br />
<span class="math display">\[f(x) = \frac{1}{\varphi(\kappa \nu)} e^{\kappa \cos(x - \mu)}.\]</span>
The former parametrization in terms of
<span class="math inline">\(\theta\)</span> is, however, the canonical
parametrization of the family of distributions as an exponential family, which
is particularly useful for various likelihood estimation algorithms.
The normalization constant</p>
<p><span class="math display">\[\begin{align*}
\varphi(\kappa \nu) &amp; = \int_{-\pi}^\pi e^{\kappa \cos(x - \mu)}\mathrm{d} x \\
&amp; = 2 \pi \int_{0}^{1} e^{\kappa \cos(\pi x)}\mathrm{d} x = 2 \pi I_0(\kappa) 
\end{align*}\]</span></p>
<p>is given in terms of the <a href="http://mathworld.wolfram.com/ModifiedBesselFunctionoftheFirstKind.html">modified Bessel function</a>
<span class="math inline">\(I_0\)</span>. We can easily compute and plot the density using R’s <code>besselI</code> implementation of
the modified Bessel function.</p>

<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="1-2-monte-carlo-methods.html#cb10-1"></a>phi &lt;-<span class="st"> </span><span class="cf">function</span>(k) <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span><span class="kw">besselI</span>(k, <span class="dv">0</span>)</span>
<span id="cb10-2"><a href="1-2-monte-carlo-methods.html#cb10-2"></a><span class="kw">curve</span>(<span class="kw">exp</span>(<span class="kw">cos</span>(x)) <span class="op">/</span><span class="st"> </span><span class="kw">phi</span>(<span class="dv">1</span>), <span class="op">-</span>pi, pi, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">ylab =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.52</span>))</span>
<span id="cb10-3"><a href="1-2-monte-carlo-methods.html#cb10-3"></a><span class="kw">curve</span>(<span class="kw">exp</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">cos</span>(x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">phi</span>(<span class="dv">2</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</span>
<span id="cb10-4"><a href="1-2-monte-carlo-methods.html#cb10-4"></a><span class="kw">curve</span>(<span class="kw">exp</span>(<span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span><span class="kw">cos</span>(x <span class="op">+</span><span class="st"> </span><span class="fl">1.5</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">phi</span>(<span class="fl">0.5</span>), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vonMisesDens"></span>
<img src="CSwR_files/figure-html/vonMisesDens-1.png" alt="Density for the von Mises distribution with parameters \(\kappa = 1\) and \(\nu = 0\) (black), \(\kappa = 2\) and \(\nu = 1\) (red), and \(\kappa = 0.5\) and \(\nu = - 1.5\) (blue)." width="70%" />
<p class="caption">
Figure 1.7: Density for the von Mises distribution with parameters <span class="math inline">\(\kappa = 1\)</span> and <span class="math inline">\(\nu = 0\)</span> (black), <span class="math inline">\(\kappa = 2\)</span> and <span class="math inline">\(\nu = 1\)</span> (red), and <span class="math inline">\(\kappa = 0.5\)</span> and <span class="math inline">\(\nu = - 1.5\)</span> (blue).
</p>
</div>
<p>It is not entirely obvious how we should go about simulating data points
from the von Mises distribution. It will be demonstrated in Section
<a href="4-3-reject-samp.html#reject-samp">4.3</a> how to implement a <em>rejection sampler</em>, which is one
useful algorithm for simulating samples from a distribution with a density.</p>
<p>In this section we simply use the <code>rmovMF</code> function from the <code>movMF</code> package,
which implements a few functions for working with (finite mixtures of) von
Mises distributions, and even the general von <a href="https://en.wikipedia.org/wiki/Von_Mises–Fisher_distribution">Mises-Fisher distributions</a>
that are generalizations of the von Mises distribution to <span class="math inline">\(p\)</span>-dimensional
unit spheres.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="1-2-monte-carlo-methods.html#cb11-1"></a><span class="kw">library</span>(<span class="st">&quot;movMF&quot;</span>)</span>
<span id="cb11-2"><a href="1-2-monte-carlo-methods.html#cb11-2"></a>xy &lt;-<span class="st"> </span><span class="kw">rmovMF</span>(<span class="dv">500</span>, <span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span><span class="kw">c</span>(<span class="kw">cos</span>(<span class="op">-</span><span class="fl">1.5</span>), <span class="kw">sin</span>(<span class="op">-</span><span class="fl">1.5</span>)))</span>
<span id="cb11-3"><a href="1-2-monte-carlo-methods.html#cb11-3"></a><span class="co"># rmovMF represents samples as elements on the unit circle</span></span>
<span id="cb11-4"><a href="1-2-monte-carlo-methods.html#cb11-4"></a>x &lt;-<span class="st"> </span><span class="kw">acos</span>(xy[, <span class="dv">1</span>]) <span class="op">*</span><span class="st"> </span><span class="kw">sign</span>(xy[, <span class="dv">2</span>])</span></code></pre></div>

<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="1-2-monte-carlo-methods.html#cb12-1"></a><span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">15</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>)</span>
<span id="cb12-2"><a href="1-2-monte-carlo-methods.html#cb12-2"></a><span class="kw">rug</span>(x)</span>
<span id="cb12-3"><a href="1-2-monte-carlo-methods.html#cb12-3"></a><span class="kw">density</span>(x, <span class="dt">bw =</span> <span class="st">&quot;SJ&quot;</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb12-4"><a href="1-2-monte-carlo-methods.html#cb12-4"></a><span class="kw">curve</span>(<span class="kw">exp</span>(<span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span><span class="kw">cos</span>(x <span class="op">+</span><span class="st"> </span><span class="fl">1.5</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">phi</span>(<span class="fl">0.5</span>), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:vMdata"></span>
<img src="CSwR_files/figure-html/vMdata-1.png" alt="Histogram of 500 simulated data points from a von Mises distribution with parameters \(\kappa = 0.5\) and \(\nu = - 1.5\). A smoothed density estimate (red) and the true density (blue) are added to the plot." width="70%" />
<p class="caption">
Figure 1.8: Histogram of 500 simulated data points from a von Mises distribution with parameters <span class="math inline">\(\kappa = 0.5\)</span> and <span class="math inline">\(\nu = - 1.5\)</span>. A smoothed density estimate (red) and the true density (blue) are added to the plot.
</p>
</div>
</div>
<div id="mixtures-of-von-mises-distributions" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Mixtures of von Mises distributions</h3>
<p>The von Mises distributions are unimodal distributions on <span class="math inline">\((-\pi, \pi]\)</span>. Thus to
find a good model of the bimodal angle data, say, we have do move beyond these
distributions. A standard approach for constructing multimodal distributions
is as <em>mixtures</em> of unimodal distributions. A mixture of two von Mises distributions
can be constructed by flipping a (biased) coin to decide which of the two
distributions to sample from. We will use the exponential family parametrization
in the following.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="1-2-monte-carlo-methods.html#cb13-1"></a>thetaA &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">3.5</span>, <span class="dv">-2</span>)</span>
<span id="cb13-2"><a href="1-2-monte-carlo-methods.html#cb13-2"></a>thetaB &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">4.5</span>, <span class="dv">4</span>)</span>
<span id="cb13-3"><a href="1-2-monte-carlo-methods.html#cb13-3"></a>alpha &lt;-<span class="st"> </span><span class="fl">0.55</span> <span class="co"># Probability of von Mises distribution A</span></span>
<span id="cb13-4"><a href="1-2-monte-carlo-methods.html#cb13-4"></a><span class="co"># The sample function implements the &quot;coin flips&quot;</span></span>
<span id="cb13-5"><a href="1-2-monte-carlo-methods.html#cb13-5"></a>u &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="dv">500</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">prob =</span> <span class="kw">c</span>(alpha, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha))</span>
<span id="cb13-6"><a href="1-2-monte-carlo-methods.html#cb13-6"></a>xy &lt;-<span class="st"> </span><span class="kw">rmovMF</span>(<span class="dv">500</span>, thetaA) <span class="op">*</span><span class="st"> </span>u <span class="op">+</span><span class="st"> </span><span class="kw">rmovMF</span>(<span class="dv">500</span>, thetaB) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>u)</span>
<span id="cb13-7"><a href="1-2-monte-carlo-methods.html#cb13-7"></a>x &lt;-<span class="st"> </span><span class="kw">acos</span>(xy[, <span class="dv">1</span>]) <span class="op">*</span><span class="st"> </span><span class="kw">sign</span>(xy[, <span class="dv">2</span>])</span></code></pre></div>
<p>The <code>rmovMF</code> actually implements simulation from a mixture distribution
directly, thus there is no need to construct the “coin flips” explicitly.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="1-2-monte-carlo-methods.html#cb14-1"></a>theta &lt;-<span class="st"> </span><span class="kw">rbind</span>(thetaA, thetaB)</span>
<span id="cb14-2"><a href="1-2-monte-carlo-methods.html#cb14-2"></a>xy &lt;-<span class="st"> </span><span class="kw">rmovMF</span>(<span class="kw">length</span>(x), theta, <span class="kw">c</span>(alpha, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha))</span>
<span id="cb14-3"><a href="1-2-monte-carlo-methods.html#cb14-3"></a>x_alt &lt;-<span class="st"> </span><span class="kw">acos</span>(xy[, <span class="dv">1</span>]) <span class="op">*</span><span class="st"> </span><span class="kw">sign</span>(xy[, <span class="dv">2</span>])</span></code></pre></div>
<p>To compare the simulated data with two mixture components to the model and
a smoothed density, we implement an R function that computes the density
for an angle argument using the function <code>dmovMF</code> that takes a unit circle
argument.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="1-2-monte-carlo-methods.html#cb15-1"></a>dvM &lt;-<span class="st"> </span><span class="cf">function</span>(x, theta, alpha) {</span>
<span id="cb15-2"><a href="1-2-monte-carlo-methods.html#cb15-2"></a>  xx &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">cos</span>(x), <span class="kw">sin</span>(x))</span>
<span id="cb15-3"><a href="1-2-monte-carlo-methods.html#cb15-3"></a>  <span class="kw">dmovMF</span>(xx, theta, <span class="kw">c</span>(alpha, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha)) <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi)</span>
<span id="cb15-4"><a href="1-2-monte-carlo-methods.html#cb15-4"></a>}</span></code></pre></div>
<p>Note that <code>dmovMF</code> uses normalized <a href="https://en.wikipedia.org/wiki/Spherical_measure">spherical measure</a>
on the unit circle as reference
measure, thus the need for the <span class="math inline">\(2\pi\)</span> division if we want the result to be
comparable to histograms and density estimates that use Lebesgue measure on
<span class="math inline">\((-\pi, \pi]\)</span> as the reference measure.</p>

<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="1-2-monte-carlo-methods.html#cb16-1"></a><span class="kw">hist</span>(x, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">15</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>))</span>
<span id="cb16-2"><a href="1-2-monte-carlo-methods.html#cb16-2"></a><span class="kw">rug</span>(x)</span>
<span id="cb16-3"><a href="1-2-monte-carlo-methods.html#cb16-3"></a><span class="kw">density</span>(x, <span class="dt">bw =</span> <span class="st">&quot;SJ&quot;</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb16-4"><a href="1-2-monte-carlo-methods.html#cb16-4"></a><span class="kw">curve</span>(<span class="kw">dvM</span>(x, theta, alpha), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</span>
<span id="cb16-5"><a href="1-2-monte-carlo-methods.html#cb16-5"></a></span>
<span id="cb16-6"><a href="1-2-monte-carlo-methods.html#cb16-6"></a><span class="kw">hist</span>(x_alt, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span>pi, pi, <span class="dt">length.out =</span> <span class="dv">15</span>), <span class="dt">prob =</span> <span class="ot">TRUE</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>))</span>
<span id="cb16-7"><a href="1-2-monte-carlo-methods.html#cb16-7"></a><span class="kw">rug</span>(x_alt)</span>
<span id="cb16-8"><a href="1-2-monte-carlo-methods.html#cb16-8"></a><span class="kw">density</span>(x_alt, <span class="dt">bw =</span> <span class="st">&quot;SJ&quot;</span>, <span class="dt">cut =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lines</span>(<span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb16-9"><a href="1-2-monte-carlo-methods.html#cb16-9"></a><span class="kw">curve</span>(<span class="kw">dvM</span>(x, theta, alpha), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:mixvMdata"></span>
<img src="CSwR_files/figure-html/mixvMdata-1.png" alt="Histograms of 500 simulated data points from a mixture of two von Mises distributions using either the explicit construction of the mixture (left) or the functionality in rmovMF to simulate mixtures directly (right). A smoothed density estimate (red) and the true density (blue) are added to the plot." width="49%" /><img src="CSwR_files/figure-html/mixvMdata-2.png" alt="Histograms of 500 simulated data points from a mixture of two von Mises distributions using either the explicit construction of the mixture (left) or the functionality in rmovMF to simulate mixtures directly (right). A smoothed density estimate (red) and the true density (blue) are added to the plot." width="49%" />
<p class="caption">
Figure 1.9: Histograms of 500 simulated data points from a mixture of two von Mises distributions using either the explicit construction of the mixture (left) or the functionality in <code>rmovMF</code> to simulate mixtures directly (right). A smoothed density estimate (red) and the true density (blue) are added to the plot.
</p>
</div>
<p>Simulation of data from a distribution finds many applications. The technique
is widely used whenever we want to investigate a statistical methodology in
terms of its frequentistic performance under various data sampling models, and
simulation is a tool of fundamental importance for
the practical application of Bayesian statistical methods. Another important
application is as a tool for computing approximations of integrals. This
is usually called Monte Carlo integration and is a form of numerical
integration. Computing probabilities or distribution functions, say,
are notable examples of integrals, and we consider here the computation of
the probability of the interval <span class="math inline">\((0, 1)\)</span> for the above mixture of two von Mises
distributions.</p>
<p>It is straightforward to compute this probability via Monte Carlo integration
as a simple average. Note that we will use a large number of samples,
50,000 in this case, of simulated angles for this computation. Increasing
the number even further will make the result more accurate. Chapter <a href="5-mci.html#mci">5</a>
deals with the assessment of the accuracy of Monte Carlo integrals, and how
this random error can be estimated, bounded and minimized.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="1-2-monte-carlo-methods.html#cb17-1"></a>xy &lt;-<span class="st"> </span><span class="kw">rmovMF</span>(<span class="dv">50000</span>, theta, <span class="kw">c</span>(alpha, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha))</span>
<span id="cb17-2"><a href="1-2-monte-carlo-methods.html#cb17-2"></a>x &lt;-<span class="st"> </span><span class="kw">acos</span>(xy[, <span class="dv">1</span>]) <span class="op">*</span><span class="st"> </span><span class="kw">sign</span>(xy[, <span class="dv">2</span>])</span>
<span id="cb17-3"><a href="1-2-monte-carlo-methods.html#cb17-3"></a><span class="kw">mean</span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;</span><span class="st"> </span><span class="dv">1</span>)  <span class="co"># Estimate of the probability of the interval (0, 1)</span></span></code></pre></div>
<pre><code>## [1] 0.08662</code></pre>
<p>The probability above could, of course, be expressed using the
distribution function of the mixture of von Mises distributions, which
in turn can be computed in terms of integrals of von Mises densities.
Specifically, the probability is
<span class="math display">\[p = \frac{\alpha}{\varphi(\theta_A)} \int_0^1 e^{\theta_{A, 1} \cos(x) + \theta_{A, 2} \sin(x)} \mathrm{d} x +  
\frac{1 - \alpha}{\varphi(\theta_B)} \int_0^1 e^{\theta_{B, 1} \cos(x) + \theta_{B, 2} \sin(x)} \mathrm{d} x,\]</span>
but these integrals do not have a simple analytic representation – just as the
distribution function of the von Mises distribution doesn’t have a simple analytic
expression. Thus the computation of the probability requires numerical
computation of the integrals.</p>
<p>The R function <code>integrate</code> can be used for numerical integration of univariate
functions using standard numerical integration techniques. We can thus
compute the probability by integrating the density of the mixture,
as implemented above as the R function <code>dvM</code>. Note the arguments passed
to <code>integrate</code> below. The first argument is the density function, then follows
the lower and the upper limits of the integration, and then follows additional
arguments to the density – in this case parameter values.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="1-2-monte-carlo-methods.html#cb19-1"></a><span class="kw">integrate</span>(dvM, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">theta =</span> theta, <span class="dt">alpha =</span> alpha)</span></code></pre></div>
<pre><code>## 0.08635171 with absolute error &lt; 9.6e-16</code></pre>
<p>The <code>integrate</code> function in R is an interface to a couple of classical
<a href="https://en.wikipedia.org/wiki/QUADPACK">QUADPACK</a> Fortran routines for
numerical integration via <a href="https://en.wikipedia.org/wiki/Adaptive_quadrature">adaptive quadrature</a>.
Specifically, the computations rely on approximations of the form
<span class="math display">\[\int_a^b f(x) \mathrm{d} x \simeq \sum_i w_i f(x_i)\]</span>
for certain <em>grid points</em> <span class="math inline">\(x_i\)</span> and weights <span class="math inline">\(w_i\)</span>, which are computed using
<a href="https://en.wikipedia.org/wiki/Gauss–Kronrod_quadrature_formula">Gauss-Kronrod quadrature</a>.
This method provides an estimate of the approximation error in addition to
the numerical approximation of the integral itself.</p>
<p>It is noteworthy that <code>integrate</code> as a function implemented in R
takes another function, in this case the density <code>dvM</code>, as an argument. R
is a <a href="https://adv-r.hadley.nz/fp.html">functional programming language</a>
and functions are <a href="https://en.wikipedia.org/wiki/First-class_function">first-class citizens</a>.
This implies, for instance, that functions can be passed as arguments to other
functions using a variable name – just like any other variable can be passed
as an argument to a function. In the parlance of functional programming,
<code>integrate</code> is a <a href="https://adv-r.hadley.nz/functionals.html">functional</a>:
a higher-order function that takes a function as argument and returns a
numerical value. One of the themes of this book is how to
make good use of functional (and object oriented) programming features in R
to write clear, expressive and modular code without sacrificing computational
efficiency.</p>
<p>Returning to the specific problem of the computation of an integral, we may ask
what the purpose of Monte Carlo integration is? Apparently we can
just do numerical integration using e.g. <code>integrate</code>. There are at least two
reasons why Monte Carlo integration is sometimes preferable. First, it is straightforward
to implement and often works quite well for multivariate and even high-dimensional
integrals, whereas grid-based numerical integration schemes scale poorly with
the dimension. Second, it does not require that we have an analytic representation
of the density. It is common in statistical applications that we are interested
in the distribution of a statistic, which is a complicated transformation of
data, and whose density is difficult or impossible to find analytically. Yet if
we can just simulate data, we can simulate from the distribution of the statistic,
and we can then use Monte Carlo integration to compute whatever
probability or integral w.r.t. the distribution of the statistic that we are
interested in.</p>
</div>
<div id="large-scale-monte-carlo-methods" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Large scale Monte Carlo methods</h3>
<p>Monte Carlo methods are used pervasively in statistics and in many other
sciences today. It is nowadays trivial to
simulate millions of data points from a simple univariate distribution like
the von Mises distribution, and Monte Carlo methods are generally attractive
because they allow us to solve computational problems approximately
in many cases where exact or analytic computations are impossible and alternative
deterministic numerical computations require more adaptation to the specific problem.</p>
<p>Monte Carlo methods are thus really good off-the-shelf methods, but scaling
the methods up can be a challenge and is a contemporary research topic.
For the simulation of multivariate <span class="math inline">\(p\)</span>-dimensional data it can, for
instance, make a big difference whether the algorithms scale linearly in <span class="math inline">\(p\)</span>
or like <span class="math inline">\(O(p^a)\)</span> for some <span class="math inline">\(a &gt; 1\)</span>. Likewise, some Monte Carlo methods (e.g. 
Bayesian computations) depend on a data set of size <span class="math inline">\(n\)</span>, and for large
scale data sets, algorithms that scale like <span class="math inline">\(O(n)\)</span> are really the only
algorithms that can be used in practice.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="1-1-intro-smooth.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="1-3-optimization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
